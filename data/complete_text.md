

## Introduction

### SCIENCE AND YOUR EVERYDAY LIFE

A highly contagious and potentially fatal virus spreads through respiratory droplets but is easily preventable through a simple vaccination. Sound familiar? Since you’ve gone through a pandemic—one of the events in your lifetime that will make history—we know what you’re thinking: Covid‐19!

But no, the virus we’re talking about is canine distemper. This is one of the most serious diseases a dog can get. It can also affect foxes, pandas, skunks, and raccoons. Like rabies, distemper is nothing you or your furry friend want to mess with. It can lead to some gnarly symptoms, including dehydration, vomiting, difficult breathing, and odd fits of snapping or chomping. As the condition worsens, infected dogs can suffer grand mal seizures followed by death.

Dog owners find the idea of canine distemper distressing. Most want effective prevention and treatment for their pets and, if they hear of canine distemper, follow expert veterinary advice. What’s tragically ironic is that some of the same dog owners who do not hesitate to vaccinate their puppies against distemper are skeptical towards vaccines for humans, discounting the advice of medical experts.

Human papilloma virus (HPV) is widespread worldwide; it is one of the world’s most frequently sexually transmitted diseases. Among other effects, HPV substantially increases the risk of various forms of cancer. Thankfully, there’s a vaccine for HPV. The vaccine first became available in 2006, after thorough testing for safety and efficacy. The World Health Organization (WHO) recommends HPV vaccines as part of routine vaccinations in all countries. And yet, the global HPV vaccination rate in 2018 was estimated to be only 12.2%. This low rate is a combination of limited availability and affordability in low‐ to middle‐income nations and parents’ resistance to their children receiving the HPV vaccine, especially in high‐income nations.

At some point in their lives, most people will need to decide about whether to be vaccinated for some disease, whether to have their children undergo routine vaccinations, and even whether to have their dog vaccinated. And, when it comes to vaccines for humans, sometimes vaccine skeptics have louder voices than doctors and other experts. So, it can be difficult to get a clear understanding of vaccines’ safety, effectiveness, and necessity for public health. What can help is a sound understanding of the medical research about vaccines and a deeper understanding of what makes this and other scientific research trustworthy.

All vaccines approved for use in humans or animals have undergone thorough testing for safety and efficacy. Most vaccines do have potential side effects, such as achiness for a day or two, but serious side effects for any approved vaccine are very rare. And vaccine skeptics’ claims about substantive risks of vaccinations have been thoroughly debunked.

But you don’t need to just take our word for it, or the word of any individual scientist. Science’s credibility and its trustworthiness as a source of knowledge result from its methods and reasoning processes and how these are carried out by scientists and endorsed by scientific institutions. This is what makes established scientific knowledge trustworthy. Learning more about these methods and reasoning processes can give you a sense for why scientific research results in trustworthy knowledge, and it can also prepare you to evaluate specific reports of scientific research findings.

Understanding how science works is important because scientific findings, and the public’s reactions to them, dramatically shape our world. Science regularly influences your life, whether you are looking for it to or not. Consider the Covid-19 pandemic, the internet and the rise of AI, and climate change policy. The ability to understand and assess scientific reasoning enables you to make educated decisions related to your health, medical care, lifestyle, and more. It also enables you to critically evaluate reports of scientific findings and the credentials of experts in order to decide not just what to believe, but—more importantly—why.

Someone with a sophisticated understanding of science is also well positioned to make judgments about science more globally. Is the level of public funding for  scientific research sufficient? Should we worry if private corporations fund science? Are there important topics that aren’t yet adequately targeted in scientific research? Answers to these questions require thinking about the status of the scientific enterprise as a whole, how it should relate to society, and whether and how funding sources matter.



Scientists are, of course, the main practitioners of science. Other researchers have as their primary focus understanding what science—and scientists—are up to. These researchers investigate what science is and how it works, its challenges and limitations, and its relationship with society. These topics are what this book is all about. Several disciplines investigate science in this way; primary among these are history, sociology, and philosophy. Historians of science research how science has changed over time. Sociologists research social and cultural influences on science. This book draws from the history and sociology of science, but its main approach is philosophical. This is because we, its authors, are philosophers of science.

If you haven’t studied philosophy of science, it may sound obscure. But philosophy of science is just the investigation of science, focused especially on questions of what science should be like in order to be a trustworthy route to knowledge and to achieve the other ends we want it to have, such as usefulness to society. This book is written from a philosophical perspective, but it does not dwell on philosophers’ different theories and debates about science. Instead, we aim to combine insights about science from philosophy with concrete examples to illuminate science’s aims, methods, and patterns of reasoning, without getting bogged down in controversies, technical terminology, or too many details.

The title of this book, *Recipes for Science*, is meant to evoke two ideas. First, culinary recipes have many variations: in what dish they are used to create, which version of the dish, and details of implementation. Different recipes are used to make bread and lasagna, bread recipes may call for leavening with yeast or baking soda, and ingredient measurements may be in weight or volume. Science is also like this. Scientific research can have many different aims and proceed using a variety of different methods.

On the other hand, any culinary recipe employs intentional combinations of ingredients using time-tested methods to lead to a specific outcome. And different recipes for one type of food tend to have some elements in common, even if many of their features vary. So, for example, breads usually incorporate grain of some kind as a major ingredient, most use a leavening agent, and they are cooked—usually but not always by baking in the oven. There are resemblances among different breads and the recipes used to make them, even if there’s no simple definition of bread and no one recipe required to make bread. Science is like this as well. Even as it proceeds in different ways, and even as there’s no one overarching set of instructions or mechanical procedures that guarantees good science, there are certain generalizations that can be made about how good science is conducted.



 

Recipes for bread have many variations, but both the recipes and the resulting breads tend to have some features in common with one another. Scientific methods are like this: endless variation but with themes in both methods and results.

This book aims to facilitate a clear understanding of the main elements of science, and the importance of those elements, even as it illustrates the tremendous variety of projects that count as science.

The first part of the book, Chapters 1 – 5, addresses the nature of science and its key methods.

Chapter 1 surveys what is distinctive about science’s aims, methods, and institutional structure and suggests those features as a checklist for distinguishing science from non-science and fake science.

Chapter 2 introduces how science is shaped by values, varies in its aims, and consists in a variety of recipes with a few commonalities.

Chapter 3 examines the nature of scientific experiments and the roles experimentation plays in science.

Chapter 4 catalogues varieties of non-experimental studies and discuss their advantages and disadvantages.

Chapter 5 focuses on scientific models: how they are constructed and used, and the main varieties in which they come.

The second part of the book, Chapters 6 – 10, focuses on important patterns of reasoning in science.

Chapter 6 Examines patterns of deductive reasoning and their use in scientific hypothesis-testing.

Chapter 7 Addresses the importance of and challenges with inductive reasoning and the scientific significance of abductive reasoning, also known as inference to the best explanation.

Chapter 8 Introduces basic concepts and interpretations of probabilistic reasoning.

Chapter 9 Surveys graphical and numerical representation using descriptive statistics and misuses of statistical reasoning, while

Chapter 10 Discusses how inferential statistics is used in estimation and hypothesis-testing.

The final part of the book, Chapters 11 – 13, addresses the ultimate aims of science and its relationship to society.

Chapter 11 Addresses how scientific methods are used to acquire causal knowledge.

Chapter 12 Examines how scientific findings yield theoretical knowledge and understanding of the world and discusses change in scientific theories and how science makes progress.

Chapter 13 Discusses the complicated relationship science bears to society, analyzes how values influence science, and surveys the changes and challenges facing science in the 21st century.

### INTENDED AUDIENCES AND HOW TO USE THE BOOK

This book is not just for students of philosophy or science majors. Indeed, the primary audience we had in mind in developing this book is an undergraduate student in a general education course, who may not take any additional science courses in college. We asked ourselves, what would that student most benefit from knowing about how science works? What episodes from historical and current science would that student be interested to read about and contemplate?

We expect this book will also be useful for some more specialized or more advanced courses. These include science education courses, especially those that focus on the nature of science and scientific reasoning; introductory philosophy of science courses, especially if supplemented with primary readings that address some of the major philosophical controversies about science; and introductory science courses, especially methods courses, when supplemented with material specific to the particular scientific field of study.

This textbook was designed to be usable in its entirety in a standard semester, with approximately one chapter covered per week. But, to be useful in a wide range of course levels and disciplines and for different teaching goals, we have also designed the book to be modular: each chapter can be used independently from the others. Instructors (or independent readers) can thus choose to use only the chapters that suit their needs. Each section may rely on earlier sections in the same chapter, but not later sections in the same chapter or other chapters. Instructors may choose not to assign later sections in some chapters that seem overly specialized or too difficult for their teaching needs.

Scientific integrity requires the proper acknowledgement of the sources of ideas or words researchers use from someone else. There are standard citation practices for ideas and words from published material such as articles, books, and encyclopedia entries. But even using a tool like a large language model (LLM) for generating and editing text should be transparently acknowledged in a paper. When you directly use others’ words, that should be indicated with quotation marks and precise citation, including page number where available. A similar point applies to paraphrases. In this textbook, we have compiled our sources for each chapter in a bibliography at the back of the book. Failing to cite one’s sources in academic writing or using parts of a text written by someone else or the ideas of others—whether intentional or not—is plagiarism. But scientific integrity not only requires proper acknowledgement of sources; it also requires relying on the best available sources. Sources must be credible, up-to-date, and pertinent. There’s no general standard for where to find high-quality sources. Depending on the purpose of a piece of writing, peer-reviewed academic research articles and books may be the only acceptable sources, while, in other instances, popular content from newspapers and magazines might also be fine. Internet sources might be okay too, but because anyone can publish a blog or pontificate on social media, it’s essential to carefully evaluate the credibility, reputation, and timeliness of a source on the internet and whether it comes from a genuine expert on the topic.

Each section within every chapter ends with a list of exercises to solidify understanding and challenge students to apply what they have learned. We encourage instructors to make use of these exercises for in-class group or individual activities, homework, or exam questions. Exercises are divided into three categories: Recall exercises can be completed just by consulting the section. Think exercises provide opportunities to consider implications of or questions about ideas from the section. In Apply exercises, students are asked to apply ideas from the section to new examples or circumstances.

A list of further readings at the end of each chapter provides inroads into more in-depth investigations of individual topics covered. At the end of the book, there is a glossary of technical terms and other specialized vocabulary that students can consult as needed. Terms defined in the glossary are indicated in the main text with bold and italics when they are first defined, as philosophy of science was earlier in this introduction.

Finally, there is a website to accompany the textbook. The website includes example syllabi for different kinds of courses utilizing this text, additional exercises, an answer key for some exercises, some image files related to the text, and links to content that will enrich students’ experience with the topics covered in this book. The website also includes a series of brief videos, each engaging with one of the core topics in this book.



#### EXERCISES

0.1 Recall: List three ways in which science is relevant to your life (and others’ lives). Watch Video 1

0.2 Think: What do you expect to learn from this textbook and the course you’re reading it for?

0.3 Think: What most concerns you about this textbook and the course you’re reading it for?

0.4 Think: What do you think is most valuable about learning about science and scientific reasoning? Give reasons to support your response.

0.5 Apply: Describe your relationship to science. For example, have you taken many courses in science or read about science on your own? If so, on what topics, and did you enjoy the experience? Do you know any scientists? Do you think there are reasons to distrust or dislike science? If so, what are the reasons?

### FURTHER READINGS

For an overview of immunization and vaccination, see World Health Organization. Vaccines and immunization. www.who.int/health‐topics/vaccines‐and‐immunization

For a concise overview of how vaccination has contributed to global health, see Greenwood, B. (2014). The contribution of vaccination to global health: Past, present and future. Philosophical Transactions of the Royal Society B, 369 (1645), 20130433.

A general reference on topics in philosophy, including philosophy of science, is the Stanford encyclopedia of philosophy. https://plato.stanford.edu

## CHAPTER 1 The nature of science

### 1.1 SCIENTIFIC KNOWLEDGE OF CLIMATE CHANGE

After reading this section, you should be able to:

- Explain why climate change is a serious practical concern
- Describe how scientific research supports the finding of human‐caused climate change and why public opinion lags behind the research
- List three indicators that scientific knowledge is trustworthy

#### A serious practical concern

In November 2023, the 28th United Nations Climate Change conference was held in the United Arab Emirates. This event was the 28th Conference of the Parties (COP28) to the United Nations Framework Convention on Climate Change (UNFCCC). COP28 was also the 18th meeting of the parties to the Kyoto Protocol, which in 1997 extended and expanded the nations supporting the UNFCCC, and the fifth meeting of the parties to the Paris Agreement, signed by 196 countries in 2015. As this book was printed, COP29 was in planning for November 2024, and annual international meetings in this series are intended to continue.

International conferences about the challenge of climate change have been occurring for 30 years, with increasing consensus about the measures needed to counteract rising global temperatures. A primary goal is to limit the rise in global mean temperature—the average of all land and ocean surface temperatures—to 1.5° Celsius or below compared to preindustrial levels. This temperature change would be minor if it were a single‐day temperature in one place. But a 1.5° Celsius increase in global mean temperature is a major change with radical consequences.

Think of this temperature increase like a fever. The human body maintains a relatively constant temperature in the range of 36.5°–37.5° Celsius (97.7°–99.5° Fahrenheit). When your body temperature increases 1.5° Celsius, which is nearly 3° Fahrenheit, you have a fever. If your body were suddenly that much warmer on average, day in and day out for months and years, it would be a serious medical emergency.

An average global temperature increase of 1.5° Celsius would be similarly devastating for Earth. But why? First, because it changes the Earth’s climate.

Climate change, mountain glaciers are shrinking, and ice sheets are melting in the Arctic, Greenland, and Antarctica. These changes lead to sea levels rising, thereby flooding coastal areas. Precipitation patterns across seasons also become more unstable, leading to more droughts, heat waves, flooding from storms, and wildfires—even shifting the growth timing of plants and crops that makes them more vulnerable to loss.

Second, the changing climate has downstream effects. These effects threaten to push some animal and plant species to extinction, and even collapse ecosystems. Also threatened are human social conditions. Drinking water is scarcer and droughts more frequent or severe; crop yields are expected to decrease. Coastal cities and island nations are at risk of serious floods and devastating hurricanes. All of this affects global health, poverty, hunger, and national security. The World Bank estimates that 200 million people will be forced to migrate between 2020 and 2050 due to the impacts of climate change. Ultimately, global warming will make the Earth less hospitable for all creatures, including humans, and a more unjust place in virtue of who will suffer and how this suffering will be managed. International climate change work therefore includes not just efforts to mitigate climate change but also, increasingly, attention to how to adapt human societies to a changed climate.

Greenhouse gases work like a blanket. As incoming radiation from the Sun permeates our atmosphere, some hits the Earth and is reflected back out to space. But greenhouse gases, such as methane (CH4), carbon dioxide (CO2), and water vapor, trap some of the heat in the atmosphere. This trapped heat warms the planet’s surface, making it hospitable to life. Higher concentrations of greenhouse gases lead to a warmer planet; lower concentrations lead to a cooler planet.

Changing atmospheric concentrations of greenhouse gases are a major factor in Earth’s climate. Other factors include variations in the Earth’s orbit, the motion of tectonic plates, the impact of meteorites, and volcanism on the Earth’s surface. So, our climate has never been static: it has been fluctuating for billions of years. What’s special about the current climate changes, then? Why is this time different?

What’s different is that human activities have led to extreme changes. Since the beginning of the Industrial Revolution, human activities that burn fossil fuels like coal and oil have resulted in carbon dioxide being released into the atmosphere at unprecedented rates. Since carbon dioxide is a greenhouse gas, this increases the heat retention of our atmosphere. Other human activities—primarily agricultural activities such as raising livestock—release methane, which is another greenhouse gas even more potent than carbon dioxide in trapping heat. These human-caused greenhouse gas emissions are so extreme that they’ve led to a historically unprecedented increase in the Earth’s global mean temperature.

This discovery isn’t recent. Scientists have known since the 18th century that burning carbon-based fossil fuels releases carbon into the atmosphere. Systematic research on the relationship between carbon dioxide emissions and climate change began in the 19th century, when the American engineer Marsden Manson discovered how the heat-trapping power of the atmosphere varies with only slight changes in its makeup. A few years later, the Swedish physicist and chemist Svante August Arrhenius completed calculations showing that changes in carbon dioxide also function as a “throttle.” on other greenhouse gases like water vapor. He calculated that there would be an arctic temperature increase of approximately 8° C (46.4° F) from atmospheric carbon levels two to three times their known value at the time. In 1908, Arrhenius predicted, “the slight percentage of carbonic acid in the atmosphere may, by the advances of industry, be changed to a noticeable degree in the course of a few centuries.”

Just before the outbreak of World War II, the British steam engineer Guy Callendar presented a paper to the Royal Meteorological Society, in which he pointed out that the atmospheric concentration of carbon dioxide had significantly increased between 1900 and 1935, based on temperature measurements at 200 meteorological stations. In 1939, Callendar concluded:

As man is now changing the composition of the atmosphere at a rate which must be very exceptional on the geological time scale, it is natural to seek for the probable effects of such a change. From the best laboratory observations it appears that the principal result of increasing atmospheric carbon dioxide . . . would be a gradual increase in the mean temperature of the colder regions of the earth.



This prescient recognition of the role of human activity on atmospheric temperatures had to wait several decades to become widely accepted.

In 1958, the geochemist Charles David Keeling installed four infrared gas analyzers at the Mauna Loa Observatory in Hawai’i. Measurement collection has occurred continuously since 1958, recording an ever-increasing atmospheric CO2 concentration. The graph showing these measurements is known as the Keeling Curve (see Figure 1.2 a).

Keeling’s measurements provided evidence of rapidly increasing carbon dioxide levels in the atmosphere, and a 1979 report by the National Research Council—an American nonprofit organization devoted to scientific research—connected this increase to rise in average temperature. This report predicted that doubling atmospheric CO2 concentration from 300 to 600 ppm would result in an average warming of 2.0°–3.5° C. (Parts per million refers to a unit for measuring small concentrations of a substance.)

We haven’t yet reached the ominous level of 600 ppm, but we’re now long past safe levels of CO2 in the atmosphere, estimated to be about 350 ppm.

 

 Unprecedented increases in atmospheric carbon dioxide after the Industrial Revolution



For several decades, climate scientists have tracked changing atmospheric carbon dioxide levels with increasing precision. Ice cores taken from various locations in the Antarctic have enabled scientists to extrapolate historic CO2 levels for comparison to recent levels (see Figure 1.2(b)). A group of 78 scientists gathered data from several “climate proxies,” including tree rings, pollen, corals, glacier ice, lake and marine sediments, and historical documents. These data provided multiple types of evidence supporting the conclusion that, at the end of the 20th century, atmospheric levels of CO2 and global mean temperature are higher than at any point in the previous 2,000 years.

For the past 800,000 years, atmospheric carbon dioxide hadn’t been over 300 ppm (see Figure 1.3). Since the Industrial Revolution began about 250 years ago, the concentration has spiked to 420 ppm. This is nearly 50% more than levels had reached in 800 millennia—reached in only a quarter of one millennium of human-caused change. (See www.co2.earth for an updated estimate; unfortunately, this number is still climbing steadily.) The last time CO2 levels were this high, humans did not yet exist. In 2022, global mean temperature was 1.06° C (1.90° F) warmer than the pre-industrial period (1880–1900) and has been going up 0.18° C each decade. At this rate, 1.5° C will be surpassed before 2040.

#### Trustworthy scientific knowledge

Centuries of scientific research—including convergence of many types of evidence and broad consensus among scientists with relevant expertise—support the conclusion that we face an unprecedented climate crisis caused by human activity, sometimes called anthropogenic climate change. Like other scientific knowledge, it wasn’t initially obvious and still might not be obvious to those without relevant expertise. Scientists had to try out various techniques and gather different kinds of data to discover this conclusion is true.

Fundamentally, science aims to produce knowledge—in particular, scientific knowledge: explanatory knowledge of why or how the world is the way it is. And it’s the best approach we humans have developed for answering questions about the world around—and within—us. As we will see throughout the book, the scientific establishment has developed countless techniques to acquire knowledge. (You’ve already read about some of these at work in the climate science just described.) Understanding how scientists acquire new knowledge can give people greater reason to trust scientific knowledge, even if they themselves don’t have a full understanding of the evidence, methods, and reasoning leading to it.

First, relevant expertise is important for scientific knowledge to be trustworthy. You should trust climate scientists to do climate science in the same way you trust your mechanic with your car or your favorite restaurant with your dinner. The types of expertise required for these positions takes years, even decades, to develop. But the expertise doesn’t neatly transfer from one domain to another: don’t trust the average climate scientist to fix your car or make you a delicious meal. Similarly, politicians and policymakers know things about political and legislative matters, but they should not be looked to as authorities on the science of climate change—regardless of whether they accept its existence. To do so would be an appeal to irrelevant authority: appealing to the views of an individual who has no expertise in a field as evidence for some claim.

Second, consensus among the relevant experts is an important indicator that the findings are settled scientific knowledge. There is striking agreement among climate scientists about the existence of anthropogenic climate change. Reputable scientists and scientific societies, including the national science academies of the world and the Intergovernmental Panel on Climate Change (IPCC), agree that human-caused, or anthropogenic, climate change is occurring. This includes virtually all climatologists. In 2004, the historian of science Naomi Oreskes analyzed 928 abstracts on climate change published in scientific journals from 1993 to 2003; none expressed disagreement with the consensus position that anthropogenic climate change is occurring. In 2010, a group of researchers studied the views of the 200 climate scientists with the most extensive and productive publication records; more than 97% affirmed the existence of anthropogenic climate change as described by the IPCC.

Third, the convergence of different sources and types of evidence provides solid grounding for scientific knowledge. Well-established theories in physics explain how heat radiation works. Physical chemistry shows how carbon dioxide and other greenhouse gases in the atmosphere traps heat. Climatologists have developed extensive sources of evidence that support the same conclusions about climate change and its relationship to greenhouse gases and human activities. As we described earlier, some of this knowledge goes back centuries, and a range of techniques have been used to amass ever-more relevant evidence. Since the 1950s, scientific models and computer simulations have helped scientists to make testable predictions about what would happen to the global climate in response to different changes in human activities, and evidence has confirmed those predictions.

And yet, despite decisive scientific evidence supporting a consensus among scientists, public concern for climate change lags behind the research. According to surveys from the Pew Research Center from 2013, 44% surveyed across 23 countries did not view climate change to be a major threat; by 2018, that number had dropped to 33% across the same countries. Whether people are concerned about climate change largely

Today’s decisions determine the extent of climate change by 2100 depends on understanding its human causes and level of education. In some countries like the United States, however, being better educated doesn’t predict climate change concern as well as political views do.

People who don’t know much about a given topic can experience an illusion of understanding, in which they lack genuine understanding and so fail to appreciate the depth of their ignorance about that topic. For climate change, this means that people without advanced education in science—a demographic that includes most politicians—tend to have unwarranted confidence in their ability to assess the scientific findings. This includes those who are concerned about climate change as well as those who deny its existence. Worse, illusions of understanding have become easier to sustain in today’s society. Finding information merely through internet searches (so-called Google-knowing) has diminished genuine understanding, and we have limited opportunities for truly public discourse. Our online and in-person conversations tend to happen with people who have beliefs similar to our own.

Improving public climate literacy can support public engagement about global warming. If one knows that Earth is warming up and genuinely understands why, this can lead to changed behavior—for instance, petitioning one’s government to support more energy-efficient practices. More generally, understanding the processes that support trustworthy scientific knowledge—including relevant expertise, broad consensus, and extensive convergent evidence—is vitally important to assessing whether something qualifies as legitimate scientific knowledge and how to go about finding out.

#### EXERCISES

1.1 Recall: How do scientists know that human activities are radically altering Earth’s climate? Why are these changes a serious concern?

1.2 Think: Do all scientists, in virtue of being scientists, have the expertise to make pronouncements about global warming? Or only just those scientists who specialize in the climate sciences? Give reasons to support your answer.

1.3 Think: Describe how a nonspecialist can know whether to trust someone claiming scientific expertise, listing at least three kinds of evidence of their expertise.

1.4 Recall: Identify three indicators that scientific knowledge is trustworthy described in this section. For each, briefly say why it is important.

1.5 Apply: Think of a scientific finding that strikes you as surprising or possibly wrong. Do a little internet research (trying to focus on reputable sources). Assess how that scientific finding fares according to the three indicators that scientific knowledge is trustworthy. Based on this, do you think the finding qualifies as settled knowledge at this stage?

1.6 Think: List three reasons why public concern about anthropogenic climate change lags behind scientific research. Given that lag, how should climate scientists affect environmental policy in the government? Should they merely collect evidence and produce knowledge, leaving policy decisions to public officials? Do they have any obligations to more actively engage with the public?

### 1.2 SUBJECT MATTER AND METHODS

After reading this section, you should be able to:

- Describe what it means for science to provide natural explanations of natural phenomena
- Define empirical investigation and evidentialism and state their importance for science
- Indicate the differences between falsificationism, falsifiability, and openness to falsification, and state which are essential to the nature of science

#### The subject matter of science

We just described some of the abundant scientific evidence for anthropogenic climate change that has amassed over centuries. But we also noted how other experts, including political leaders, have roles to play in public conversations and policy decisions bearing on climate change mitigation and adaptation. What, if anything, is the difference between these forms of expertise?

This question relates to the nature of science, that is, the orientation, values, and methods that are specific to science and allow it to generate knowledge in the ways that it does. To begin, notice that things are more complicated than just saying science is in the business of generating knowledge. Scientific projects can be directed at a wide range of goals. Some scientific research aims at knowledge for its own sake; this is sometimes called basic research. For example, scientists investigate the conditions under which rainbows form to learn more about the behavior of light. Such knowledge may have applications, but basic research is not primarily focused on identifying or developing applications. Instead, basic research often aims for explanatory knowledge: sufficiently justified truths about how things work and why they are the way they are. We know so much about our world, such as how greenhouse gases influence the Earth’s climate, how rainbows form, and how unemployment relates to inflation, because of discoveries and theories generated from basic research.

Yet, science also plays an important role in satisfying practical goals. Many life-changing innovations have come about through computer science. The biological and pharmaceutical sciences have vastly improved medical care and public health. Skyscrapers and airplanes wouldn’t be possible without a lot of physics. The contrast with basic research is applied research. Scientific research is applied when it makes use of scientific knowledge to develop some tangible output, such as techniques, software, drugs, and new materials. Often, a core motivation for applied research is generating products for profit; successful research can result in patentable intellectual property.

Basic and applied scientific research can operate synergistically. Scientists aiming at the production of knowledge for its own sake often rely on materials and techniques created by scientists doing applied research, while scientists doing applied research often exploit pure scientific knowledge in order to develop new products. Still, basic and applied research are often carried out by different scientists, often using very different techniques, and sometimes in entirely different fields of science and types of institutions. For example, when Kathleen Montagu and Arvid Carlsson discovered the neurotransmitter dopamine in the human brain in 1957, this was basic research conducted in a hospital laboratory. In contrast, scientists employed by pharmaceutical companies to develop and improve dopamine-related treatments for Parkinson’s disease are doing applied research.

Beyond this distinction between basic and applied research, there is also tremendous variety in topics among the various fields of science. Investigations range from sub-atomic particles like quarks, to DNA, to emotions, consciousness, and mental maladies, to languages, societies, and economic phenomena, and much else besides. It can seem as if there is a science of absolutely everything! Professional sports are a good example; some scientists devote their research to learning how to improve athletic performance. Other topics of scientific research are more abstract. String theory, for example, is highly theoretical physics that posits one-dimensional entities called strings as the basic building block of our universe.

Despite this variety, it’s possible to give a unifying description of the sort of explanatory knowledge sought in science: science provides natural explanations of natural phenomena. This thesis is sometimes called naturalism.

Natural phenomena are objects, events, or processes that are sufficiently uniform to be susceptible to systematic study. Disease epidemics, lunar eclipses, and droughts are all natural phenomena. Inflation, poverty, and unemployment are all phenomena in human societies, but they also count as natural phenomena under this definition. The word phenomenon (plural phenomena) comes from Greek and means “that which appears or is seen.” So, phenomena include all observable occurrences, that is, occurrences detectable with the use of our senses, including the use of our senses aided by technological devices like telescopes that extend their reach. Natural phenomena need to be somewhat uniform to enable systematic study. Occurring in a regular way is needed for scientists’ observations across different times and places to be used to generate knowledge.

Natural explanations of natural phenomena invoke features of the world—that is, other natural phenomena—to account for these observable occurrences. If there’s an epidemic in France or increased employment in Colombia, you might wonder how that came to be. A natural explanation of the epidemic might specify a contagion and a mechanism of transmission, for example, while a natural explanation for the increase in employment might specify private investments in industry and legislative choices made by political parties. These are both natural explanations of natural phenomena.

Science is always naturalistic in what it investigates and how it explains. The meaning of the term natural in the context of the naturalism of science can be better understood by contrasting it with supernatural. Supernatural entities and occurrences may not be governed by discernible regularities, may not be observable at all or not observable by other people, or are just supposed to transcend the range of physical human experience. Because supernatural entities or occurrences are not natural phenomena, science won’t be able to deliver knowledge about them: they would be beyond its explanatory reach. Nor does science appeal to supernatural entities or occurrences to explain natural phenomena. “A miracle caused her to recover from disease” couldn’t possibly be a scientific explanation, even though recovering from a disease is a natural phenomenon.

#### The methods of science

Science’s goal of providing natural explanations of natural phenomena isn’t all that is distinctive about the nature of science. Also significant are science’s methods. One important ingredient of these methods is closely related to the idea of naturalism: science involves empirical investigation, which means using one’s senses to inform one’s beliefs about the world. What scientists see, hear, smell, touch, and so forth can all be used as empirical evidence for or against some attempted natural explanation.

The method of empirical investigation isn’t special to science. We all use our senses in everyday life to learn about the world around us, beginning as infants. You know it’s a clear day because you can see and feel the sun shining through the window. But science has fine-tuned and adapted this method to generate certain kinds of knowledge.

In science, empirical investigation is explicitly used to generate evidence. Science is thus based on evidentialism, the thesis that a belief’s justification is determined by how well it is supported by evidence. For any scientific claim—particularly, any natural explanation of a natural phenomenon—it must be possible to state why that claim should be believed. This evidence ultimately traces back to empirical observations, but empirical evidence often confirms scientific claims only indirectly. We don’t directly see human activity increasing atmospheric CO2, for example; rather, scientists made predictions about changes to the atmosphere, historical trends in global temperature, and more, based on this conjecture; and then they tested those predictions with empirical evidence. So, evidentialism is important to science, but how evidence is gathered and used is not always straightforward.

# 

##### Box 1.1 Is science always empirical? 

Scientists typically use empirical evidence as the basis for knowledge. However, in fields like mathematics, computer science, and economics, some claims are not based on empirical evidence, or at least not directly. The mathematical claim that Log2(1/2) = −1 is not an empirical claim, in the sense that it’s not based on observation. Something similar—perhaps surprisingly—applies to physics too, where it can be very hard to obtain empirical evidence that bears on some phenomena. String theory, for example, is the idea that the fundamental objects in the world are extended, one-dimensional objects called strings. Empirical evidence of these strings cannot be provided by present-day instruments, but string theory has been developed to account for features of fundamental physics that are well confirmed empirically, and string theorists work to find nonempirical evidence that bear on this theory. Sources of nonempirical evidence include the simplicity and unifying and explanatory power of a theory, plus the logical relationships between the theory and other claims well confirmed by the empirical evidence or believed to be self-evidently true. Nonempirical evidence in favor of string theory includes that it can account for well-corrob- orated claims in fundamental physics, that it has been productively applied to a range of scientific problems like black holes and nuclear physics, and that it fits with both quantum mechanics and Einstein’s theories of gravity. So, not all evidence is empirical evidence, and not all scientific research is based on empirical evidence.

Evidentialism in science leads to continual, self‐corrective investigation in which ideas are fine‐tuned or extended in light of new evidence. Significant empirical evidence is needed before some scientific claim, like the claim that human activity is causing global warming, is broadly accepted as settled scientific knowledge. There are many scientific findings that are so well supported by evidence that they seem entirely certain. We know atmospheric CO2 is more than 50% higher now than at any other time in human history, and we know that the last four decades are the warmest on record. We know anthropogenic climate change is occurring. We also know that the Earth orbits around the Sun, that water molecules are composed of two hydrogen atoms and one oxygen atom, and so much more. Still, in principle, scientific claims are never taken to be absolutely beyond any doubt. And very occasionally, continuing investigation even leads widely held or long‐established ideas to be significantly revised.

Karl Popper was a philosopher of science in the early 20th century who took this in‐principle revisability of science to be especially important. Popper developed a principle called falsificationism, which names the thesis that scientific reasoning proceeds by attempting to disprove claims rather than to prove them right—that is, by advancing bold and risky conjectures, and then trying to falsify or refute them. This criterion for science has been very influential among scientists, but it is controversial. One problem is that the relationship between empirical evidence and a scientific theory can be complicated, so that it is sometimes hard to say when the evidence would disprove a theory. A second problem is that incessantly trying to prove central claims false would limit scientific progress. It seems scientists do accept theories and hypotheses that are well supported by evidence, moving on to downstream questions based on those theories and hypotheses.

Two other aspects of falsificationism do seem more plausible. First, any scientific claim should in principle be falsifiable. A claim is falsifiable when it is possible to describe what kind of evidence would, if found, show the claim to be false. This property is required for scientific claims to be subject to empirical evidence; without it, a claim would be unscientific. Notice that true claims can be falsifiable—you can describe what kind of evidence would, if found, disprove a true claim. It’s just that, because the claim is true, you will never actually find such evidence. Even for false claims, scientists may never be in the right circumstances to obtain falsifying evidence. Putting forward falsifiable claims enables science to be based on empirical evidence and to reject ideas when the evidence warrants doing so.

Second, science requires honesty when empirical evidence does indicate a claim is false. When scientists discover apparently falsifying evidence, they should begin to doubt the ideas under investigation. In general, we humans try hard to hold on to our existing beliefs, even when those beliefs are challenged. Scientists are no different. But science’s evidentialism requires scientists to doubt any scientific claims—even claims they had thought were really promising—when empirical evidence suggests they may be wrong. We might call this openness to falsification: any claim should be abandoned when the preponderance of evidence indicates that it’s false.

# 


##### EXERCISES

1.7 Recall: Define natural phenomena and natural explanations, and describe the importance of each to science’s ability to generate trustworthy knowledge.

1.8 Apply: Describe one real example of basic research and one real example of applied research. For each, describe your reasoning in considering it basic or applied research.

1.9 Recall: Describe what it means for science to provide natural explanations of natural phenomena. What are the limitations to the kinds of knowledge science can produce due to this requirement?

1.10 Recall: Define empirical investigation and evidentialism. Describe how they are different from each other and how each is important to science.

1.11 Think: Evaluate how and why the subject matter and methods of science are each relevant to the nature of science.

1.12 Recall: Define falsificationism, falsifiability, and openness to falsification, making sure you are clear about how each is different from the others. For each, say whether it is essential to science and why.

### 1.3 THE INSTITUTION OF SCIENCE

After reading this section, you should be able to:

- Define confirmation bias and give examples of how it works
- Describe how social structure is important to the nature of science
- Describe how social norms for individual scientists and the scientific community are important to the trustworthiness of science

#### Flaws in human reasoning

Empirical investigation is a basic aspect of human existence and so not special to science. Why, then, is science needed to give us knowledge about the world, beyond just our ordinary human powers of observation? Just as we humans are predisposed to investigate our world using our senses from our first days of infancy, we are also predisposed to some serious flaws in how we gather evidence and how we reason. Science is the best route to knowledge about the world in part because it incorporates ways to protect against those flaws in reasoning.

It is normal for people to favor some ideas over others. We can then use our experiences in the world, investigation of existing knowledge, and critical thinking to ensure that the ideas we favor are, in fact, good ideas. The problem is, we also seek out and interpret information in ways that fit with our favored ideas, and we avoid information that challenges those ideas. This is a well-established feature of human reasoning called confirmation bias

Confirmation bias: the tendency to look for, interpret, and recall evidence in ways that confirm and do not challenge our existing beliefs.

Imagine someone has just brought her friends to a restaurant she’s selected. When she asks her friends if they like the restaurant, she may say, “It’s good, isn’t it?” Framing the question in this way promotes agreement with the judgment she already has of the restaurant—it’s a way of looking for confirming evidence. Similarly, someone who’s skeptical about climate change may perform an internet search for the phrase evidence against climate change to learn more, or they may focus on what critics say and ignore what climate scientists say. Someone concerned about genetically modified crops is more likely to make time to read an article entitled “Dangers of Genetic Modification” than an article titled “Genetic Modification Boosts Soy and Corn Performance.” These are ways of seeking evidence that confirms one’s existing ideas rather than challenging those ideas. We are also prone to interpreting evidence as supporting our existing ideas. In one study, people who were in favor of and opposed to the death penalty both read the same discussion of the death penalty. People on each side of the issue interpreted the discussion entirely differently; each side thought it supported their own view.

Confirmation bias can involve looking only for evidence that supports your existing beliefs, cherry-picking which research to believe and which to ignore, holding evidence against your views to a higher standard than evidence in favor of your views, and more easily remembering supporting evidence than contrary evidence.

We all do this; it doesn’t matter what views about the world we have, what political views we have, whether we’ve graduated from college, or whether we have been trained as scientists. In fact, some evidence suggests that confirmation bias worsens with increased education. Although everyone is prone to confirmation bias, the effect tends to be stronger for politically or emotionally charged issues, such as vaccinations, climate change, and health.

Scientists’ expectations or desires about the results of scientific research can lead to incorrect findings. One way in which this can happen is through the observer-expectancy effect, when a scientist’s expectations lead them (perhaps, unconsciously) to influence the behavior of experimental subjects. A famous example of this involved Clever Hans, a horse who was thought to have sophisticated abilities including performing arithmetic calculations. Hans’s owner, Wilhelm von Osten, was a mathematics teacher, horse trainer, and phrenologist. (Phrenology is the now-discredited study of the shape of the skull as an indicator of personality and mental abilities.) Hans was trained to recognize numerals from 1 to 9 and to tap his hooves to indicate which ones he recognized. Eventually, van Osten had Hans tapping out correct answers to questions like: what’s the number of 4s in 16?

In 1891, van Osten traveled around Germany to exhibit his amazing horse. There was such fanfare that the famous psychologist Carl Stumpf appointed a special commission to provide critical scrutiny. In 1904, the commission concluded that Hans’s abilities were legitimate. The horse was able to answer questions from simple arithmetic to square roots, fractions and decimals, units of time, musical scales, and the value of coins. Hans could even respond accurately when van Osten wasn’t present.

 

  

FIGURE 1.6
The commission was wrong. Stumpf’s pupil, Oskar Pfungst, demonstrated that Clever Hans was not performing sophisticated mental calculations. Pfungst used blinders to vary whether Hans could see the questioner, and he varied who played the role of questioner. Hans produced the correct answer even when van Osten himself did not ask the questions, but Hans’s performance fell apart when the questioner did not know the answer or when the horse was asked the question from behind a screen. When the visibility of spectators and questioners was masked, Hans’s ability to produce correct answers fell dramatically from 89% to 6%. Further observations confirmed that Hans was being unwittingly cued by his human audience. Questioners’ body language and facial expressions became taut as his tapping approached the correct answer, and then more relaxed upon the final tap; this change prompted Hans to stop tapping.

#### Science as a social enterprise

Like van Osten and all the other people who asked questions of Clever Hans, our expectations can affect how matters play out, even when we don’t intend this to happen. This possibility makes it hard for people—including scientists—to reason their way to the right answers. For this reason, one element of science’s great success in generating knowledge about our world is its institutional features that protect against or counteract the basic flaws in human reasoning.

Scientific research requires communities of many people working together. Teams of scientists work together on research projects; it is common for research publications to have multiple authors. Scientists also regularly make use of techniques, data, or ideas developed by other scientists. And all new scientific research is based in part on the findings of previous scientists. Such collaboration is essential to the development and refinement of scientific knowledge: no one scientist can produce scientific knowledge on their own.

We have seen how science is based on empirical investigation. And yet, empirical evidence bearing on scientific claims often doesn’t come directly from an individual scientist’s own observations. Instead, an important source of evidence is other scientists’ reports of their observations as detailed in research publications. Keeling and his collaborators first measured the increasing concentration of atmospheric CO2 depicted in the Keeling curve, but many more climate scientists later made use of those data in their own research. Scientific collaboration thus greatly amplifies the reach of empirical investigation.

Collaboration and competition among scientists also help detect and correct flaws in human reasoning, giving rise to the self-corrective process of refining scientific knowledge. Collaboration among scientists creates opportunities for people with other viewpoints to analyze the evidence and ideas from their own perspectives and methodologies. While new research projects are based on the findings of previous scientists, they are also opportunities to refine or challenge those earlier findings. Competition among scientists—to make a discovery before anyone else, to get their research projects funded, and to show that an idea is better supported by the evidence than an opposing idea—also spurs reexamination of ideas that other scientists might take for granted. Collaboration and competition in science should combine to increase the trustworthiness of scientific knowledge. If a large and diverse group of scientists agree about some finding, we should be more confident that it is legitimate.

This raises another point about the importance of science as a social enterprise. To adequately protect against individual flaws in reasoning, scientific communities need to be diverse in order to provide satisfactory interpretations of the available evidence, as well as to formulate and test a variety of ideas, including perspectives from different nationalities, races and ethnicities, gender identities, cultures, and more. This kind of diversity benefits science by guarding against any individual biases and personal values.

#### Social norms of science

Because the institutional structure of science is essential to its ability to generate knowledge, science has important social norms—rules or guidelines that scientific activities should adhere to and against which they are evaluated. One set of norms applies to the behavior of scientists. Scientists are obligated to have scientific integrity, which involves expectations of honesty and avoiding improper influence by others. Norms of scientific integrity are so important that their violation is severely punished by the scientific community, such as with bans from publishing in scientific journals or even loss of one’s job as a scientist.

Examples of scientific dishonesty include plagiarism and fabricating data. Plagiarism is the fraudulent theft of someone else’s ideas, scientific results, or words, which are subsequently presented as one’s own work without giving proper credit. Fabricating data occurs when, rather than collecting empirical evidence, scientists create records of observations they didn’t actually make in order to use them as evidence to support a desired conclusion.

In 2011, a Dutch social psychologist, Diederik Stapel, published a widely read study in *Science*, one of the most prestigious scientific journals, presenting evidence that trash-filled environments lead people to be more racist. But rather than collecting actual data, Stapel just made it up. When this was discovered, his reputation immediately collapsed. All his other publications were scrutinized, and approximately 60 other papers were retracted for data fabrication. Other scientists have also been forced out of science after their ethics violations were discovered, such as the Seoul National stem-cell researcher Hwang Woo-suk and the Harvard evolutionary biologist Marc Hauser. Some science journalists have helped increase awareness of issues like plagiarism and data fabrication by running blogs such as Retraction Watch*.

##### Box 1.2 Merton’s social norms of science

Social norms are informal rules that govern behavior in groups and societies. American sociologist of science Robert Merton specified four social norms that govern scientists’ attitudes and behaviors towards each other and their research, thereby enhancing the moral integrity of scientific communities and supporting the expansion of scientific knowledge.

1. Communism: scientific findings and methods are common goods owned by all and should be shared freely.
2. Universalism: scientific work should be evaluated based on impersonal criteria like coherence with other bodies of knowledge and empirical confirmation. In other words, scientific work should be independent of the socio-political or personal status of the scientists involved.
3. Disinterestedness: scientific work should not be aimed at personal gain.
4. Skepticism: scientific work should be scrutinized critically and transparently by relevant scientific communities before being accepted.

These four norms relate to how we are discussing collaboration and competition and social norms of science in this section.

Scientists also are expected to avoid conflicts of interest: financial or personal gains that have the potential to inappropriately influence scientific research, results, or publication. Conflicts of interest, especially when research is funded by organizations with a financial stake in the findings, can result in researchers intentionally or unintentionally altering what research they conduct, their findings, or what they report in publications. Thus, scientists are obligated to disclose any potential conflicts of interests they may have. The existence of potential conflicts of interest does not necessarily lead to bias, but transparency about them allows others to evaluate the possibility of improper influence.

Here’s an important example. Clair Patterson, a geochemist at Cal Tech in California, led the campaign to remove lead from gasoline in the 1960s and 1970s. Leaded gasoline contained lead tetraethyl, which is extremely toxic to human and non-human animals alike. Because the campaign against leaded gasoline threatened their profits, the fossil fuel industry—particularly the Ethyl Corporation—fought bitterly against Patterson’s research. Among their tactics was to pay another scientist, Robert Kehoe, to attest to the safety of leaded gasoline. Eventually, his dishonesty was revealed, and honest science carried the day. Lead was removed from gasoline, but only after generations of people in many countries around the world suffered from elevated lead levels in their blood, which leads to brain damage, chronic illness, birth defects, and increased death rates. Urban areas around the world still have elevated levels of lead in their soil from this period.

Another important form of protection against flaws in reasoning involves social norms and incentives governing the scientific community as a whole. One such norm is trust. Scientists’ trust in one another is the glue of scientific communities. For example, collaborative projects on climate change involve scientists with a range of different expertise, including climatologists, ecologists, physicists, statisticians, and economists. None of these scientists alone possesses comprehensive expertise to collect, analyze, and interpret the full range of evidence that bears on our understanding of anthropogenic climate change. These scientists must rely on each other and must trust one another’s scientific work.

Scientists also are expected to critically evaluate one another’s work by deciding whether results warrant publication, evaluating the strengths and weaknesses of research findings, and choosing whether and how to respond to published findings. One important form of critical evaluation is attempting to replicate others’ research. In replication, an experiment or study is performed again (often by different scientists) to determine whether the same findings obtain. If successful, the replicated results further confirm the ideas under investigation. If the results are not replicated, this raises doubts about the original work, such as the possibility that something unexpected was instead responsible for the finding. This is one way to think about what happened with continued evaluation of Clever Hans’s apparent math skills.

##### EXERCISES

1.13 Recall: Describe three types of influence of confirmation bias, and define observer-expectancy effect.

1.14 Recall: Describe how social structure is important to science, listing at least three ways in which it’s important that are discussed in this section.

1.15 Think: What does it mean to say scientific knowledge is produced by scientific communities instead of individuals? In light of your answer, explain why scientific communities need to be diverse across a range of characteristics.

1.16 Recall: Describe how social norms for individual scientists and for the scientific community are both important to the trustworthiness of science.

1.17 Recall: Describe three kinds of scientific fraud or scientific misconduct, giving an example of each.

1.18 Think:  How should trust and criticism be balanced in scientific communities, and why is this important to science? How should trust and skepticism of the public toward scientific findings be balanced, and why is this important for the public’s relationship to science?

### 1.4 DEFINING SCIENCE

After reading this section, you should be able to:

- Describe why it is difficult to define science and distinguish it from other pursuits
- Define pseudoscience and give examples
- Analyze whether a claim or topic of research counts as scientific using the checklist for science

#### Pseudoscience and the tricky work of defining science

Science is unrivaled in its ability to generate knowledge about our world. It has earned authority and legitimacy from centuries of successes and improvements that go beyond the expertise of any individual scientist or investigation. Many people and organizations are eager to lay claim to scientific legitimacy, and it’s sometimes difficult to discern whether they are entitled to it.

This is not a new problem. Karl Popper, the 20th-century philosopher encountered in the previous section, argued that some investigations thought to be scientific were instead pseudoscience, which means false, fake, or bogus science. Such nonscientific activities are designed to look enough like science to deceive people into thinking they have scientific legitimacy. A standard example of pseudoscience is astrology (not to be confused with astronomy, which is the scientific field that studies celestial objects in space). Astrology is commonly associated with horoscopes, which use zodiac signs to

make predictions about future events, relationships, destiny, and the like. Tests of astrological ideas have generated lots of empirical evidence against them, and advocates of astrology rarely engage in systematic attempts to empirically test their claims—claims that haven’t changed much since astrology peaked in popularity centuries ago. And yet,

even though astrology is bunk, it is still promoted as a legitimate source of knowledge. Massive numbers of astrologers, clairvoyants, psychics, and other charlatans take in billions of dollars every year for their consultations.

If astrology is pursued purely for entertainment, without pretense of generating knowledge or misleading anyone into thinking it’s doing so, then perhaps there’s no grounds for complaint. The central problem with pseudoscience is the deceptive attempt to appear scientific and, thus, to have the ability to generate scientific knowledge when it doesn’t.

In many cases, the specific intent of the advocates of pseudoscientific theories is to appeal to science’s self-correcting nature to call into doubt scientific findings supported by enough evidence to be considered established scientific knowledge. Anti-vaccination advocacy is like this. One popular anti-vaccination argument is that childhood vaccines increase the risk of autism. Extensive testing has demonstrated clearly and conclusively that there is no causal connection between vaccination regimes and the incidence of disorders like autism. This conclusion is scientific: it is based on evidence, is open to falsification, and would be rejected if sufficient evidence against it were found. But existing research is so extensive and compelling that the possibility of newfound disconfirming evidence is virtually nonexistent. Nonetheless, propaganda outlets and anti-vaccination groups peddle misinformation, trying to induce doubt by misconstruing the relevant research and with stories of children who were diagnosed with autism after vaccination. (This does regularly happen, for the simple reason that vaccination regimes and many symptoms of autism both tend to emerge in the same stage of early childhood.)

Another example of pseudoscience is creationism and intelligent design, which are attempts to explain the characteristics of living organisms by appeal to supernatural events, inspired by religious teachings. For close to a century now, “creation science” and later intelligent design were effectively advocated in the United States as alternative scientific theories to evolutionary theory, including publication of glossy textbooks and even a creationism-based alternative natural history museum. The basic thought behind both creationism and intelligent design is that living organisms are so complex that they couldn’t possibly have come about by evolution. This idea is not supported by evidence; it is actually debunked by the evidence, which, at the same time, clearly indicates the workings and effects of biological evolution. Notice that this does not imply that evolutionary theory has proven that there is no supernatural involvement; that would be beyond the purview of science. Rather, it’s just that the natural explanation of evolution successfully accounts for the natural phenomenon of complex lifeforms.

Healthcare is a common target for pseudoscience. Besides anti-vaccination advocacy, another example is conversion therapy, which is intervention intended to change a person’s sexual orientation. Conversion therapy pretends to be like psychological therapy and is still practiced in some circles, but it has been thoroughly shown to be ineffective and psychologically harmful. Other instances of pseudoscience might be less clear‐cut. Naturopathy is an approach to healthcare that emphasizes thinking about conditions of the whole body and looking to natural, folk, or indigenous remedies for health concerns. This approach might have some value when medical research is focused on precisely targeted medical intervention and when pharmaceutical drugs (but not herbal supplements) are subject to rigorous testing and regulation. Further, naturopathy training programs and licensure exist in some places. Nonetheless, some approaches endorsed in naturopathic medicine have been disproven with evidence. It can be difficult to judge whether naturopathy should be dismissed entirely as pseudoscience or might be rendered more legitimately science‐based with continued development or integration into mainstream medical practices.

Here’s another example of pseudoscience that comes from inside science. Naomi Oreskes and Erik Conway’s book, *Merchants of Doubt*, which also inspired a film of the same name, details how one group of well‐respected scientists in the United States provided legal testimony and spurred research that misled the public and enabled corporations to dodge responsibility for the health and environmental catastrophes of cigarettes, acid rain, climate change, and the toxin DDT. Apparently inspired by their political views, these scientists misused the authority of science to delay acceptance of established scientific knowledge that was inconvenient for powerful corporations.

As these examples reveal, discerning science from pseudoscience can be essential for health and safety, but doing so can be very difficult. Where is the line between harmless entertainment and pernicious fake knowledge, or between a new, underexplored alternative idea and a cynical attempt to inspire doubt in well‐established scientific knowledge? It seems we cannot just rely on whatever individual scientists tell us to believe. And some features of the nature of science described in the previous section might be shared by varieties of pseudoscience.

#### A checklist for science

We have discussed many distinctive features of the nature of science. These include aiming to generate knowledge, naturalism, empirical investigation, evidentialism, falsifiability and openness to falsification, and characteristic institutional structures. Some people have advocated one or another of these as the best way to define science, as with Popper’s falsificationism. Others have suggested these different features are together the hallmark features of science. We think that is the most promising approach. So, we define science as the inclusive social project of developing natural explanations for natural phenomena. These explanations are tested against empirical evidence and must be subject to open critique, refinement, and rejection.

The characterization of science developed here can provide a kind of checklist for assessing to what extent some activity qualifies as scientific, as pictured in Table 1.1. Consider how this characterization of science relates to our earlier example of climate change. First, science aims to generate knowledge. Climate science aims to generate knowledge of the extent and ways in which human activities are transforming Earth’s climate and of the impacts this transformation will have on weather systems, ecosystems, and human societies. Because science is naturalistic, it is limited to natural explanations of natural phenomena. The warming of the Earth’s climate is a natural phenomenon, subject to empirical investigation. The proposed natural explanation for this phenomenon is that human activities have generated unprecedented levels of greenhouse gases and the warming effect of those gases.

##### Table 1.1 Checklist of hallmark features of science 

✓ Aims to generate knowledge (knowledge-oriented)

✓ Provides natural explanations of natural phenomena (naturalism)

✓ Advances claims that can be tested against observational evidence (empiricism)

✓ Updates claims based on available evidence (evidentialism)

✓ Abandons any idea that has been thoroughly refuted (openness to falsification)

✓ Involves the broader scientific community (social and institutional structure)

All scientific claims must be testable, or falsifiable, with the use of empirical evidence, and claims must be supported by significant evidence to be accepted (or disconfirmed by sufficient evidence to be discarded). The claims that the concentration of atmospheric greenhouse gases has dramatically increased since the Industrial Revolution and that the last four decades are the warmest on record (for example) are both testable. We can describe the kinds of evidence that would lead us to reject these claims, but scientists have not found that evidence despite extensive investigation. These claims have not been falsified; they are accepted by the scientific community only because there is strong evidence in their favor.

As new evidence becomes available, scientific claims are corroborated, revised, corrected, or rejected through the collaborative work of researchers embedded in the social and institutional structures of science. Climate change research involves numerous scientists utilizing techniques from different fields of science, and our understanding of climate change and predictions of its effects are constantly fine-tuned. The basic idea of anthropogenic climate change has persisted through all of this—indeed has become more broadly held—because no challenges to the idea or to the research supporting it have been successful. Multiple studies published in peer-reviewed scientific journals independently confirm that glacier retreat and climate-warming trends over the past century are due to human activities, and most of the leading scientific organizations worldwide endorse this conclusion.

Here’s an obvious contrast with science: jazz. Jazz artists do not collect measurements or other similar forms of evidence to test hypotheses about the value of a piece of work, and disagreements about the value of, say, Ella Fitzgerald’s Over the Rainbow cannot be settled by running experiments, conducting empirical studies, or developing models. Unlike scientists, jazz musicians do not aim to find natural explanations of features of the natural world with their practices.

Now consider astrology, a canonical example of pseudoscience introduced previously. The primary claims made in astrology, such as horoscope predictions, are not designed to be falsifiable; in fact, many are specifically designed to be unfalsifiable. They are vague in ways that allow many different interpretations, and so, for any interpretation that is wrong, another can be offered in its place. Further, the systems of horoscopes used by astrologists are inconsistent with well-understood basic theories of biology, physics, and psychology. This violates the expectation of the collaborative exchange of ideas among scientists. Astrology is not science.

Astrology may be a harmless fad, with negative consequences largely confined to misspent leisure time and money. Other pseudoscientific projects are much more dangerous. Denials of anthropogenic climate change—despite overwhelming evidence—have contributed to a lack of political will to address the climate crisis, a failure that is beginning to lead to catastrophic consequences. The campaign of denialism described in Merchants of Doubt involved well-established scientists introducing doubt and distraction about topics beyond their scientific expertise to influence political outcomes. Their denial of climate change was not designed to be falsifiable: no amount of evidence would change their mind. Some climate change deniers have even rejected the idea that science is a trustworthy source of knowledge in order to hold fast to their rejection of climate change.

##### Box 1.3 Evaluating scientific expertise

Imagine you are asked to vote on a policy about banning cannabis. The potential ban appeals to research showing that cannabis causes schizophrenia. Suppose you do not know much about cannabinoids and their psychiatric effects. Where would you search for relevant, trustworthy information? Without expertise in the relevant science, it can be difficult to evaluate scientific research. You might find on social media two alleged experts who disagree about the causal claim. How should you decide who is the most credible?

The most straightforward way to evaluate scientific claims is to assess the quality of the arguments presented by the experts. But this can be difficult, as scientific information can be technical and hard to understand for non-experts. For this reason, it is also important to consider the credentials and reputation of the alleged experts, including the relevance of their qualifications and their accomplishments in their field, and look out for any possible sources of conflict of interest or bias. And, because science is a collaborative enterprise, try to learn what the consensus or near-consensus is in the relevant area of research. This is more important than what any individual scientist thinks. So, you should also beware the maverick scientist who claims to have refuted the consensus in the field!

#### Science’s limitations

While science is our best route to knowledge about the world around us and to developing innovations based on that knowledge, it is also important to recognize what it doesn’t do.

Scientists try to gain knowledge, that is, to develop natural explanations of natural phenomena. The list of the phenomena investigated in science is long; in principle, it includes everything in our universe. But there are some important limitations to the scope of science. Science doesn’t replace or limit nonscientific intellectual pursuits, like literature, music, and painting—or politics for that matter. Basing our scientific knowledge about climate change on fluctuating political agendas would be a mistake. But, when it comes to addressing climate change with policy interventions, debating which steps are politically feasible and desirable is fair game for politicians. Of course, knowledge from climate science and other scientific fields such as economics, sociology, and psychology should be considered in these deliberations.

Scientific knowledge differs from theological doctrine and religious practice, too. Unlike religious practitioners, scientists attempt to explain things without appeal to supernatural entities or influences, such as deities or miracles, or to literary allegories or culturally significant myths. Furthermore, faith has a central place in many religions, while it should have none in science. Of course, one can be religious in myriad ways, and many people—scientists included—are both religious and believers in scientific knowledge. People disagree about the role religion should play in our society, but whatever role that might be, science is not designed to occupy it.

Scientism is a derogatory term for an excessive belief in science as a solution to every possible problem—including philosophical problems about the meaning of life and our place in the universe. Like pseudoscience, scientism expresses a kind of intellectual arrogance, where one gives excessive deference to science as the sole source of knowledge we might acquire and the only way to find correct answers to any question of human concern we might ask. In public debates, symptoms of scientism include generic slogans like “because science says so” and “science doesn’t care what you believe,” which are ironically designed to halt discussion rather than to promote it. Also included are quick dismissals of other humanistic endeavors and disciplines like history and philosophy as being “anti-science.” We think it is important to distinguish the thought that science is a uniquely trustworthy source of a certain kind of knowledge from ideas that might sound similar, such as that professional science is the only way to have knowledge of any kind or should be the basis of one’s entire worldview.

##### EXERCISES

1.19 Recall: Define the term pseudoscience and give two examples of pseudoscience discussed in the section. For each, describe why it counts as pseudoscience.

1.20 Apply: Choose one example of pseudoscience discussed in this section and evaluate it using the checklist of science. Describe how it is similar to science and how it is different. Can you identify features of the example you’ve chosen that seem to be intended to appear more like science than they are?

1.21 Think: What’s distinctive about science, in comparison to activities like literature, music, and art, as a source of knowledge about the world? Do you think there are any important differences between scientific and artistic ways of gaining knowledge? Support your answers with justification.

1.22 Think: Why must science be limited to the study of natural phenomena? Why must it give only natural explanations? Can you think of any scientific projects that don’t seem to satisfy these requirements? If so, describe one such project, making clear why you think it might not be naturalistic. If not, describe a nonscientific project that seems to be non-naturalistic and say why.

1.23 Apply: Search the internet (news websites, magazines, blogs, etc.) for a story about a finding purporting to be based on science, and answer the following questions about it. Include a link to your source when submitting your response. (Alternatively, your instructor may provide you with a story to analyze.)

Answer the following questions about the story:

1. a. What is the source? Is the person making the claims someone with genuine expertise in what they’re claiming?
2. b. Does it seem like there’s any conflict of interest? Why or why not?
3. c. Does the claim involve vague or ambiguous language?
4. d. Do the claims fit with other well-confirmed scientific theories?
5. e. What is the evidence cited in support of the claim?
6. f. Does this describe good science? Why or why not?

1.24 Recall: Define scientism and describe why it is a problem. Give an example of legitimate reasoning leading to knowledge that occurs outside of professional science.

##### FURTHER READING

For more on political influence used to cast doubt on climate change research and other scientific findings, see Oreskes, N., & Conway, E. (2010). Merchants of doubt. Bloomsbury.

For an accessible online resource about the nature of science and scientific processes, see the website Understanding science. https://undsci.berkeley.edu

For more on how social norms and social structures influence scientific inquiry, see Merton, R. K. (1942). Science and technology in a democratic order. Journal of Legal and Political Sociology, 1, 115–126. Reprinted with the title “The normative structure of science” in Merton, R. K. (1973). The sociology of science: Theoretical and empirical investigations. University of Chicago Press.

Wilson, C., & Weisberg, M. (Eds.). (2018). *Scientific collaboration and collective knowledge*. Oxford University Press.

For more on the demarcation between science and pseudoscience, see Pigliucci, M., & Boudry, M. (Eds.). (2013). *Philosophy of pseudoscience: Reconsidering the demarcation problem*. University of Chicago Press.


## CHAPTER 2 How science pursues its aims

### 2.1 PUBLIC HEALTH AND HOW VALUES SHAPE SCIENCE

After reading this section, you should be able to:

- Define biological sex and gender and say how each might be relevant to health outcomes
- Describe the germ theory of disease and social determinates of health, saying what is important about each focus in health research
- Describe how social values influence scientific research aims

#### Covid-19 and social determinates of disease

Covid‐19 was declared to be a global pandemic by the World Health Organization in March of 2020. So early in the pandemic, little was known about the illness. Scientists very quickly identified the virus responsible, dubbed SARS‐CoV‐2. But how it was transmitted, what influenced people’s vulnerability to the illness, and how the pan‐demic would progress remained a mystery for some time.

Studies based on early reports out of Wuhan, China, concluded that men were more than twice as likely as women to die from Covid‐19. Other studies corroborated that men were much more likely to be admitted to intensive care units and to die from the illness. Early investigations of this phenomenon tended to target biological sex as the relevant factor, focusing on immune system differences between males and females due to hormonal balance and genes on the X and Y chromosomes. One study proposed that a “sex‐based approach” to treating Covid‐19 should be developed, with different medical support for male and female patients.

Biological sex includes the categories male, female, and intersex (perhaps with multiple varieties), which in humans is determined by combinations of X and Y chromosomes, hormones, reproductive organs, and other physical traits. The distinct but related term gender includes behaviors, social roles, appearances, and identities of individuals traditionally associated with the expression of masculinity, femininity, or non‐binary features. A broader range of gender identities are acknowledged today, and some challenge the very idea of gender categories. Here, what’s relevant are the behaviors and social roles related to genders traditionally associated with biological sex categories—that is, being a man or being a woman.

Biological sex and gender are distinct variables in health research, but which is relevant can be difficult to discern in some cases. Although biological sex is physiological and gender is behavioral and social, gender can still have physiological effects, including health effects. For instance, if men are more likely to continue to work outside the home during a pandemic stay-at-home order due to gender differences across occupations (a social role) or more likely to resist health recommendations like masking (a behavioral tendency), then this could result in increased susceptibility to Covid-19. If men are more likely to neglect preventive healthcare and treatment of health conditions (a behavioral tendency), then this could result in worse outcomes when they contract Covid-19. If it’s unknown whether sex or gender differences are responsible for some health disparity, researchers might just refer to “sex/gender.”

In light of the emerging focus on different Covid outcomes for men and women, a group of scientists and science scholars at Harvard University’s GenderSci Lab began to comprehensively track sex/gender disparities in Covid-19 outcomes across the United States. These researchers found that the sex/gender differences in Covid outcomes changed over time, across different states, and in different social contexts such as urban and rural areas. This pattern suggested it was not biological differences between sexes but social/behavioral differences between men and women that were primarily responsible for the observed variation in Covid outcomes. This is because typical behaviors and social roles vary across locations and incidental circumstances in a way that the sex differences between males and females (chromosomes, hormones, and reproductive organs) do not. On average and in ways that vary across time and place, men and women tend to have different careers, different likelihoods of smoking cigarettes, different relationships to preventive care and health precautions, and more—all of which can influence one’s susceptibility to Covid-19 and its severity if one does contract it.

And so, what had initially appeared to be a physiological difference in susceptibility to Covid-19 related to biological sex was revealed by further research to be instead—at least in large part—a social difference in exposure and vulnerability related to gender.

This difference is important for researchers to understand. In health research, biological factors like genes and hormones associated with biological sex tend to receive more attention than social factors like lifestyle choices and healthcare access. This can lead healthcare to focus too much on biological factors and neglect social factors. Recall, for example, the study mentioned earlier that suggested the need for different medical treatments for Covid-19 in men and women due to presumed immune system differences. That study did not consider whether social factors might instead be responsible for the sex/gender disparity in Covid-19. This focus on biological sex in health research and healthcare and the neglect of social factors related to gender can in turn reinforce stereotypes about differences between men and women tracing back to biological sex differences. It’s hard to learn about the significance of social factors related to gender if they aren’t investigated in research.

Note that similar points apply to health impacts of race. Health research has tended to emphasize physiological differences related on average to race, such as prevalence of certain genes or genetic conditions or susceptibility to conditions like heart disease or osteoporosis. But race is a social category, associated with social factors that have clear implications for health, such as average socioeconomic status, access to health‐care, exposure to racism and other sources of stress, and exposure to environmental hazards (like proximity of a neighborhood to polluting industries). As with gender and biological sex, if health research does not attend to race as a social factor, it risks essentializing race as only a biological factor. In the Covid‐19 pandemic, racial and ethnic minorities in the United States suffered higher rates of infection and death from Covid‐19 due in large part to social factors like living conditions, type of work, and access to healthcare.

There is a broader point behind these stories about Covid‐19’s variable impact by gender and race. Historically, health research and health campaigns largely focused on social influences on health: better sanitation, less crowded housing, safer work conditions, and neighborhood improvements. In the late 19th century, microbes were discovered: bacteria, viruses, and fungi so tiny they are invisible were found to be the source of many diseases. The germ theory of disease, the theory that such microbes, or “germs,” cause illnesses, won out over the miasma theory, which held that illnesses are caused by bad air from rotting matter and other bad sources. This led health research and campaigns to narrow their focus to preventing the transmission of germs and infection from germs, as with antibiotics and vaccination.

Yet there was also something right about the earlier health focus on living conditions. As we’ve illustrated with Covid‐19, various social factors are relevant to disease susceptibility and severity: education, income, housing conditions and exposure to pollution, pervasive stress from racism, access to healthy food and activities, and more. These are collectively referred to as social determinants of health.

Over the past century or so, a focus on interventions related to germs, like avoiding and slowing disease transmission and developing vaccines and antibiotics, has predominated over research and interventions related to the social determinates of health. 

#### Social values and the aims of health research

 The health sciences include a variety of fields, two of which are medicine and public health. Medical research and practice focus on preventative and treatment options for individuals with, or at risk of, particular health conditions. Medicine primarily draws on the biological sciences, as reflected in the common term *biomedical science*. In contrast, public health research and practice focus on the overall health of populations, primarily in disease prevention, drawing from research in social sciences, psychology, and environmental science.

The field of public health is where social determinates of health are most likely to be investigated. But even public health has been shaped by the germ theory of disease to focus especially on disease transmission, to the extent that social determinates of health have been pushed to the side. Social determinates of health, like housing conditions, exposure to pollution, access to healthy food, and more, can be less obvious in their importance and can be challenging to address. But, for many diseases, addressing social determinates of health is crucial to supporting a healthier population. This is especially so for so-called lifestyle diseases that aren’t caused by pathogens directly but rather things like diet, exercise, smoking, and drug and alcohol use. Examples of lifestyle diseases are heart disease, stroke, type II diabetes, and some forms of cancer. In many nations, lifestyle diseases are among the most common causes of death.

Focusing too much on the role of germs in diseases—a medical view of disease—can make for a sicker population by leading to the neglect and misunderstanding of the social determinates of communicable diseases, like Covid-19, and to the relative neglect of lifestyle diseases. In some articles in the popular magazine *The Atlantic*, science writer Ed Yong has suggested that the Covid-19 pandemic, including its inequities along race and gender lines, is an opportunity to refocus public health on the social determinates of disease.



##### Table 2.1 **The contrasting features of medicine versus public health**

|                   | Medicine                                                     | Public Health                                                |
| ----------------- | ------------------------------------------------------------ | ------------------------------------------------------------ |
| Target            | Individuals                                                  | Whole populations                                            |
| Aim               | Prevent and treat particular health conditions               | Improve overall community health, including disease prevention |
| Relevant Sciences | Biological sciences, pharmacology, bioinformatics/bioengineering | Sociology, environmental sciences                            |



Covid‐19 is a good illustration of how scientific research could focus on many different but related topics. Scientific research on Covid‐19 ranges from the SARS‐CoV‐2 virus’s structure and impact on specific cells; to the epidemiology of how quickly the disease would spread, how it would impact the economy, and how spread would change with different public health actions, like stay‐at‐home orders; to the influences of age, class, gender, and race, as described earlier; and more. And, of course, Covid‐19 is just one threat to public health. There are also many other health topics in need of study, in general and even in how the pandemic influenced them. For the pandemic, these include mental health and educational impacts of stay‐at‐home orders and school closures; the effects of postponed care on health conditions like heart disease, cancer, and diabetes; how social distancing influenced the transmission of seasonal illnesses like the flu; and more. And this only scratches the surface of the range of potential health research topics in general, of course.

So, which of these many research topics should be prioritized in health research? And should the focus be on medical treatment, preventative and population health, or something else? The answers to these questions are influenced by social values of the communities that influence science. Social values are group priorities and moral ideas accepted in a community. Social values provide a shared background orientation that can influence decisions and activities, including in scientific research. But social values are not universally shared: different communities might have other social values or differently prioritize some of the same social values.

Here’s an example related to our case study of how Covid‐19 impacts different genders. Harvard University’s GenderSci Lab, the group that tracked sex and gender disparities in Covid‐19 outcomes, describes itself on its website as “dedicated to generating feminist concepts, methods and theories for scientific research on sex and gender.” This group brings their shared feminist values to their biomedical research, including bringing a critical perspective to research that may emphasize sex differences more than the data warrant. This perspective leads to research that can shed light on how gender influences health outcomes.

As this example shows, social values influence which research topics are priorities in health research. Other examples include whether attention should focus more on medical options for difficult‐to‐treat diseases or on broad health outcomes in the overall population, including those with less access to medical care, and whether attention should focus more on theoretical knowledge of some disease, be it Covid‐19 or cancer, or prevention of the most cases possible. Different orientations on these and other questions will shift which research topics are prioritized and what the focus is in researching any given topic. This helps make sense of Ed Yong’s suggestion that attention to social injustice and health inequity arising out of Covid‐19 may motivate additional investment in public health research and a greater focus on the social determinates of health within the field of public health.

The influence of social values on research topics and aims is not special to health science but is general across science. Incredibly important questions to ask to understand science, then, are these: What is the specific research topic and aim? And what are the reasons for prioritizing those topics and aims over others?

In Chapter 1, we suggested that science is ultimately structured to pursue knowledge about our world: natural explanations of natural phenomena. Here, we’ve seen how that general aim can vary widely in the specifics, and social values help drive which specific aims and topics are prioritized over others. The remainder of this chapter is devoted to an overview of the methods science employs to pursue these aims and how the institution of science developed to support them.

##### EXERCISES

2.1 Recall: Define biological sex and gender and describe how each was thought to be relevant to Covid-19 susceptibility and severity.

2.2 Think: Consider how sex/gender has both physiological elements (biological sex) as well as behavioral and social elements (gender).

​	(a) Why is it important to consider these as distinct variables in health research?

​	(b) Why can these influences be difficult to untangle?

​	(c) Why do you think biological sex tends to be focused on more in health outcomes than gender is?

2.3 Recall: Define germ theory of disease and social determinants of disease, then

​	(a) indicate how each relates to medicine and to public health, and

​	(b) describe what is correct about each.

2.4 Apply: List at least six social factors that might be relevant to health outcomes. For each, describe the potential relevance and whether it could be changed to improve public health in general and/or the health of specific populations.

2.5 Think: What are some risks of health research focusing only on medicine (neglecting public health)? What are some risks of health research focusing only on public health (neglecting medicine)?

1. Think: Define social values, give at least three examples, and say in your own words how social values can influence research aims in science.

### 2.2 VARIETY OF SCIENTIFIC AIMS AND METHODS

After reading this section, you should be able to:

- Identify why there is not a single, unified scientific method
- Explain how different scientific aims and circumstances influence scientific methods
- Characterize the roles of the following in science: experiments and observational studies, modeling, scientific arguments, statistical reasoning, and theorizing

---

### No simple scientific method

In some science class along the way, you probably learned about the scientific method. But, interpreted literally, the idea that science always uses the scientific method is a myth. There is no fixed series of steps that scientific research follows. There is immense variability in aims and in methods for getting there, and there is considerable room for creativity along the way.

In Chapter 1, we developed a checklist approach to defining science. That checklist focused a lot on methods common in science, like empirical investigation, evidence gathering, openness to criticism, and collaboration. Scientific methods are central to its ability to produce trustworthy knowledge about our world. But the reason we defined science with a checklist is because of all the variety scientific projects can have, and that includes variety in methods.

Some of the most important scientific breakthroughs had decidedly unscientific-seeming origins. For example, there was no real method by which 19th-century German chemist August Kekulé discovered that the benzene molecule was structured like a ring; allegedly, he just had a daydream of a snake biting its tail. (However, this daydream came after Kekulé had been studying chemistry and the nature of carbon-carbon bonds for years.) Similarly, the idea that natural selection is the mechanism of evolutionary change occurred to the British naturalist Alfred Russel Wallace during a feverish attack of malaria while traveling in Indonesia in 1858—or so he wrote in his autobiography.

We also saw in section 2.1 how scientific research can have a number of different aims—generating knowledge, supporting effective action, making predictions, designing and building new products and technologies—and can focus on a number of different topics. For example, we encountered the different health conditions medical science and public health may prioritize, as well as whether the focus is on theoretical understanding, medical treatment, prevention efforts, or something else.

Scientific methods are sometimes represented very simply, but there are many variations in science’s aims and methods. So, there is no clear method supporting at least some important scientific discoveries, and there’s lots of variation in the aims of scientific research. You might think that once an aim is decided on and then a hypothesis is formulated, the scientific method kicks into gear in how the hypothesis is tested. But there are also many differences in how and the degree to which scientific claims are tested by empirical evidence. Sometimes empirical investigation is exploratory and open‐ended, without clear ideas in mind to test. Sometimes getting direct empirical evidence for or against an idea isn’t possible, and scientists must be creative in how they find evidence or what they count as evidence. Sometimes the research doesn’t involve collecting new empirical evidence at all but combining or reinterpreting existing evidence. These and other complications are reasons to say that there is no single thing we can call “the” scientific method.

##### Box 2.1 Descriptive versus normative claims in science

Descriptive claims are claims about how things are. Examples of descriptive claims are that this textbook has three authors and that the Nile River flows over 6,600 kilometers. Descriptive claims can be evaluated for their truth or falsity. “Rabat is the capital of Australia” is a false descriptive claim. In contrast, normative claims are claims about how things should be. For example, people should read more; scientists should be sincere; there ought to be peace. These claims can be evaluated for the robustness of the rules that they specify. Descriptive and normative considerations are both part of science. Certain theories in economics, for example, make claims about rational decision-making, which express how agents should make decisions. If people do not make decisions that way, it does not follow that the theory is false—though economists, depending on their goals, might revise their normative theories to make them more descriptively accurate. Just as science involves both normative and descriptive claims, both kinds of claims can be made about science. One can simply attempt to characterize what science is—that is, how scientists in fact develop theories and test claims.

Metascience, using scientific techniques to study science itself, is a discipline that pursues this route. Or, one can attempt to say how science should work, that is, what features science should have for it to succeed at generating knowledge. Philosophy of science sometimes pursues this route. This book does both.

#### Different methods for different aims and circumstances

Let’s add more detail to the idea of a variety of scientific aims introduced in section 2.1. First off, that variety of aims regards what natural phenomenon is studied—such as in the case of health sciences, Covid‐19, heart disease, and environmental pollution, to name just a few options. This variety of aims also regards what specific aspects of the phenomena are investigated. An illustration of this is

##### Table 2.2 The variety of scientific aims

| Types OF VARIETY               | Examples                                                     |
| ------------------------------ | ------------------------------------------------------------ |
|                                |                                                              |
| Phenomenon studied             | Covid-19, heart disease, or environmental pollution          |
| Focal aspect of the phenomenon | Structure and biological action of SARS-CoV-2, epidemiological models of disease spread, or how virus affects different genders and races |
| Goal of the research           | Specific theoretical knowledge, connections to knowledge of other phenomena, medical treatment, prediction, or public policy guidance |

All the different aspects of Covid‐19 that were investigated by different scientists, such as the structure and biological action of the SARS‐CoV‐2 virus, epidemiological models of disease spread, and how the virus affected people of different genders and races differently.

The variety of scientific aims also extends to the specific research goals when targeting some aspect of some phenomenon. Is the focus of studying the structure and biological action of SARS‐CoV‐2, for example, to develop theoretical knowledge of this virus in particular, or to explore its similarities to other coronaviruses, or to spur vaccine discovery, or to predict how the virus will likely evolve, or to determine what kinds of public policy would mitigate its spread? All of these are reasonable goals for scientific research into this aspect of the phenomenon, but each can lead to research with different features.

Besides having a variety of different aims, scientific research is also carried out in a variety of different circumstances. Some phenomena you can directly influence, while others you can just watch from a distance. Some phenomena you can see with your own eyes, and others you can merely detect distant evidence of. Some phenomena change quickly, and others are very slow. Sometimes scientists have specialized equipment to support exactly what they’re trying to do, and at other times they need to make do with old equipment or no specialized equipment at all. Perhaps the desired equipment hasn’t yet been invented.

These differences in the aims and circumstances of scientific research give rise to differences in scientific methods. A good bit of resourcefulness is needed to find the empirical evidence to support developing natural explanations of natural phenomena. The specific aims and circumstances influence what methods will be useful to that project. Most of the main topics of this book can be thought of as exploring one or another aspect of how scientific methods vary in response to aims and circumstances.

As we’ve already suggested, one major type of variability in methods regards the manner and extent of empirical investigation. Recall from Chapter 1 that empirical investigation is inquiry that grounds the justification for beliefs about the world in sensory information and observations. More empirical evidence that directly bears on ideas under investigation is always better. What varies is, first, how empirical evidence can be gathered and, second, how directly that evidence bears on the ideas being investigated. Experiments are a highly valuable way of conducting empirical investigation. In Chapter 3, we will survey the ways in which experiments are conducted, identifying their core features and also recognizing how different experiments can be from one another.

Sometimes it just isn’t possible to conduct an experiment. When this is the case, there are various ways to conduct observational studies and use other methods to gather empirical evidence bearing on the ideas under investigation. We survey several of those methods in Chapter 4. One valuable set of methods to indirect empirical investigation is scientific modeling; this is the topic of Chapter 5.

We said just a few paragraphs ago that the aims and circumstances of scientific investigation influence the extent to which empirical evidence bears directly on the ideas under investigation. Oftentimes, whether an idea is true can’t be directly determined using empirical investigation. Instead, scientists need to deploy arguments, or reasoning, that use empirical evidence to support conclusions about the ideas they are interested in. This reasoning can follow different patterns. Sometimes it’s what we call deductive reasoning, as when an empirical test provides grounds for definitively rejecting a hypothesis; we examine that pattern of reasoning in Chapter 6. Other times, reasoning patterns in scientific arguments involve drawing general conclusions from a limited set of evidence or, in other ways, reasoning beyond what the evidence guarantees. These forms of reasoning, called inductive and abductive, are discussed in Chapter 7.

A variety of mathematical tools are also put to use in science, though whether and how mathematics is relevant is yet another feature of science that varies. Particularly widespread and important uses of mathematical tools involve reasoning with probabilities, which we discuss in Chapter 8, and using statistics to describe phenomena (Chapter 9) and to make inferences and predictions (Chapter 10). Statistical tools can be used to uncover patterns in what might otherwise seem merely like random variation.

One important aim of scientific research is uncovering causal relationships. Chapter 11 explores how methods encountered in earlier chapters can be used in causal reasoning. Chapter 12 examines how all of the various methods of empirical investigation surveyed throughout the book can be used to develop scientific theories and explanation, important forms of scientific knowledge. Finally, Chapter 13 explores more fully how social values influence scientific practices and surveys salient features of science in the 21st century and new challenges it faces.

By the time we’ve worked through all the topics of this book, we will have seen the great extent of variation in science’s methods and in how these methods relate to the different aims and circumstances of scientific research. But first, let’s take a quick look at some of the commonalities across these methods.

##### Box 2.2 How to read a scientific article

Watch Video 4

Scientific knowledge is typically communicated in articles published in professional journals written by experts, for experts. Thus, scientific articles tend to use specialized jargon, formalism, images, equations, and tables that most people will find hard to understand. For non-experts reading scientific articles, one helpful method involves a set of five questions for structured reading:

1. What problem did the authors try to address? You will typically find the answer to this question in the article’s Abstract and/or Introduction.
2. What’s the point of addressing that problem? To answer this question, focus on the Abstract, Introduction, and Discussion sections.
3. What did the authors do to address their question or problem? The Methods and Results sections should provide you with an answer; but do not get lost in the details—just focus on the independent and dependent variables the researchers manipulated and measured and the general kind of methods they employed.
4. What did the authors find? Focus on the key finding presented in the Results section. This is where the specific research question and rationale are addressed.
5. How are the results interpreted? Read the Discussion section to answer this question, considering whether the authors’ interpretation is warranted by what they did and what they set out to address, and try to figure out if an alternative interpretation of the results may be more warranted.

##### EXERCISES

1. Recall: What are some reasons to think there’s no single, unified scientific method?
2. Think: Consider Figure 2.2. Describe the idea that there’s no unified scientific method, and then evaluate this idea. Try to raise at least three considerations in favor of the idea as well as three considerations opposed to the idea.
3. Recall: Describe how scientific methods are influenced by (a) the specific aims of investigation and (b) the circumstances of investigation.
4. Think: Look at this book’s table of contents, and perhaps flip through some of the chapters to come. Write out at least three questions about scientific methods and reasoning that you want to find answers to from reading this book.
5. Apply: Go to www.science.org, the website of a prestigious scientific journal, Science. Choose an article featured on the website, read the title and abstract, and look at all the section headings. Alternatively, your instructor may provide you with an article to analyze.

---

#  

(a) Write the title of the article; (b) summarize the main point(s) of the article in 1–2 sentences; and (c) describe how well the structure of the article matches the article structure described in Box 2.2. Finally, (d) identify which of the tools summarized in this section (experiment, observational study, model, argumentation, statistics, explanation, theorizing) were relevant to the research depicted in the article, and say how each was relevant.

### 2.3 RECIPES FOR SCIENCE

After reading this section, you should be able to:

- Describe what the metaphor of recipes and ingredients is intended to mean here
- Define each of the three ingredients found in most recipes for science, and describe why each is a challenge
- Describe at least three ways in which each of the ingredients of science—hypotheses, expectations, and observations—can vary

#### Methods in science

In this chapter, we have surveyed how scientific aims and methods vary. Science proceeds in myriad ways, and there’s not a simple, unified scientific method. And yet, as the title of this book suggests, even as scientific methods vary, science does follow some familiar recipes.

Consider culinary recipes like you find in a cookbook. These recipes have some standard components, like the name and origin of the dish, the ingredients along with their quantities and proportions, cooking times, and the necessary equipment to make the dish. These recipes also vary: in their ingredients, the equipment and processes they involve, their difficulty, how long they take, and—of course—what will result from following the recipe. Furthermore, simply following the steps doesn’t guarantee a delicious dish. Many cooks have margin notes in their cookbooks adapting recipes to their circumstances and tastes. And some recipes are just bad recipes!

Like culinary recipes, recipes for science have multiple components, involve a wide array of techniques and instruments, vary from one to another, accomplish different tasks, and are improved by others. As with cooking, there is no single set of mechanical instructions and step-by-step procedures that guarantees good science. Just like great cooking, good science is a highly variable and creative process. It also can be messy.

Still, just as culinary recipes tend to have some common features, recipes for science tend to use some common patterns. To start, most involve something like these three ingredients, in one form or another: hypotheses, expectations, and observations. What is sometimes thought of as “the” scientific method describes one way these ingredients can come together: scientists may formulate hypotheses about the world, described in Chapter 1 as bold and risky conjectures, and then use those hypotheses to generate specific expectations regarding their experiences. If their observations conform to those expectations, their hypotheses are confirmed. If not, they return to the drawing board.

These three ingredients—hypotheses, expectations, observations—can be combined in different orders, and they can be combined again and again in different patterns. And each ingredient can vary in its features. For example, sometimes scientists investigate a specific hypothesis, while at other times research is more exploratory and open-ended. Sometimes hypotheses have obvious empirical implications, and at other times scientists need to use statistics to develop their expectations. Sometimes scientists design experiments to test their expectations, and at other times they develop models. Further, some scientific research isn’t described well by this trio of hypothesis, expectations, observations, such as highly theoretical research carried out without making observations.

Nonetheless, these three ingredients are integral to the production of scientific knowledge. They are the basic ingredients that, with tremendous variation, occur in the many successful recipes for science we survey in this book.

#### Hypotheses

Empirical investigation is how we learn about our world. Scientists make observations to try to figure out what’s out there, why things are the way they are, and how things change. But simple observations can’t accomplish these tasks by themselves; scientists also need theoretical claims.

Theoretical claims are claims made about entities, properties, or occurrences that are not directly observable. As an example, consider a claim about all of something of some kind, like the claim that all salt dissolves in water. You might have seen plenty of salt dissolve in water, but you will never be able to witness all of the salt that exists dissolving in water. Because you can’t directly observe that all salt dissolves in water, this is a theoretical claim. We have plenty of evidence that this is true, but the claim is theoretical because it goes beyond what we can directly observe.

Theoretical claims investigated in science are called hypotheses. A hypothesis is a conjectural statement based on limited data—a guess about what some aspect of the world is like, which is not (yet) backed by sufficient, or perhaps any, evidence. Scientists do not yet know whether any given hypothesis is true or false; when there is sufficient evidence in favor of some hypothesis, it graduates from that category. Theoretical claims that we have sufficient evidence to conclude are true become scientific knowledge.

Formulating a hypothesis requires some imagination: if you could observe something we can’t—if you could witness the beginning of life on Earth, or see all the salt in the world—what would you find? Sometimes scientists may formulate a hypothesis before any observations have been made, just with the use of their imagination. But often, initial observations, other hypotheses, or background knowledge about related phenomena help inspire new hypotheses. Before scientists knew about the properties of potassium chloride, they’d seen that table salt—sodium chloride—dissolves in water. This informed their expectations for potassium chloride, a similar compound. Scientists’ hypotheses about the first lifeforms were shaped by what they know about organisms, existing and extinct, and how the Earth has changed over geologic time.

Scientists can have different levels of confidence in different hypotheses. If a hypothesis is informed by lots of experience with similar objects or significant background knowledge of related phenomena, scientists might be much more confident in it than if it were a random guess. But, by their very nature, hypotheses are guesses. This is why hypotheses must be tested.

#### Expectations

Learning whether a hypothesis is true is often more circuitous than just making direct observations. A second ingredient is usually needed to test hypotheses: this is developing expectations based on hypotheses. Expectations are conjectural claims about observable phenomena based on some hypothesis. These claims are conjectures since they go beyond what scientists have observed so far, but, unlike hypotheses, their truth or falsity can be discerned directly from making the right kind of observations. Expectations are claims about what scientists expect to observe if a given hypothesis is true.

Expectations do not regard just any possible observations, but observations that scientists anticipate being able to make. We could say what we would expect to experience if we were present for the beginning of life on Earth, but since we don’t have a way to make those observations, such expectations are useless. Instead, expectations based on a hypothesis regarding the origin of life on Earth should be about what scientists expect to see today, in present lifeforms or in traces of past life.

Depending on the nature of a hypothesis, developing expectations based on the hypothesis can be straightforward or complicated. On one extreme, the hypothesis that all salt dissolves in water leads directly to an expectation: any sample of salt will dissolve when placed in water. But even then, the expectation needs to be fine-tuned. Should salt dissolve when placed on a chunk of ice (frozen water)? What if some salt is already dissolved in the water; should we still expect the sample of salt to dissolve? And expectations for present observations that bear on some hypothesis about the origins of life on Earth are, of course, much more complicated to develop.

No matter whether deriving expectations is relatively straightforward or very complicated, this is an important and nontrivial ingredient of scientific research. Expectations set scientists up to make observations that can provide evidence for or against the truth of a hypothesis. Deriving expectations thus serves as a bridge between theoretical claims (hypotheses) and observations (data).

#### Observations

All or nearly all science fundamentally depends on observations. It’s not enough to think up interesting ideas about how the world might work; those interesting ideas must also be evaluated by how well they fit with our observations of the world. This is why both empirical investigation and evidentialism are on our checklist definition of science from Chapter 1. Observations include any information gained from your senses—not only what you see, but also what you hear, smell, touch, taste, and any other way you may be able to experience the world.

Your sensory experiences belong only to you. If we are on a hike together, we might both hear a rattling sound coming from behind a boulder. But each of us only has access to our own experience of the sound. Data are different. Data are public records produced by observation, sensory experience, or some measuring device. Observations are important because they are your only way to directly access the world. Data based on observations are important because they allow us to record and compare our observations.

Observation isn’t passive. We can move our heads to see different things and relocate our bodies to different places where we can hear different things. We can also use observations from multiple senses together. If you’re wondering about that rattling sound from behind the boulder, you can walk around to the other side to see whether there’s a rattlesnake there. Besides changing our position and using multiple senses to enhance our observations, we can also change the world around us to create opportunities for different observations. Crushing a leaf lets you better smell whether it’s sage or mint.

Humans have also found many ways to use tools to enhance our powers of observation. Light can be refracted with mirrors, prisms, and lenses to extend the reach of vision. We now can see not just through our eyes alone, but also through our eyes aided by telescopes, microscopes, and other devices. To help us hear beyond our ears’ capabilities, we have developed microphones, stethoscopes, and more. These technological enhancements range from observational correctives like eyeglasses and simple sensory aids like microscopes to much more complex technology with highly specific purposes, like an fMRI machine that can show brain activity and the Large Hadron Collider, which uses superconducting magnets to cause streams of high-energy particles to collide in a detectable way. Such enhancements have allowed humans to generate what we might call super-observational access: using tools to enhance our powers of observation beyond what they ordinarily include.

Making observations, and collecting data as records of those observations, is at the heart of science’s ability to generate knowledge of our world. But observations aren’t always independent from the ideas about the world we already have. Changes in what we believe to be true can have significant impact on what we observe. For instance, when we observe the Sun at the horizon, what we seem to see is the Sun at one point on its path across the sky. Geocentricism, the historically dominant idea that the Earth is the center of the universe, organizes this and similar observations into an easily understood pattern, and those observations confirm geocentrism. But from the perspective of heliocentrism—the idea that the Earth and other planets revolve around the Sun—once your head is slightly turned to the side, the Sun at the horizon and the other planetary bodies that appear comprise a different observation. Figure 2.4 schematically diagrams this conceptual shift.

The switch in theoretical orientation to heliocentrism thus provides a different perspective on astronomical observations. It may also create a different perceptual experience: instead of the Sun moving below the horizon as it sets, your position on Earth rotates away from the Sun. New ideas can sometimes have a strong effect on what we think we see. Thus, observations are a crucial ingredient of science, but they aren’t passive, aren’t always the starting point, and aren’t always decisive.  

##### EXERCISES

2.12 Recall: This section develops the metaphor of recipes with common ingredients. Watch Video 5 What about science do recipes correspond to, and why is it a plural—recipes instead of recipe? What about science do the ingredients correspond to?

2.13 Think: Describe at least three aspects of science the metaphor of recipes with common ingredients is intended to highlight. Evaluate the metaphor: what do you think is useful about it, and what is a limitation or potentially misleading about it?

2.14 Recall: What is the difference between observations and data? What is important about observations in particular, and why? What is important about data in particular, and why?

2.15 Think: Hypothesis, expectations, and observations are all important ingredients for most science. Describe the importance of each, a typical way that the three ingredients work together, and what they accomplish together.

2.16 Think: Hypothesis, expectations, and observations are all important ingredients for most science. Describe a difficulty with each, or circumstances in which it can be difficult.

2.17 Apply: Go to www.science.org, the website of a prestigious scientific journal, *Science*. Choose an article featured on the website, read the title and abstract, look at all the section headings, then read more of the article as needed to complete the following steps. Alternatively, your instructor may provide you with an article to analyze.

1. Characterize what you think the hypothesis under investigation is and, in 1–2 sentences, say why you think so. If you aren’t sure what the hypothesis is or you don’t think there is a hypothesis, give your reasoning.
2. How explicitly did the researchers describe their expectations? See if you can distinguish the specific expectations, or expected observations, from the general hypothesis under investigation. Whatever your answer on this, give your reasoning.
3. Describe the kinds of observations made in the research. What were the researchers’ findings? If there weren’t observations of any kind made as part of the research, describe what you think the point of the article is.

### 2.4 SCIENCE’S ORIGIN AND KNOWLEDGE ACROSS CULTURES

After reading this section, you should be able to:

- Describe how scientific methods for gaining knowledge about the world are similar to and different from strategies employed in daily life
- List innovations from the Islamic Golden Age and the Scientific Revolution and their significance for science
- Indicate three areas of investigation to which indigenous knowledge is particularly relevant and describe why it’s relevant

#### Science and everyday reasoning

The ingredients of science’s recipes discussed in section 2.3—hypotheses, expectations, and observation—comprise a distinctive and powerful combination that support science’s distinctive ability to generate knowledge about our world. They are also to some extent common strategies employed by people in their everyday lives, as well as strategies harnessed historically by different cultures around the world, to some extent building incrementally toward the modern institution of science.

Alison Gopnik, a psychologist at the University of California at Berkeley, has conducted research exploring ways in which early childhood development involves empirical investigation, much like the research conducted by scientists. Babies and children conduct informal experiments: they test their ideas about the world around them by checking out whether what they observe matches up with what they expect to happen.

Over time, children develop something akin to theories about things that are important to them, including about what other people around them think and believe. These theories grow more sophisticated as children develop, for example, by incorporating the recognition that someone with different experiences from oneself will have different ideas. Around four or five years old, a child begins to recognize, for example, that someone who did not witness a jar of cookies being moved to a new location will have a false belief about where the cookies are, even though the child knows the true location of the cookies.

Much like scientists, children conduct experiments and develop theories as attempts to better understand the world around them. This use of observation to develop theories about the world extends into adulthood, though adults tend to be more confident about what we will encounter and thus more fixed in our ideas. Perhaps, then, scientific research can be thought of in some respects like an extension of childhood curiosity and openness, cultivated into habits of investigation and openness to refutation about the topics a scientist investigates.

The basic pattern of making guesses, collecting observations, and then adjusting ideas in response is common across people of all ages, at least when the circumstances call for it. What is distinctive about science is, first, harnessing this basic pattern to systematically gain knowledge about our world, and, second, developing an institution around this project, including the important social norms introduced in Chapter 1.

#### The development of science as an institution

Science’s aim of producing knowledge traces back to the origins of the very word science. This word derives from the Latin words scientia and scīre, which pertain to knowledge. So, science, from its origins, has been about the pursuit of knowledge.

Most historians of science agree that cultural, social, and technological changes that unfolded in Europe between roughly 1550 and 1750 are very important to the development of the modern institution of science. This period is often referred to as the Scientific Revolution, beginning with the work of Nicolaus Copernicus, who put forward a heliocentric theory of the cosmos, and ending with Isaac Newton, who proposed universal laws of physics and a mechanical universe. The Scientific Revolution brought about fundamental transformations in our knowledge of the natural world and in how knowledge claims were thought to be justified. Many of the methods, ideas, and institutional structures developed during that period remain central to science.

But let’s start our consideration of science’s history even further back. Way before the Scientific Revolution, a variety of innovations across diverse civilizations—including ancient Egypt, Iran, India, China, Greece, and the pre‐Columbian Americas—provided fertile grounds for proto‐scientific activity. A variety of civilizations developed measurement systems that were essential for collecting data and refining ideas about various phenomena. For instance, many ancient civilizations made sophisticated catalogues of constellations and their observed movements in the night sky, which provided a detailed record of data against which later astronomical predictions and discoveries could be checked.

One important period in the development of science prior to the Scientific Revolution was the 500 years from the 8th through 13th centuries known as the Islamic Golden Age, during which time early science saw significant development from Central Asia to the Iberian Peninsula. Here is a sample of some of the scientifically important developments from that period.

The Hindu‐Arabic numeral system, which greatly advanced the symbolic representation of numbers and calculation, was invented between the first and fourth centuries in India. Muḥammad ibn Mūsā al‐Khwārizmī further developed this system in the eighth century and brought it to Arabic mathematics, and his work later introduced this numeral system to medieval Europe. Al‐Khwārizmī also made significant contributions to algebra, geometry, and astronomy. Shortly after, Abū Bakr Muhammad ibn Zakariyyā al‐Rāzī was responsible for many innovations in medicine, including advocating for experimental methods and developing classifications of contagious diseases. In the ninth and tenth centuries, Ibn al‐Haytham conducted revolutionary work in optics and vision, including the discovery that vision occurs by eyes detecting light deflected by objects.

Arabic polymaths, including especially Ibn Sina, known also by the Latinized name Avicenna, ibn Aḥmad Al‐Bīrūnī, and Ibn Rushd, or Averroes, preserved and developed theories about the natural world from the famous fourth‐century BCE philosopher Aristotle. This was the basis of ideas about the natural world in 15th‐century Europe, with ideas added from Christian, Jewish, and Islamic theology. Based on Aristotle’s views, the universe was thought to be geocentric—the Earth at the center—and with two regions: terrestrial for Earth and celestial for the planets and stars. The celestial region was thought to contain transparent concentric spheres that rotate around the Earth. In the first century, Ptolemy supplemented this with an account of the apparent motions of the stars and planetary paths, including detailed models and tables that could be used to calculate the positions of the stars and planets. Geocentrism in 15th‐century Europe blended observations of planetary bodies with religious ideas about humanity’s place in the universe.

A longstanding problem with the geocentric view of the cosmos was the appearance of retrograde motion. In observations made over a series of nights, planets sometimes seem to stop in their orbit, reverse course back across the sky, then stop again, and reverse yet again to continue on their original way. Following Ptolemy, geocentrists explained retrograde motion by positing epicycles: that the planets were on mini‐orbits that also follow the larger orbits. This successfully accounted for retrograde motion, but it wasn’t as intuitive as other elements of geocentrism.

In the 16th century, Nicolaus Copernicus presented a radical alternative conception of the cosmos as heliocentric, or centered on the Sun, and this provided an alternative explanation for retrograde motion. According to heliocentrism, retrograde motion of planets was due to Earth’s changing position relative to other planets as these all revolved around the sun. Copernicus’s proposed heliocentric conception of the cosmos was met with skepticism. It violated widely accepted beliefs and called for a fundamentally new physics of the heavens. Besides, the mathematics of Copernicus’s system was just as complex as Ptolemy’s epicycle solution to retrograde motion, and it did not   make predictions of planetary motion any more accurate. So, few astronomers were convinced by Copernicus’s theory.

The situation changed with the research of Johannes Kepler and Galileo Galilei, each of whom developed and improved the Copernican heliocentric system. Kepler was a German mathematician and astronomer with interest also in astrology; he devised a set of laws that described the motions of planets around the Sun. Based on calculations of the orbits of Mars, he inferred that planets do not have circular orbits as proposed by Copernicus but ellipses instead. This simplified the Copernican theory and significantly improved the predictive accuracy of heliocentric models. Born in Italy, Galileo was instrumental in establishing Copernicus’s heliocentric system and, more generally, in replacing Aristotelian mechanics of the separate terrestrial and celestial realms with a new, single physics. Galileo invented the telescope, which he used to observe the phases of Venus and to discover that Jupiter had moons orbiting it. This was a significant discovery for heliocentrism: if our Earth were the center of the cosmos around which all things orbit, then Jupiter’s moons should be orbiting Earth instead.

In the Scientific Revolution, the rapid development of new ideas, methods, and tools resulted in the swift accumulation of knowledge. A similar process played out in the later development of the fields of chemistry, biology, psychology, and economics. But many of the pursuits that furthered scientific knowledge also included religious, theological, and philosophical ideas that we would not consider scientific nowadays. In the Islamic Golden Age and the Scientific Revolution, philosophy, theology, and science were not divided as they are now, and often the same ideas had significance for religious belief and views about the natural world. The Scientific Revolution was a decisive step toward the separation of scientific from nonscientific questions and thus toward science explicitly adopting naturalism.

Other central features of the nature of science were also established in the Islamic Golden Age and the Scientific Revolution, such as looking to sense experience and performing experiments to decide what’s true, the systematic use of mathematics to study natural phenomena, and the institutionalization of investigation in formal organizations. Of course, these features have also continued to develop since those times. For example, the social organization of scientific activity was significantly transformed. with the professionalization of science in Europe and North America beginning in the mid‐19th century, which also established the French language, and later English, as the dominant language for scientific communication.

#### Institutional science and indigenous knowledge

This picture of scientific revolutions culminating in the development of contemporary science is helpful for demonstrating how science is a development shaped by various human societies, but it has the drawback of perhaps overemphasizing the extent to which contemporary institutional science is responsible for knowledge about our world.

For some investigations, such as astronomy and fundamental physics, specialized equipment and training are so essential that such knowledge is the special province of the institution of science. But it wasn’t always so. As noted earlier, astronomical observation occurred across many historical civilizations, such as the Mayan in Central America, Polynesian, and Chinese civilizations. And, even today, scientific research about astronomy, as well as many other topics, sometimes incorporates observations or other contributions from people who aren’t scientists but are just interested in astronomy. This is called participatory research (also citizen science), to be discussed more in Chapter 13.

Some types of scientific research aren’t limited to only people with access to specialized equipment or training. And some types of scientific research relate as much or more to circumstances on the ground in some specific place as to general scientific knowledge. Examples of these kinds of research include investigations of biodiversity in different locations, effective land management techniques, and how specific communities can mitigate the most disastrous effects of climate change on them. For these kinds of scientific research, it’s increasingly appreciated that locals have important expertise and the ability to contribute meaningfully to scientific research.

Beyond the value of localized expertise, it’s also now recognized that traditional societies in many parts of the world have developed extensive stores of knowledge about the natural world around them, some of which are still maintained today. Indigenous knowledge refers to true claims based on observations, practices, and ideas developed about some geographic region by people native to the area. Indigenous knowledge is in part developed with the use of practices crucial to science—observation, systematic recordkeeping, and checking ideas against evidence—but typically outside the institution of science. There is increasing interest in the value of indigenous knowledge within the institution of science, especially about local environmental sustainability and resource use. This becomes only more valuable as scientific research increasingly turns to questions of sustainability and climate change adaptation, as these are shaped by local conditions and the subject of local knowledge.

Although the institution of science aspires to be fully inclusive and international, it inherits a history of exclusion and is still limited in whom it involves. Historically, in the 18th and 19th centuries, sea voyages of European nations played dual roles as both scientific expeditions and also commercial trips to expand colonization. Even today, there are fewer opportunities to become scientists in the Global South (Latin America, Asia, Africa, and Oceania), and scientists in the Global South face more professional challenges in their research. We will discuss diversity in science in greater depth in Chapter 13.

In the context of this chapter’s discussion of how science pursues its aims, this discussion reveals that, though the development of professional science as an institution was very important for its success in uncovering knowledge, it’s also increasingly appreciated that institutional science isn’t the only place where relevant scientific knowledge is found. The scientific value of indigenous knowledge shows that scientific reasoning and scientific knowledge are not the purview of any single culture or institution.

##### EXERCISES

2.18 Recall: Describe two ways in which children’s reasoning is like scientific reasoning and two ways in which scientific reasoning is distinct.

2.19 Recall: Choose one proto-scientific development from the Islamic Golden Age or the Scientific Revolution. Describe how that development constituted progress (a) in the subject matter of science and (b) in the methods of science.

2.20 Think: It was discovered in the 19th century that the planet Mercury was not following the orbit predicted by Newton’s theory of gravity. When this happened, Newton’s theory was not considered falsified. Instead, it was hypothesized that this anomaly was the result of another planet, named Vulcan, orbiting between Mercury and the Sun. Despite a systematic search, Vulcan was never found. The anomalies exhibited by Mercury’s orbit could be explained only a century later by Albert Einstein’s theory of general relativity.

1. Why do you think scientists initially refused to consider Newton’s theory falsified?
2. Was this a failure of science? Should the scientists have given up Newton’s theory sooner? Why or why not?
3. Does this mean Newton’s theory of gravity was not falsifiable? Why or why not?

2.21 Recall: Define indigenous knowledge. List three areas of investigation to which indigenous knowledge is particularly relevant and, for each, describe why it’s relevant.

2.22 Apply: Mythology and science are generally understood to be very different from one another. And yet early science had its origins in, and then grew out of, mythology, and both myths and scientific theories provide explanations of the natural and social phenomena observed in the world around us.

1. Look up two creation myths from different cultures and historical periods—that is, myths of how the world began and how people first came to inhabit it.
2. Identify similarities and differences across the two myths.
3. Describe similarities between the creation myths and scientific theories of human origin.
4. Describe differences between the creation myths and scientific theories of human origin.

##### FURTHER READINGS

For resources on gender and sex disparities in Covid‐19, see the Harvard Gender‐Sci Lab’s Teaching Module. Gender/sex in Covid-19. www.genderscilab.org/gender-sex-in-covid19-teaching-module

For more on Covid‐19 and the importance of social determinants of health, see Yong, E. (2021). How public health took part in its own downfall. The Atlantic. www.theatlantic.com/health/archive/2021/10/how-public-health-took-part-its-own-downfall/620457/

For a consideration of how values influence science, see Potochnik, A. (2020). Awareness of our biases is essential to good science. Scientific American. www.scientificamerican.com/article/awareness-of-our-biases-is-essential-to-good-science/

For more on the Scientific Revolution, see Shapin, S. (1996). The scientific revolution. University of Chicago Press.

On science in the Islamic Golden Age and other periods around the world, see the History of science society introduction to the history of science in non-western traditions. https://hssonline.org/page/teaching_nonwestern

For more on science’s relationship to indigenous knowledge, see Nicholas, G. (2018). When scientists “discover” what indigenous people have known for centuries. Smithsonian Magazine.

## CHAPTER 3 Scientific experiments  

### 3.1 THE NATURE OF LIGHT AND EXPERIMENTAL DESIGN

After reading this section, you should be able to:

- Define experiment and provide examples
- Describe three ways in which existing scientific knowledge shapes experiments
- List five features of experimental design and identify them in an example experiment

#### Experimenting on light

In Chapter 2, we discussed how many of the successful recipes for science involve three ingredients: hypotheses, expectations, and observations. Scientific experiments provide scientists with a structured way to make observations and compare them to what we would expect to observe if the hypothesis under investigation is true.

An experiment is a type of empirical investigation where researchers perform an intervention that changes some feature of a system and observe the effects, with the aim of understanding how the system works or why a certain outcome occurs. Ideally, an experiment changes a system in such a way that the effects depend only on the intervention rather than on other possible factors. For example, by giving the plants on one windowsill in my apartment different types of fertilizer and observing what happens, I can know that the fertilizer is what’s making a difference to the plants’ growth. This is how experiments enable us to figure out what would happen to a system if some of its features were different—for example, what would happen to my plants if I gave them urine as fertilizer?

Being able to figure out what would happen if something were different matters for policymaking and applied research—for example, a company might decide to invest in urine-based fertilizers, or governments may incentivize the use of urine-diverting toilets for recycling waste, if it turned out that urine was an excellent fertilizer.

To begin to explore the main aspects of experiments, let’s consider the nature of light. Have you ever seen how a glass prism can make little rainbows appear around a room? When sunlight passes through a piece of glass, the white light is separated into different rainbow colors. Why does that happen? Where do those colors come from?

The nature of light and its relation to the color spectrum visible in rainbows have been studied for millennia. In Chapter 1, we mentioned Ibn al-Haytham (Latinized as) Alhazen, who during the Islamic Golden Age advanced the scientific understanding of vision, optics, and light. Through experiments using lenses and mirrors, al-Haytham showed that light travels in straight lines. From dissections, he began to explain how the eye works and began synthesizing the medical knowledge of previous scholars. In particular, al-Haytham demonstrated that light is not produced by the eye, as some theories had claimed, but instead that it enters the human eye from the outside. This research formed the basis of scientific knowledge about light.

In the 17th century, many scientists—or “natural philosophers,” as scientists were called then—believed in what we might call the modification hypothesis of light. They thought that sunlight is essentially white, and that the spectrum of colors we see from a glass prism is caused by the impurities of the glass modifying the light. Isaac Newton was unconvinced. He hypothesized instead that white light is made of several colors, and that passing sunlight through a glass prism causes those colors to separate and become visible. If this hypothesis were true, then the modification hypothesis would be wrong: the impurities of the glass are not the cause of the rainbow colors we observe from prisms.

Newton performed several experiments to test his hypothesis. In one experiment, he darkened his room and bored a small hole in the window shutters so that only a thin beam of light could enter the room, casting a white circle of light on the wall. Then Newton placed a glass prism in the beam. A rainbow of colorful light appeared on his wall. This observation was consistent with the expectations of both the modification hypothesis and Newton’s alternative hypothesis that white light is a mixture of colors. Both hypotheses lead us to expect that a beam of light travelling through a glass prism will produce different-colored bands. One thing was intriguing though: the shape of rainbow light was not a circle, as the white light had been, but oblong.

Then, Newton added a second prism to the path of the light. If the modification hypothesis was true—he reasoned—you would expect that the impurities contained in the two glass prisms would continue to modify the sunlight and just spread out the color spectrum further. But when the spectrum of colored light passed through the second prism, it recomposed back into white light! Because the modification hypothesis, if true, does not lead us to expect this observation, Newton concluded that the Modification hypothesis was probably false. This result showed that white light could be composed of a rainbow spectrum: Newton’s experiment had made this happen! This finding also raised new questions. If light is a spectrum of colors, what’s the nature of these colors? Are they particles of some sort? What makes them different colors? And why do the different colors spread out when they travel through the prism, making the light oblong instead of round? It would take more experiments performed by Newton and several other scientists to answer these questions and lead us to better understand the nature of light.

#### Experimental design

As Newton’s experiments illustrate, experiments involve much more than simple observation. Experiments are strategically designed to enable the expectations drawn from a hypothesis to be tested.

An important feature of any experiment is its material aspects. Performing an experiment involves physical, concrete objects. While the experimental setup in Newton’s experiments on light involved only cheap glass prisms, pencils, and notebooks, many present-day experiments require more expensive technologies, including specialized instruments, biological samples, chemical reagents, standardized questionnaires, computers, software for data analysis, and so on. All this apparatus costs money, which raises questions about how funding should be distributed among experimental research projects. For example, should we spend billions of dollars on a special superconducting collider for experiments in particle physics, or should funding agencies distribute money to prioritize several small-scale cheaper experiments in other fields?

Another important material aspect of experiments is what is being experimented upon. Experiments can focus on humans, non-human animals, or inanimate objects; these are the subjects of the experiment, also called experimental entities or participants. Human experimental participants are typically paid for participating in an experiment, while non-human animals for experimental testing often need to be bought, fed, and trained. Some inanimate objects on which certain interventions are performed are cheap to obtain or free, such as the rays of sunlight on which Newton experimented. But other objects studied in other experiments, such as rare metals, are hard to obtain and expensive. Experiments on humans vs. non-human animals vs. inanimate objects present different challenges and opportunities, which is discussed in section 3.3.

##### Box 3.1 Ethics and data management in experiments

Ethical evaluation is an integral part of contemporary scientific practices. If researchers want to run an experiment involving humans or non-human animals, typically they have to fill out an Ethical Clearance, Data Management and Protection form, where they describe the aim of the experiment, how it will be performed, what data will be collected, how the data will be analyzed, where The data will be stored, for how long, and who can access them. The researcher fills out and submits this form to the Ethics Committee of their institution. In the US, this is the Institutional Review Board (IRB). This committee includes other researchers and ethicists tasked with evaluating potential ethical and methodological issues with the proposed research. The Ethics Committee must give clearance before the research begins. The aim is to uphold scientific integrity and methodological soundness—especially when personal data are collected, such as sensitive demographic information, or when invasive interventions are performed.

Before participating in an experiment, subjects must be informed of the research’s potential risks and benefits, and they must explicitly consent to be part of the experiment and grant the researcher the right to collect and use their data for specific scientific purposes. Ethical clearance and data management and protection is a recent innovation. Many (in)famous experiments in medicine and social psychology, such as the Tuskegee Study in the 1930s, Harry Harlow’s monkey studies in the 1960s, and Philip Zimbardo’s Stanford Prison Experiment in 1971, did not receive ethical clearance and could not be performed nowadays.

Where an experiment occurs and over what period of time can also be important features of the experimental design. Newton’s experiments on light took place in his room at Trinity College, Cambridge UK, around 1670. Many present-day experiments occur in laboratories located in universities and hospitals or take place in the field, that is, in settings like farms, subway stations, and forests. Newton’s experiments on light had a short duration; other experiments can last years, such as present-day experiments in high-energy physics at the European Organization for Nuclear Research (CERN) in Geneva, Switzerland, where a very expensive and large superconducting collider called the Large Hadron Collider is used to accelerate and collide subatomic particles to study the nature of the fundamental constituents of matter and light.

Whether an experiment takes place in a laboratory or the field, their location and setup are always background conditions that can influence the data collected. Background conditions are the physical, technological, and social aspects of an experiment or study. The room at Trinity College where Newton performed his experiments had a certain ambient lighting, temperature, and humidity. The angle at which sunlight hit the room’s windows varied by time of day and season. Prisms, the instruments Newton used, were not commonly thought of as scientific instruments in the 1660s and so were sold simply for their entertainment value. As a result, they were irregular in both size and composition. These features were all in the background of Newton’s experiments. For his experiments to produce evidence against the modification hypothesis, Newton needed to show that none of these background factors were responsible for the results.

Experiments are designed to produce data. Data was defined in Chapter 2 as public records produced by observation or by some measuring device. Data provide evidence in favor of or against a hypothesis. Newton’s data consisted of records in a notebook of the effects of passing a beam of sunlight through one or more glass prisms. For physicians, the results of blood tests and testimony about one’s medical history can both count as data. Fossils, tracks, and recordings of the chemical features of mammoth tusks and of rocks in different locations all can count as data for a paleontologist. Climate scientists collect data from things like glaciers, oceans, and the atmosphere—for example, glaciers’ mass balance, sea surface temperatures, and the atmospheric pressure at sea level.

Another feature of experimental design is who carries out the experiment. A scientist may conduct an experiment alone, but collaborative experiments are common in contemporary science. Most collaborative experiments involve scientists with different scientific expertise who rely on one another’s expertise. Experiments at CERN, for example, are highly collaborative, run by hundreds of scientists and engineers from all over the world, each of whom brings some specific expertise to bear.

Even when an experiment is run by a single lab or an individual scientist, the broader scientific community shapes the experimental design. Communities of scientists, represented by scientific institutions and societies, determine protocols to be followed in experimental design and data analysis. These protocols include ethical guidelines for what sort of experiments are permissible, how experimental participants—humans or non-human animals—should be treated, and how data should be managed. As it happened, the Royal Society—the learned society for science of which Newton was a member—criticized his results, suggesting that the prisms’ bubbles, veins, and other impurities caused the light to become colored as it passed through and that the modification hypothesis could account for the results of his experiments.

##### EXERCISES

3.1 Recall: Define experiment and give two examples of experiments.

3.2 Apply: For each of the two example experiments from Exercise 3.1, identify the hypothesis or hypotheses under investigation, the expectations for the experiment based on the hypothesis or hypotheses, and important features of the experimental design.

3.3 Recall: What is the modification hypothesis of light? Describe Newton’s one-prism experiment and his two-prism experiment. For each, say what evidence it provided that challenged the modification hypothesis.

3.4 Recall: Describe three ways in which existing scientific knowledge shapes experiments. Illustrate each with an example from Newton’s experiments on light.

3.5 Recall: List five features of experimental design. Identify each feature of experimental design for both Newton’s prism experiments and experiments at CERN, the Large Hadron Collider.

3.6 Apply: List five features of experimental design. Find an example experiment described in a research article (or your instructor may provide you with an example). As best you can, identify each feature of the experimental design from what is said in the article. Then, describe how the experiment relies on existing scientific knowledge.

### 3.2 THE POWER OF EXPERIMENTS: INTERVENTION AND CONTROL

After reading this section, you should be able to:

- Define intervention, independent variable, dependent variable, and extraneous variable and indicate the role of each in a perfectly controlled experiment.
- Indicate how defining expectations and collecting data can introduce confounding variables.
- Describe two strategies of variable control: direct and indirect.

#### The perfectly controlled experiment

Experiments have some ingenious features that make them a powerful way to gain scientific knowledge. To appreciate those features, it will be useful to start by describing an ideal experiment, even if real experiments usually deviate from this ideal. In an ideal experiment, experimenters perform an intervention that changes only one single feature of a system or situation while all other features remain the same. As a result of all the other features being unchanged, scientists know that any change in the system or situation is due only to the intervention.

That’s the basic idea, but introducing some technical vocabulary will help make this precise. A variable is anything that can change, vary, or take on different values. For example, the number of books you read in one year, people’s height, and the temperature in your hometown are all variables, since these are all things that can change over time or vary in different people or places. The value of a variable is just the particular state of the variable in some instance. For example, the value of the variable number of books you read in 2024 might be 0, 12 or 56; the value of the variable Matteo’s height is now 1.85 meters (6 feet); and your hometown temperature might have the value 62° Fahrenheit (16.67° Celsius) one summer evening and 92° Fahrenheit (33.33° Celsius) the next evening.

In experiments, there are three types of variables, distinguished by the roles the experimenters want them to play. An independent variable is a variable that’s changed or observed at different values in order to investigate the effect of the change. A direct manipulation of the value of the independent variable is called an intervention. For example, the independent variable in Newton’s experiment on light was the number of glass prisms through which the beam of sunlight passed; this variable had the value of 0, 1, or 2 in the experiments we described earlier.

A dependent variable is a variable researchers measure for changes after they intervene on the independent variable. The researchers anticipate how the value of the dependent variable depends on, or is affected by, the independent variable. When scientists perform an intervention in an experiment, they do so to investigate how that change affects one or more dependent variables. For example, Newton varied the number of prisms through which sunlight passed (independent variable) and then looked for changes in the color and shape of the light that had passed through the prisms (dependent variables).

The goal of an experiment is to isolate the relationship between an independent variable and one or more dependent variables. This requires controlling all extraneous variables.

#### Extraneous variables

Extraneous variables are all other variables besides the independent variable that may influence the value of the dependent variable. In Newton’s prism experiments, extraneous variables included bumps and impurities in different prisms, the time of the day, the angle at which a beam of light hits the prism, the ambient temperature, and much more. If you are experimenting with a new homemade fertilizer to find out how it affects the growth of your plants, then the amount of light, water, soil quality, ambient temperature, and more are all extraneous variables.

In an ideal experiment, recall, experimenters intervene on one feature of a system or situation (the independent variable) while all other features (extraneous variables) remain the same, so they know that any change (dependent variable) is due to the intervention. Keeping fixed the values of all extraneous variables is known as controlling the extraneous variables. More precisely, variable control is creating conditions such that no extraneous variable can change the value of a dependent variable during or as a result of an intervention on the independent variable. In a perfectly controlled experiment, any change in a dependent variable can only be due to the intervention on the independent variable. This isolates how the independent variable affects the dependent variable(s). In Newton’s prism experiments, his goal had been to control the conditions of the light beam so carefully that any changes to the light (color, shape, etc.) could be due only to the prism(s).

#### Controlling variables

A perfectly controlled experiment is simple to describe, but it’s difficult even to get close to this ideal in practice. Many extraneous variables can influence the dependent variable in a given experiment, and some may be hard to control or even to identify. When you investigate the effect of a homemade fertilizer on your houseplants’ growth, you need to somehow ensure no other conditions—amount of sunlight, season, warmth in your home, humidity, soil quality, the prior health of the plants, different growth rates in different kinds of plants, etc.—are instead responsible for any changes in growth.

When extraneous variables are not controlled and affect the relationship between the independent and dependent variables, we call them confounding variables, or confounds. Confounding variables can undermine researchers’ ability to draw conclusions about the influence of the independent variable. So the goal of variable control is to avoid any confounding variables.

##### Table 3.1 Types of variables and their use in experiments

| Type of Variable     | Use in Experiments                                           |
| -------------------- | ------------------------------------------------------------ |
| Independent variable | An intervention is performed upon the independent variable   |
| Dependent variable   | Dependent variable(s) are measured for changes after an intervention |
| Extraneous variable  | Extraneous variables are controlled directly or indirectly so they do not vary during an experiment |
| Confounding variable | An extraneous variable that was not controlled and may have interfered with the relationship between independent and dependent variables |

There are two basic strategies of variable control: direct and indirect.

**Direct variable control** is when experimenters hold extraneous variables at constant values during an intervention. This is why Newton ran his experiments at the same time of day and in the same darkened lighting conditions. Keeping the values of those variables constant ensured that they didn’t change the light’s behavior. Newton also attempted to directly control the confounding variable of air bubbles and other impurities in the prisms by using higher-quality prisms. The carefully managed conditions in today’s laboratories help scientists to directly control many variables. For example, there is a standard temperature and pressure used for laboratory experiments, abbreviated STP. In experiments conducted with the Large Hadron Collider at CERN, scientists use sophisticated technologies to keep many variables under direct control, such as the magnetic fields and temperature in the collider.

Some extraneous variables are difficult to hold constant or even to identify as potentially relevant. For these variables, indirect variable control is best.

**Indirect variable control** is when experimenters allow extraneous variables to vary but ensure that variation is independent from the value of the independent variable. The key to indirect variable control is to study multiple systems, situations, or groups, all with the same variety of features and facing the same range of conditions other than the independent variable. Then, even though many variables vary, the value of the independent variable is the only systematic difference between them. In this case, any differences in the dependent variable between the systems, situations, or groups must be due to the difference in the independent variable. You might not be able to keep the humidity or temperature of your home exactly the same over days or weeks, and you certainly can’t control the weather. But you can put two plants of the same kind on the same windowsill, give them the same amount of water (these are direct variable control), and let the other conditions the two plants encounter vary. Those conditions should affect both plants about the same.

But what if one of the two plants just happens to be heartier or quicker growing than the other? Indirect variable control often employs groups to also include variations across individuals. So, instead of studying two plants, perhaps you plant ten seeds from the same seed packet, five into each of two pots. You place both pots on the same windowsill and water both pots the same amount, at the same time. Perhaps you even switch which side of the windowsill each is on once a week. After three weeks, you thin the plants to the three tallest in each pot. Then, even though conditions for the plants are changing over time and you don’t know if some of the plants will grow larger than others, the group of plants in each pot should experience about the same range of conditions.

With indirect variable control, the only systematic difference between groups is the value of the independent variable. One group, the experimental group, receives the intervention to the independent variable, or experiences the intended value of the independent variable. The other group, the control group, does not receive the intervention but experiences other value(s) of the independent variable. As you can probably guess by now, of the two pots of plants, one should be treated with your homemade fertilizer, while the other should not. What happens to that second pot of plants, your control group, depends on what you want to investigate. Do you want to know how your homemade fertilizer compares to no fertilizer at all, or to the fertilizer you used to buy from the store? What value you set the independent variable to in your control group determines what you will learn about the intervention under investigation.

One common strategy for forming experimental and control groups is randomization, which is the use of arbitrariness or some chance procedure like a lottery to assign experimental entities to experimental and control groups. Randomization is meant to ensure that the two groups are equal in all relevant characteristics except the intervention, since any differences among the experimental entities should vary randomly across groups. This is effectively what we were proposing when we described planting ten seeds from the same packet into two pots—seeds with different characteristics were equally likely to make it into each group. Many scientists, especially in the medical sciences, believe that randomized controlled trials (RCTs) are the gold standard of indirect variable control. But, as we will see later in this chapter and in the next chapter, there are other techniques for managing extraneous variables.

Random group assignment guarantees extraneous variables are not deliberately related to group assignment, and so not related to whether experimental entities experience the intervention. But random group assignment does not guarantee that all extraneous variables vary equally within the two groups. Randomization only ensures the similarity of the experimental and control groups in the limit—only when the experimental subjects are randomly divided in two groups an infinite number of times. In actual randomized experiments, the two groups may have systematic differences simply due to chance. Perhaps, just by chance, all the seeds that went into one pot were able to germinate sooner and grow larger. For this reason, for randomization to be an effective approach to indirect variable control, the groups must be large enough so that large chance differences across groups are very unlikely. Planting five seeds per group is better than just one seed, and planting ten seeds per group (with adequate space to grow) is even better.

#### Clarifying expectations and collecting data

To test a hypothesis with an experiment, clear expectations must be articulated for the outcome of the experiment. These expectations are predictions of the results of some intervention, assuming the hypothesis in question is true. Expectations should be clearly and precisely defined before running the experiment, in a way that makes them easily comparable to the data the experiment will produce. Yet, scientists’ hypotheses can involve broad concepts and ideas that can be hard to know how to test.

Two techniques that scientists can use to generate precise expectations from hypotheses with broad concepts and ideas are operational definitions and cluster indicators. An operational definition is a specification of the conditions when some term applies, enabling measurement. In social science research, for example, wealth might be operationally defined as a household’s combined material assets, as this would capture an important component of material wealth and offer a precise, measurable basis for comparison. But this operational definition also simplifies a complex concept. For instance, generational wealth not yet transferred into a household isn’t considered. Because of this lack of nuance, economists often study wealth using a combination of indicators, such as yearly income, access to education and healthcare, and permanent housing. Such cluster indicators identify several markers of some variable in order to more precisely measure it while not oversimplifying it. Many terms can be defined in multiple ways without one being obviously best, but the choice between different operational definitions and cluster indicators is not arbitrary. This depends on the scientists’ research goals and the details of the experimental setup, and the choice is important. Employing the wrong definition might introduce a confounding variable, such as generational wealth, or it might obscure impacts of the intervention. What if, in your fertilizer experiment, you simply measure plant height, but your fertilizer increases plant longevity or improves flowering?

Data collection is another opportunity for confounding variables. First, this often involves specialized instruments, technological tools or other kinds of apparatus used in experiments, ranging from specialized equipment to surveys. These instruments are a possible source of error—and thus a potential confounding variable. Newton had to convince the Royal Society and other audiences that the data he collected using prisms was legitimate, as prisms’ use in scientific inquiry was not yet broadly accepted. Questions about the reliability of instruments used in experiments still arise. The reliability of an instrument is the extent to which it accurately and consistently measures what it is supposed to measure.

Scientists must calibrate instruments to ensure they are reliable. Calibration is the comparison of the measurements of one instrument (for example, an electronic ear thermometer) with those of another (for example, a mercury thermometer) to check the instrument’s accuracy and adjusting the instrument if needed. In experiments with human subjects, data collection often involves surveys or questionnaires, and these also need to be calibrated and assessed for reliability just as technical apparatus does. A poorly designed question can prime subjects to answer in a certain way, for example, or questions might be ambiguous, eliciting different kinds of responses from different people or unintentionally asking about more than one thing at once.

Calibration and assessment of reliability are ways of directly controlling extraneous variables related to data collection. Another set of extraneous variables that must be controlled during data collection is human expectations. We learned about the observer-expectancy effect in Chapter 1, how a scientist’s expectations can lead them to unconsciously influence the behavior of experimental subjects. For example, it’s well established that the expectation that a medicine will be effective can lead to improved health; this is called the placebo effect. Researchers’ expectations and, for experiments involving human subjects, subjects’ expectations thus need to be controlled or they may become confounding variables.

The strategies of direct and indirect variable control that we have talked about so far don’t help with the extraneous variable of human expectations. To control for this, scientists rely on blinding (or masking), which is when researchers or subjects are temporarily kept unaware of group assignment, hypotheses under test, or other experiment details. Blinding aims to reduce the risk of biased observations by directly controlling the information researchers and/or experimental subjects have access to and, thus, indirectly controlling their expectations. In double-blind experiments, researchers and subjects are both unaware of which subjects are in the experimental and control groups.

##### EXERCISES

3.7 Recall: Define intervention, independent variable, dependent variable, and extraneous variable and indicate the role of each in a perfectly controlled experiment.

3.8 Apply: Review the discussion of Newton’s prism experiments from section 3.1. Identify the two hypotheses under investigation, the independent variable, and the dependent variable(s). Describe the intervention and how Newton controlled extraneous variables. What were the expectations based on each hypothesis? What did Newton conclude on the basis of his experiments?

3.9 Recall: Define extraneous variable and confounding variable. What is the relationship between the two? Why are experiments designed to limit confounding variables?

3.10 Recall: Define direct variable control and indirect variable control. Give three examples of directly controlled variables and three examples of indirectly controlled variables in the fertilizer experiment sketched in this section.

3.11 Think: (a) What is the purpose of having an experimental group and a control group in an experiment? (b) How does division into two groups achieve this purpose, and why is random group assignment important? (c) What are the limitations of this strategy?

3.12 Recall: Describe how defining expectations and collecting data can introduce confounding variables and how each can be controlled.

### 3.3 LEARNING FROM EXPERIMENTS

After reading this section, you should be able to:

- Define internal experimental validity, external experimental validity, ecological validity, and population validity and indicate why each is important
- Analyze how sample selection, sample size, group number, and group assignment influence experimental design
- Describe the challenges that reliance on background knowledge and alternative hypotheses pose to testing hypotheses with experiments

#### Internal and external validity

Laboratories give researchers control over many aspects of an experiment. Depending on the kind of experiments performed, a lab’s design features may include constant temperature, sterile environment, special equipment to produce unusual conditions, or, for experiments with human subjects, carefully selected lighting and furniture, soundproofing, and so forth. Those design features, and the direct variable control they provide, constitute one of the greatest advantages of the laboratory experiment. These features can enable scientists to discover regularities that are not easy to discern in the outside world.

The high degree of control enabled by laboratory conditions brings with it a high degree of internal experimental validity. Internal experimental validity is the extent to which researchers can infer accurate conclusions about the relationship between the independent and dependent variables. This amounts to the absence of confounding variables, achieved by direct or indirect control of extraneous variables. Another advantage of laboratory experiments is that the experimental setup and data analysis can follow standard procedures, which make it easier to assess and replicate an experimental finding.

However, lab research also has some disadvantages. Some phenomena are not easily investigated in a lab. Suppose you are investigating the effects of climate change on large marine mammals, especially the effects of elevated Arctic Ocean temperatures on the deep-diving behavior of narwhal whales. Narwhals—sometimes called unicorns of the sea because of their tusks—can dive as deep as 1.8 kilometers in Arctic waters. To directly investigate this phenomenon in a lab, you will need—for starters—a huge tank of freezing salt water nearly two kilometers deep. Investigating this in the lab is thus all but impossible.

The unusual conditions in a lab that make it easy to control variables also make the lab setting different from the outside world, and that has some disadvantages too. The artificiality of the experimental setting might mean that the results obtained in the lab do not generalize well to real-life settings outside the lab. This is problematic since it’s ultimately the real-world phenomena that we want to know about. Laboratories thus facilitate high internal validity, but potentially at the cost of external validity. External experimental validity is the extent to which experimental results generalize from the experimental conditions to other conditions—especially to the phenomena the experiment is supposed to yield knowledge about.

One component of external validity is ecological validity. Ecological validity is the degree to which an experiment’s circumstances are representative of real-world circumstances. Experimental settings or what subjects are asked to do can be artificial, unlike real-world circumstances, in ways that impact the phenomenon under investigation. One way to enhance the ecological validity of an experiment is to conduct it “in the field,” that is, in participants’ everyday environment outside of the laboratory; such experiments are called field experiments. Field experiments tend to have more external validity than lab experiments because they occur in circumstances similar to everyday circumstances. Their ecological validity is higher as a result.

A downside to field experiments is decreased internal validity. Less influence over the circumstances and the selection of experimental subjects is linked to decreased control over extraneous variables and sometimes a decreased ability to intervene in the desired way. The decreased influence on experimental design also makes it more difficult for other researchers to replicate the experiment. Researchers conducting field experiments may also be constrained in what they can be in a good position to observe or measure, the number of subjects they can involve, and how long they can run the experiment. Many field experiments require special permissions from subjects or from authorities that control access to areas like nature preserves. Uncontrollable events like inclement weather or warfare can also disrupt observation or limit the length of study that’s feasible.

Watch Video 7

#### Samples and groups

Alongside ecological validity, the second component of external validity is population validity: the degree to which experimental entities are representative of the broader class of entities or population of interest. With a representative sample, the experimental entities studied do not vary in any systematic way from the general population. The more representative a sample is of the broad class or population, the more confident scientists can be of the experiment’s external validity.

Here’s an illustration of the importance of population validity. Many clinical trials testing the efficacy and side effects of drugs have been performed only on men, but the results are expected to generalize to women as well. This decreases the population validity of the results, since women and men differ in several medically relevant ways. There is thus relatively limited experimental knowledge about the effects of some drugs on women, and this may have serious consequences for health and medicine. Indeed, some prescription drugs have been withdrawn from the market after they were belatedly revealed to pose greater health risks for women than for men.

One way to increase population validity is random sampling: using a chance method for selecting a sample to investigate from the population (this is not the same as randomization, which relates to group assignment). In a random sample, every member of the population has an equal chance of being selected for participating in an experiment. Unfortunately, hardly any experimental sample of human subjects is randomly selected. Many experiments only involve “convenience samples” like college students or social media users. But neither college students nor social media users are representative of the entire population of any country. Indeed, the criticism has been made of psychological research that almost all has been conducted on “WEIRD” subjects (Western, educated, industrialized, rich, and democratic), which are not representative of people across the world.

**Sample size** is the number of individual sources of data in a study; often this is simply the number of experimental entities or subjects. In section 3.2, we mentioned that indirect variable control requires a large enough sample to ensure chance variation doesn’t differently influence the experimental and control groups. A larger sample size also can improve the sample’s representativeness, simply by including more variation present in the broader population. Of course, this won’t help with variable values that are systematically excluded, like medical trials that enroll only men or psychological studies that enroll only college students in the United States. But, for variables that are included in the sample just by chance, a larger sample increases the values represented.

In general, then, a larger sample size increases the success of indirect variable control, thus increasing an experiment’s internal validity, and increases population validity, thus increasing an experiment’s external validity.

But the advantages of a large sample size must be balanced against the practical disadvantages. Large samples are more difficult to assemble and are more difficult and expensive to manage in the experiment. There are also diminishing advantages to samples beyond a certain size that are not intentionally more representative. It would be a bigger improvement for a psychological study to enroll subjects of different ages and education levels than it would be for the study to enroll 5,000 US college students instead of 1,000 US college students.

Another choice in experimental design concerns how many groups to include in an experiment. So far, we have focused on experiments with two groups: an experimental group and a control group. More complicated experimental designs include multiple experimental groups, each of which experiences a different but related intervention. For example, returning to our imagined fertilizer experiment, we may want to compare our homemade fertilizer both to a commercial fertilizer and to no fertilizer at all. Including multiple experimental groups can be enlightening, and it can lead to surprising outcomes. But this also complicates experiments, making them more difficult to perform, and it makes it more difficult to get an adequately large sample size for each group. Having multiple experimental groups also can make analysis of the results more difficult. For these reasons, experiments are usually performed with as few experimental groups as researchers deem absolutely necessary to get the needed comparative data.

#### Background knowledge and alternative hypotheses

The design of experiments is influenced by existing scientific knowledge. Existing knowledge shapes what hypotheses are developed and what expectations scientists have based on a hypothesis. Due to past research by others, Newton’s experiments presumed that light is a substance that travels from a light source. From Newton’s hypothesis that white light is composed of colors, Newton developed the expectation that a rainbow of light could be recombined into white light—an expectation his two-prism experiment was developed to test. This expectation relies on the idea, part of background knowledge about light, that changes to light can be reversible. Existing scientific knowledge also helps guide scientists’ interpretation of experimental results as evidence in favor or against some hypothesis. For example, the finding that a rainbow spectrum becomes oblong surprised Newton, since he knew from existing research that light typically travels in straight lines.

The reliance of experiments on existing knowledge is unavoidable, but it does create some challenges. What if any of that existing knowledge is wrong? Scientists have to rely on existing ideas to design properly functioning experimental instruments and to know what expectations to draw from their hypotheses. But they also have to rely on properly functioning instruments to test their theories with trustworthy experimental data and on the relationship between hypotheses and expectations to know what conclusions to draw about hypotheses on the basis of experimental data. Indeed, the existing knowledge that informs experimentation could turn out to be wrong.

But scientists have some resources to diminish the risk. First, researchers often have a good sense for what ideas are plausible enough to be trustworthy as the basis for experiments and which are new and risky. Second, over time, researchers refine not just their theories but also instruments and experimental designs. This can involve experimental work in replication or calibration, as discussed in section 3.4. Scientists can conduct an experiment or analyze data using different instruments or techniques to detect any variation depending on instruments or experimental design, called triangulation, and then use this to refine their theories, instruments, and experimental methods.

Another challenge in using experiments to definitively test hypotheses is underdetermination: the evidence may not be sufficient to determine which of multiple hypotheses is true. Consider again the experiment we imagined to test whether homemade fertilizer improves plant growth. Even if you clearly defined expectations if the hypothesis is true (plants receiving the homemade fertilizer grow faster than others), perfectly controlled extraneous variables with your experimental design, and collected data that matched your expectations, the truth of your hypothesis wouldn’t be guaranteed. At the outset of the chapter, we imagined testing the hypothesis that urine is an effective fertilizer, and so let’s suppose that’s the fertilizer under investigation. You take a daily multivitamin: is that the only reason the urine was an effective fertilizer? We can’t know without a new experiment. These kinds of questions are always possible, but scientists can’t think of every possible hypothesis. It’s always possible that some unimagined hypothesis that hasn’t been tested accounts for the experimental results.

How should scientists proceed in the face of underdetermination? One response would be to suspend judgment about which hypotheses should be accepted. But this isn’t an option when we need to build a bridge or design an effective drug. Instead, scientists must diligently attempt to consider alternative hypotheses that might account for the data, testing alternative hypotheses that seem potentially credible. Additionally, hypotheses that fit with the available experimental data are sometimes more or less appealing in other regards; for example, they may be simpler or fit better with other scientific knowledge. These considerations may push us toward one or another hypothesis when the data underdetermine which is true. Ultimately, underdetermination simply requires continuation of the spirit of openness to falsification that we identified as essential to science.

##### EXERCISES

3.13 Recall: Define internal experimental validity, external experimental validity, population validity, and ecological validity. For each, describe its specific importance and how it can be improved.

3.14 Recall: What are the main advantages and disadvantages of a laboratory experiment? How about a field experiment?

3.15 Apply: For each of the following hypotheses, indicate (a) whether you would study it in the lab or in the field, briefly describing why, (b) what steps you would take to control extraneous variables, and (c) whether you are more confident about the internal or external experimental validity of your study and briefly describe why.

- a. Whether peacocks’ colorful trains play a role in their mating success
- b. Whether a new fertilizer improves plant growth
- c. Whether watching a television show about sharing improves children’s ability to share their toys

3.16 Recall: Describe how sample selection, sample size, group number, and group assignment are each important to experimental design. For each, describe the negative effect a wrong choice can have.

3.17 Apply: Suppose you want to test the hypothesis that baseball players who eat pizza every day hit more home runs. Let’s suppose that to test this hypothesis, you want to divide the baseball players of some team into two groups that are balanced in all important background variables that can affect players’ performance. The only difference you want between the two groups is that the members of one group eat pizza every day and the members of the other group do not.

Rank the following four strategies from best to worst for accomplishing this goal:

1. Sit in the clubhouse after a game. The first players who enter the clubhouse are assigned to the group of pizza eaters (the experimental group), while the following players are assigned to the control group.
2. Allocate players born in the first six months of the year to the experimental group and players born in the second six months of the year to the control group.
3. For each player in the team you toss a coin. If the coin lands on heads, then the player is in the experimental group; otherwise, the player is assigned to the control group.4. Scientific experiments
4. Assign all players over 230 pounds to the experimental group and the rest of the players to the control group. Justify each of your rankings by describing how well or poorly you expect that strategy will control the extraneous variables.

 3.18 Recall: Describe the challenges that reliance on background knowledge and untested alternative hypotheses pose to testing hypotheses with experiments. How can scientists manage each challenge?

### 3.4 OTHER USES OF EXPERIMENT

After reading this section, you should be able to:

- Define crucial experiment and indicate three limitations of these experiments’ decisiveness
- Describe the use of experiments in replication and calibration and give examples of each
- Indicate how exploratory experiments differ from experiments to test hypotheses

#### Crucial experiments and replication

Albert Einstein’s theory of general relativity revolutionized our understanding of space and time. While Newton believed that space is a sort of stage on which events unfold, Einstein conceived of space and time as a single interwoven manifold, a fabric of sorts. For Newton, gravity was a force; Einstein instead explained gravity as the curvature of the space‐time manifold. Just as marbles placed on a fabric sheet held in the air bend the sheet around them, massive objects like the Sun warp space‐time in their vicinity. That’s why other objects accelerate toward those massive objects. Einstein’s theory of general relativity leads to testable hypotheses. One of these hypotheses is that light, just like any other form of matter, is affected by gravity. This hypothesis, in turn, generates the expectation that if a beam of starlight passes near the Sun it will bend toward the Sun.

This expectation was first tested on May 29, 1919, when a total solar eclipse blocked out the light of the Sun. A group of scientists led by Arthur Eddington took photographs of stars visible near the dimmed Sun. These scientists compared these to other photographs taken at night when the light of those same stars did not pass close to the Sun before reaching Earth. These data confirmed Einstein’s prediction of the starlight’s deflection. The Sun changed the path of nearby starlight as the theory of general relativity predicted, providing confirmation of the theory. When the press reported that a key prediction of Einstein’s theory had been borne out by observation, Einstein became a famous public figure.

Eddington’s test of Einstein’s new theory was a crucial experiment, an experiment that decisively adjudicates between two hypotheses. This kind of dramatic experimental result is exciting, but even crucial experiments do not yield scientific knowledge.

 As we have seen, even well‐designed experiments face numerous potential sources of error: unidentified confounding variables, reliance on background knowledge that might be wrong and techniques or instruments that might not work as intended, and unidentified alternative hypotheses that might account for the data rather than the hypothesis under investigation. These potential sources of error cannot be eliminated with one single experiment, and so science has developed experimental techniques to minimize the risks of these errors.

One is replication. Replication is performing the original experiment again—often with some modification to its design—in order to check whether the result remains the same. If, for example, Newton’s two‐prism experiment is replicated by different people, using different prisms, in different places and at different times, and they also observe the spectrum of light recombining into white light, this additionally supports Newton’s hypothesis that white light contains a spectrum of color. This shows that no oddities of Newton’s equipment or circumstances is responsible for the result, increasing internal experimental validity. Replication attempts that vary features of the experimental design—the experimental subjects or subject selection, the types of instruments or surveys used, and so on—can increase external experimental validity.

The replicability of experimental outcomes is an important ingredient of science, so much so that a persistent failure to replicate experimental findings may undermine a scientific field’s credibility. If some experimental result cannot be replicated—if different scientists follow similar experimental procedures but do not get the same result—then the original experimental result might be a fluke, or it might be due to some confounding variable in the experimental setup that the scientists haven’t yet identified.

For example, it has been suggested that the field of social psychology faces a crisis in replicability, where different research groups have tried but failed to replicate some classic experimental results. Thus, we shouldn’t put too much stock in those findings, unless this failure in experimental replicability is resolved.

##### Box 3.2 The replication crisis

Nobel Prize winner Daniel Kahneman wrote an alarmed open letter to social psychologists in 2012. He pointed out that prominent results in priming research, which is the study of how subtle cues can unconsciously influence social behavior, failed to replicate. Kahneman claimed that this field had become “the poster child for doubts about the integrity of psychological research.” This was the alarm bell that psychology was probably suffering from a replication crisis: original experimental findings widely cited by other researchers and taught to students as “facts” failed to replicate when similar experiments were performed again by other researchers. This was worrisome, as the trustworthiness of science partly depends on the idea that studies repeated under similar conditions will produce similar results.

Further, it’s not only research in social priming that suffers from problems in replicability. Important published results in the psychological, social, behavioral, and biomedical sciences have also failed to replicate. Researchers in these fields have started to discuss various potential reasons for the crisis, including sloppy experimental design and statistical analysis, publication bias, and outright fraud. And various remedies have been proposed too, such as reforms in statistical analysis, changed publication practices, more careful and powerful study designs, and—more generally—a call for open science, whereby all research practices and data are made freely available for anyone to scrutinize or use.

The importance of replication fits with the idea that science is essentially a collaborative, social venture. Gaining scientific knowledge via experimentation is generally more complicated and slower than a single dramatic experiment. This also means that scientific knowledge can go in unexpected directions. A surprising finding that upends something we thought we understood might be right around the corner.

#### Calibration

To persuade other members of the Royal Society that his hypothesis about light was true, Newton had to show that his prisms were reliable scientific instruments. For this reason, many of Newton’s experiments aimed at testing how prisms with different shapes and composition affected the light spectrum produced. Supported by Newton’s extensive data and theory of light, prisms became accepted scientific instruments.

As this illustrates, experiments also can be used to evaluate whether scientific instruments function as intended and to calibrate scientific instruments. Calibration, comparing the measurements of one instrument with those of another to check the instrument’s accuracy and adjusting it if needed, was introduced in section 3.2. This is required not just for technical apparatus like prisms and thermometers but also for surveys or questionnaires used with human subjects. Any instrument for data collection must be calibrated using known measurements before it can be used in an experiment with uncertain results.

Brain imaging techniques are a nice illustration of using experiments to establish the function of an instrument and to calibrate it for data collection. fMRI machines track blood flow in the brain. They do not directly measure neural activity, but that is what the scientists employing these machines want to assess. Neuroscientists use data about blood flow to track neural activity because they know that greater neural activity requires more energy, which requires increased metabolism, which uses more oxygen, and oxygen is delivered by blood flow. The confidence that blood flow in a brain region is a reliable measure of neural activity is confirmed by experimental findings concerning brain metabolism and the relationship between different brain areas and functions. Experiments have been run over decades to additionally develop fMRI techniques and to improve their calibration as a tool to study neural activity.

Calibration requires establishing measurement standards, or rules to regulate the use of quantity concepts and to create a meaningful scale to apply across instruments. Examples include the standard kilogram for weight or mass measurements and setting the freezing and boiling points of water at 0° C and 100° C, respectively, as temperature reference points. A standardized scale enables measurements to be compared over time and across instruments. This body of measurement data might then be used to construct more stable measurement scales and more accurate instruments.

Measurements can be based on the value of physical constants, or quantities that are believed to be universal and unchanging over time, and these are also determined experimentally. From 1889 until 2019, the standard kilogram was defined by a physical measurement standard—a physical prototype with a mass that was, by stipulation, exactly one kilogram. In 2019, the kilogram was redefined on the basis of the Planck constant, a quantity in quantum physics.

However, no scientific instrument is perfectly precise. In 2017, scientists at the National Institute of Standards and Technology (NIST) used a Kibble balance—an instrument that uses electric current to produce extremely accurate measurements of mass—to determine the most precise value yet of the Planck constant. Even after more than 10,000 measurements with this specialized instrument, a small degree of uncertainty about the exact value of the Planck constant remained. Future experiments that further refine the measurement of the Planck constant will in turn change (very slightly) how the mass of a kilogram is defined. (The value of the Planck constant is about 6.62607015 × 10−34 J/Hz if you were wondering.) Another physical constant measured experimentally is the speed of light in a vacuum. The measure of this constant has been refined from the 18th century through late 20th century, and it is used to define standard measures of both distance (the meter) and time (the second).

#### Exploratory experiments

In 1800, the British astronomer William Herschel used a telescope to observe sunspots, which are regions on the Sun that appear temporarily dark. Observing sunspots is hazardous for the eyes, and so he used colored glass filters to reduce the intensity of the rays. Herschel noticed that he could feel the Sun’s heat coming through the filters, and different filters seemed to differ in temperature. Since the filters were made of the same material, Herschel wondered whether the different colors of the filters might actually be responsible for the temperature differences. Notice that this wasn’t what Herschel had set out to investigate; sometimes experiments take us in unanticipated directions.

Herschel tested his hypothesis about a relationship between light’s color and temperature by directing sunlight through a prism to spread the spectral colors, as Newton had. Then he measured each color—red, orange, yellow, green, blue, indigo, violet—with a mercury thermometer. He also measured the ambient temperature in the room in order to have a baseline temperature to compare with the temperature measurements of the light. This setup yielded data in the form of measured values of color and measured values of temperature, which could be used as evidence to evaluate the hypothesis that different colors of light differ also in temperature. The evidence confirmed this hypothesis: Herschel found that the temperatures increased incrementally from the “cool” colors like blue to the “warm” colors like orange.

Another of Herschel’s observations in this experiment introduced a new question about light. Herschel also measured the temperature of the air just beyond the beam of red light, outside the edge of the spectrum created by sunlight through the prism, where no light was visible. His hypothesis was that this temperature would be the same as the ambient temperature in the room, since it was beyond the edge of the light spectrum. To his surprise, the temperature at that location was much warmer than the ambient room temperature, even higher than any of the temperature measurements for the light spectrum. How could that be?

Herschel’s observation immediately led to a new hypothesis: invisible, hot light exists just beyond the red part of the visible spectrum. This hypothesis—anticipated by the French physicist Émilie du Châtelet almost 65 years earlier—explained the observation that the temperature continued to increase beyond the edge of red light. Later observations confirmed this hypothesis, and we now accept the existence of this hot, invisible light. It’s called infrared light.

A further role of experiments, beyond hypothesis-testing, replication, and calibration, is exploratory. Exploratory experiments may not rely on existing theory and are Herschel’s experimental setup to test the relationship between color and temperature of light not aimed to test a specific hypothesis; instead, they are used to gather data to suggest novel hypotheses or to assess whether a poorly understood phenomenon actually exists.

Herschel’s work on the relationship between heat and light did not rely on a particular theory or a hypothesis about that relationship. When, while investigating sunspots, he discovered that red light is warmer, Herschel surmised that the light spectrum is made of both heat and colors. This idea was on the right track, but it was not until James Maxwell’s theory of electromagnetic radiation that Herschel’s observations could be adequately explained and his work vindicated.

##### EXERCISES

3.19 Recall: Define crucial experiment and describe three limitations of crucial experiments’ decisiveness.

3.20 Recall: Describe why replication is important and how replication can improve internal and external experimental validity.

3.21 Recall: Describe how calibration relies on measurement, and what role experiments play in measurement.

3.22 Think: Briefly describe three roles for experiments other than testing hypotheses, and give an example of each. Then discuss how each of these might relate indirectly to testing hypotheses.

3.23 Think: Describe how exploratory experiments differ from experiments to test hypotheses. Consider the important features of experimental design. What are some drawbacks to exploratory experiments, related to expectations, extraneous variables, and experimental design?

3.24 Apply: Before Ibn al-Haytham’s work, some thought that vision involved light shining out of the eye, coming into contact with objects, and thereby making them visible. This was known as the emission theory of vision. Ibn al-Haytham set up the following experiment to test the emission theory. He stood in a dark room with a small hole in one wall. Outside of the room, he hung two lanterns at different heights. He found that the light from each lantern illuminated a different spot in the room. For each, there was a straight line between the lighted spot, the hole in the wall, and one of the lanterns. Covering a lantern caused the spot it illuminated to darken, and exposing the lantern caused the spot to reappear.

1. What is the independent variable and what is the dependent variable?
2. How did Ibn al-Haytham control extraneous variables?
3. How did the experimental result provide evidence against the emission theory?
4. Describe one way in which the emission theory might be adapted to account for the data (but still remain an emission theory of vision).
5. Describe a new hypothesis you can formulate based on the results of Ibn al-Haytham’s experiment.

##### FURTHER READING

For an introduction to the philosophy of experiments with a focus on the natural sciences, see Hacking, I. (1983). *Representing and intervening: Introductory topics in the philosophy of natural science*. Cambridge University Press.

For more on the experimental approach in the social sciences with a focus on economics, see Guala, F. (2005). *The methodology of experimental economics*. Cambridge University Press.

For a case study on the role of instruments and measurements in experiments and studies, see Chang, H. (2004). *Inventing temperature: Measurement and scientific progress*. Oxford University Press.

For a recent perspective on replicability and the so-called replicability crisis, see Romero, F. (2019). *Philosophy of science and the replicability crisis*. Philosophy Compass, 14 (11), 1–14.

## CHAPTER 4 Non-experimental investigation

### 4.1 PALEONTOLOGY AND NON-EXPERIMENTAL STUDIES

After reading this section, you should be able to:

- Describe how scientists have learned about woolly mammoth and mastodon life histories
- Give examples of when an experiment is impossible, impractical, and unethical
- List three varieties of empirical investigation that can be used when intervention is not possible

#### Prehistoric life histories

The woolly mammoth (*Mammuthus primigenius*) is an extinct species most closely related to today’s Asian elephants. It’s one of the best understood prehistoric animals, with research based on preserved bones and dung, depictions in prehistoric cave paintings, and even frozen carcasses found in Siberia and North America.

Research on woolly mammoths isn’t based on conducting experiments. Paleontologists can’t control the conditions encountered by woolly mammoths, of course, or recruit them into experimental and control groups. Indeed, they can’t intervene on woolly mammoths at all, since the last mammoths died millennia before the invention of science. Scientists can directly study some features of mammoths—namely, physical and chemical features of their preserved carcasses, skeletons, teeth, and dung—but they are also interested in other mammoth features that can’t be studied directly, like their diets, habitats, social interactions, and migration patterns. These features relate to woolly mammoth’s life history: the traits and circumstances that affected survival and reproduction of members of the species.

The impossibility of experimentation doesn’t mean paleontologists are at a dead end, unable to gain knowledge about woolly mammoth physical traits and life histories. Instead, they just have to get a little creative about where they find evidence and how they draw inferences.

For example, a 2021 article in the journal *Science* reported the results of chemically analyzing the tusk of a woolly mammoth that lived 17,000 years ago. The researchers compared the isotopes of two elements (oxygen and strontium) to geographic maps showing isotope variation in the environment. Because of how tusks grow over a mammoth’s lifespan, this comparison enabled the researchers to identify where this particular woolly mammoth moved across its lifetime. It was found to have a very extensive geographic range, traveling very long distances across what is now Alaska.

The researchers could also see that the mammoth had different types of movements across its lifespan. In the first 16 years of its life, it moved repeatedly among the same territories, which is similar to how herds of elephants move today, suggesting the mammoth was moving with a herd. Then, in the middle of the mammoth’s life, the isotopic variation increases, suggesting it wandered irregularly over long distances, which in turn suggests that it had left its herd, as mature males in elephant species also do. Finally, in the last year and a half of its life, the mammoth moved only within a very small area. Its tusk also showed an isotopic pattern associated with starvation, which is probably how it died.

In this study, researchers were able to use chemical analysis to determine where one mammoth lived and how this changed over time, and then to draw further conclusions about its health and even its social interactions—that is, whether it lived in a herd. These conclusions aren’t just about this particular mammoth, but about other woolly mammoths as well, and potentially other similar species, especially that also lived during the Pleistocene era. Indeed, other scientists followed up on this study by performing similar chemical analyses on the tusk of an American mastodon (*Mammut americanum*) that lived about 13,000 years ago. Mastodons and woolly mammoths both lived in the Pleistocene era and were similar in appearance, but mastodons are less closely related to modern elephants.  

##### Box 4.1 The roles of museums in science

Visiting a museum is a way to learn about history, art, and science in an enjoyable and leisurely way. But museums also play an important role in scientific research. To start, many have extensive collections of artifacts that are useful as objects of scientific research. These can include fossils, artifacts from human history, preserved plants and animals, and more. Usually, a given museum will only display small portions of its collection at a time; other items in the collection can be available for scientific research. Many science museums also have scientists on staff: curators often have advanced degrees in relevant fields of science and conduct their own scientific research. It’s also common for science museums to have partnerships with nearby universities. Scientists at the university may access collections or collaborate with curators, and sometimes graduate students participate in research activities at the museum as well. There’s a trend toward making this research activity visible to members of the public who visit the museum. Sometimes museums include discussion of ongoing related scientific research in their exhibits or have lab space in which scientists can conduct research while guests and visitors look on.

These scientists were able to identify how the mastodon’s migration followed annual seasons, including adult springs and summers in an unusual location far from its typical range; this was inferred to be a mating ground. Life history research on both woolly mammoths and modern African elephants was also deployed to support conclusions from their data, for example, that the mastodon lived in herds, and also to draw conclusions from their research to a broader group of similar large mammals. Thus, both of these studies analyzed remnants from particular, long-extinct animals with reference to ecological data and knowledge about modern‐day related animals in order to draw conclusions about long‐ago happenings that we can never observe directly, let alone intervene upon.

#### When experiments aren’t possible

In the paleontology research just described, the scientists couldn’t directly or indirectly control variables, intervene on, or even directly observe the phenomena under investigation. Experiments just aren’t possible. Instead, they brought together various forms of evidence to draw inferences about mammoth and mastodon life histories.

This is one reason experiments can’t be performed: sometimes it’s downright impossible to experiment on the phenomenon under investigation. The phenomenon may have occurred eons ago, like the life histories of Pleistocene mammals, or might occur far away, like star formation in nebulas, or it might be impossible to intervene on, like the Earth’s orbit around the Sun.

Other times, experimental intervention might technically be possible but is impractical or inadvisable. We might wonder what would happen to the solar system if the Earth’s moon exploded, but no one is rushing to develop the capacity to explode the moon in order to find out. And, though it’s important to research how childhood trauma impacts health in adulthood, it’s simply unethical to perform experiments to find out, as that would require randomly assigning children to the experimental condi‐tion of experiencing significant trauma.

In instances like these, scientists need to employ methods of empirical investigation that do not rely on experimentation. Some of these methods adhere closely to experimental methods, only deviating when necessary. For example, although scientists can’t randomly assign children to an experimental group that experiences significant trauma and a control group that does not, they can compare the later health outcomes of children who experience trauma to those who do not, attempting to ensure other variables do not differ consistently between the experimental and control groups. This is an observational study: data is collected and analyzed without performing interven‐tions and sometimes without aiming to control extraneous variables. Observational studies are especially common in studying human populations, as in the health sciences, educational research, psychology, and economics, as it is unethical or impractical to intervene on many circumstances of human life.

Scientists have developed numerous approaches to observational studies. These differ from experiments in a variety of ways and can use creative methods to manage extraneous variables. Other methods of empirical investigation deviate more fully from experimental methods. We have seen that paleontology research into mammoth and mastodon life history utilizes several different forms of evidence to piece together a picture of what things must have been like. This is a common approach to empirical investigation in the historical sciences, fields of science that investigate past events, such as archaeology, paleontology, and cosmology—the scientific study of the origin and development of the universe. Another category of empirical investigation relies on extensive data or simulation, such as computer simulations, as the basis for gaining knowledge when experiments aren’t possible or feasible.



##### EXERCISES

4.1 Recall: Describe how scientists have learned about woolly mammoth and mastodon life histories. What forms of evidence have they used? What kinds of conclusions have they drawn?

4.2 Think: Describe at least two ways in which the mastodon research described earlier built on the woolly mammoth research also described.

4.3 Recall: What are three reasons that scientists can not always perform experiments? Give an example of each.

4.4 Apply: Give an example of potential scientific research in each of the following categories:

- a. performing an intervention is impossible
- b. performing an intervention is impractical
- c. performing an intervention is unethical
- d. direct observation is impossible

4.5 Recall: List three varieties of empirical investigation available when intervention is not possible; briefly describe each.

4.6 Apply: Imagine you would like to know what your friend’s favorite restaurant is, but you can’t ask her directly. List 10 ideas for how you might get evidence bearing on this question. Put a checkmark next to the 4–7 ideas that you think would be the easiest evidence to obtain. Then, put an asterisk (*) next to the 4–7 ideas that you think would generate the strongest evidence. Write 2–3 sentences analyzing the potential kinds of evidence, the ease of collecting them, and their strength. Then, describe how you would approach your “study”—that is, which form(s) of evidence you would collect and how you would go about collecting it.

### 4.2 OBSERVATIONAL STUDIES

After reading this section, you should be able to:

- Describe and give an example of natural experiments, longitudinal studies, cohort studies, case studies, and phenomenological analysis
- Indicate three ways observational studies can manage extraneous variables
- Characterize the similarities and differences between each type of observational study and experiments

#### Natural experiments

Every now and then, nature gives rise to circumstances that are almost like an experiment. These so-called natural experiments occur when an intervention on an independent variable occurs naturally in real life, without scientists bringing it about. An example is the case of Louis Leborgne, who lost the ability to speak when he was about 30 years old. He could utter only a single syllable, tan, which he usually repeated twice in succession, giving rise to his nickname “Tan Tan.” Apart from his inability to speak, Leborgne exhibited no symptoms of physical or psychological trauma. He could understand other people, and his other mental functions were apparently intact. After Leborgne died at the age of 51 in a Paris hospital in 1861, the physician Paul Broca performed an autopsy. He found that Leborgne had a lesion in the frontal lobe of the left hemisphere of his brain, an area that came to be known as Broca’s area and recognized as essential to speech production.

Broca’s insight into brain activity was based on identifying accidental circumstances that altered speech production, which we can think of as the dependent variable, and then studying what was different in Leborgne’s brain that might give rise to the dramatic change. The function of Leborgne’s brain was not intervened upon by Broca; Leborgne just happened to suffer damage to a precise location in the brain such that Broca could later identify it as crucial for speech production. Broca conjectured that a specific area in the human brain is necessary for speech, from which he developed the expectation that an injury in Broca’s area causes the loss of speech—an expectation confirmed with an autopsy after Leborgne’s death. This inability to produce speech is now known as Broca’s aphasia.

Natural experiments also occur when groups just happen to get sorted accidentally—without any scientific intervention—into something approximating experimental and control groups. Some natural or historical process separates them out, such that one group but not the other can be construed as receiving an experimental treatment or condition. For example, in the early 2000s, researchers investigated how having women village council leaders, known as Pradhan, in India might affect social services. This was a natural experiment relying on a 1993 Indian constitutional amendment that required one-third of Pradhan positions to go to women. The law was structured so that the change in leadership was randomly implemented across villages, mimicking a surgical intervention. Researchers collected data on 265 village councils in West Bengal and Rajasthan, including the minutes of village council meetings and Pradhan interviews. They also collected data about social services and infrastructure in each village and requests that had been submitted to the village council. The Pradhan’s policy decisions and villagers’ requests were unaffected by their interactions with the experimenters, since those requests and decisions were already made during data collection. The researchers found that women policymakers had important effects on social service policy decisions. Women Pradhan increasingly invested in the social goods that were more closely connected to women’s concerns in a village: drinking water and roads in West Bengal and drinking water in Rajasthan. They invested less in public goods connected to men’s concerns: education in West Bengal and roads in Rajasthan.

As this example illustrates, governmental policy can support natural experiments or at least indirectly control some variables in an observational study. Many studies examining the impact of the Covid‐19 pandemic and pandemic policies like stay‐at‐home orders or remote school instruction relied on variation in policy to create quasi‐experimental conditions.

For example, an observational study evaluating pandemic‐related learning loss in elementary‐school students compared the standardized test scores of Ohio third graders in school districts that began the 2021 school year in remote instruction, hybrid instruction, and in‐person instruction. This study benefits from both direct and indirect variable control from law and policy. All Ohio third graders are required by law to take the same standardized test at the same time of year. But, school districts across the state varied in when they returned to in‐person instruction—from the start of the 2021 school year in August to spring of 2022. That variation enabled researchers to determine whether additional time in remote instruction extended learning loss. And it did: all districts saw a decrease in student proficiency, but 11.2% fewer students who began the year with remote instruction met the state benchmark for advancing to fourth grade, whereas 6.5% fewer students with hybrid instruction and 5.3% fewer students with in‐person instruction met the benchmark to advance.

#### Managing extraneous variables

As stressed in Chapter 3, experimental methods are designed to eliminate the possibility of confounding variables through direct and/or indirect variable control. The same principles apply in observational studies, though researchers must seek circumstances that naturally hold extraneous variables constant (direct control) or vary them randomly (indirect control), or they must use techniques to manage extraneous variables when direct and indirect control aren’t possible. Circumstances sometimes perfectly mirror experimental conditions, giving rise to natural experiments, but it is common in observational studies for there to be extraneous variables that circumstances do not directly or indirectly control.

Scientists have developed various methods to manage uncontrolled extraneous variables in observational studies. For example, in the study on Covid‐19 learning loss just mentioned, school districts were not randomly distributed across the conditions of remote, hybrid, and in‐person instruction. So, researchers used the data to estimate the impact of other factors like unemployment and poverty level on learning loss and then they calculated how that effect would impact remote versus hybrid versus in‐person districts. They found that those extraneous variables did not account for the difference observed.

Another method sometimes used to help account for extraneous variables is to match subjects with different characteristics across the different conditions, and then only investigate outcomes for those subjects. For example, if this method had been employed in the Covid‐19 study just discussed, researchers would identify individual third graders in remote, hybrid, and in‐person instruction and attempt to match them with similar third graders across these instructional formats, attending to potential confounding variables like income level, race, prior academic achievement, and family unemployment or illness. This method isn’t as successful at controlling variables as random group assignment, but it goes some way toward correcting for confounding variables (as long as researchers are already aware of them).

Other approaches to accounting for extraneous variables make use of the passage of time. In a longitudinal study, observations are made of the same variables over time, in many cases over a long period of time. The study on Covid‐19 learning loss we have been discussing is a longitudinal study: the researchers compared standardized test performance of all third graders in Ohio public schools in 2022 with the performance of third graders in Ohio public schools in prior years. Unlike all prior students, third graders in 2022 had experienced educational disruptions from Covid‐19, and there’s good reason to think Covid‐19 and its downstream effects are the only major differences between these third graders and those of prior years.

Longitudinal studies can be carried out over many years. The Early Childhood Longitudinal Study was started by the US Department of Education in the late 1990s and has followed 20,000 American children, examining their development, performance at school, and early school experience. Researchers also conducted extensive interviews with the subjects’ families. This study provides a lot of information about American children’s development and family life, such as what is important about kindergarten experiences for later academic success, and whether offering Algebra I to eighth graders as an online course is effective. (It is.) Early Childhood Longitudinal Studies continue, with the latest following the kindergarten class of 2023–2024 through the fifth grade.

One type of longitudinal research is a cohort study, where researchers select a group of subjects sharing some defining trait and study them over time, in comparison to another group of subjects that is as similar as possible except without this trait. Cohort studies can reveal changes over time in the characteristics of the group of subjects with the trait of interest. For example, subjects with Covid‐19 may be grouped according to demographics like age and gender, or treatments they received, and then have their health outcomes assessed.

# Case studies

One form of observational study that is quite different from a controlled experiment is a case study, a detailed examination of a single individual, group, system, or situation in a real‐life context. Case studies allow researchers to gain a first‐hand understanding of a phenomenon as it occurs in its specific context. Often, various sources of data are used for case studies. Depending on the phenomenon under investigation, these may include observations of a person’s daily routine, unstructured interviews with participants and informants, letters, e‐mails, social media activity, legal or archival records, buildings, animal or plant behavior, and so forth.

A defining feature of case studies is their reliance on qualitative data. Qualitative data consist of information in non‐numerical form, whereas quantitative data are in numerical form, which makes them easily comparable. For example, “the subject reports being very angry” and “the subject reports being not angry at all” are qualitative data, whereas “the subject reports their anger is a 3 on a scale of 1–5” and “the subject reports their anger is 1 on a scale of 1–5” are quantitative data. Case studies are often employed in the context of qualitative research in epidemiology, psychiatry, education, ethnography, archaeology, and other social sciences.

Case studies may focus on an instance of a common situation or condition, or they may focus on outliers, that is, individuals or situations that deviate from what’s common. An example of a case study on a common situation is the research reported in the 2013 book Paying for the Party by education researcher Elizabeth Armstrong and sociologist Laura Hamilton. Armstrong and Hamilton conducted a five‐year study focusing on the college experience of one group of women at a large, public university in the United States. Their research reveals ways in which social and academic life at such a university prioritizes a “party pathway” catering to affluent and well‐connected students but disadvantages less affluent and first‐generation students, to the detriment of their education and future careers.

A downside to case studies is that they offer no ways to control extraneous variables or to compare a variety of outcomes. Because the research focuses on only one individual, event, or group, results can be difficult to replicate and to generalize. Case studies are also vulnerable to bias due to the evaluation of qualitative data and no blinding.

Yet, in some fields, detailed first‐person, qualitative reports of individual cases play important roles without necessarily aiming for reproducibility or generalizability. For example, clinical case reports often provide clinicians with accounts of surprising or novel conditions in an individual patient, which may generate contextually situated understanding of those conditions and new hypotheses about diagnosis and treatment. Case studies can also be valuable exploratory research, as a way to indicate promising foci for later experiments or more robust observational studies. For example, Armstrong and Hamilton’s research may set the stage for a broader investigation into how a university Greek system or certain majors differently affect students with differing socioeconomic status.

### Phenomenological analysis

Case studies sometimes reveal a first‐person perspective on some phenomenon or situation, that is, how things feel or seem to the subject of the investigation. You may wonder whether such subjective accounts can be of scientific value; after all, science involves empirical investigation and comparison across individual perspectives. It’s true that there is oftentimes scientific value in generalizing from one individual’s perspective. But it’s also true that first-person perspective on situations a person is experiencing can be essential to scientific knowledge. First-person accounts of lived experiences play various roles in fields such as psychiatry, health sciences, sociology, and anthropology.

First-person accounts sometimes are called phenomenological to emphasize that they are grounded in the methods of phenomenology, a philosophical tradition concerned with making sense of embodied subjective experience. In science, phenomenological analysis aims to describe and analyze what some experience is like for a particular individual. Phenomenological analysis is focused on subjective experience. It simply makes no sense to say that one’s experience of, say, pain is incorrect if it varies from others, though we might contrast common experiences of pain with outlying experiences of pain.

##### Box 4.2 Phenomenological analysis

Phemenology is a tradition in philosophy that originated in Europe in the early 20th century. It includes the work of philosophers like Edmund Husserl, Martin Heidegger, Edith Stein, Maurice Merleau-Ponty, Aron Gurwitsch, and others. The etymology of the word phenomenology comes from ancient Greek and means study of that which appears. What unifies strands of research within the phenomenological tradition is their focus on the structures of consciousness as experienced from the first-person perspective. One central structure of conscious experience is its intentionality—that is, being about or of something.

Three methods in phenomenology to study the structures of conscious experience can be relevant to scientific fields like cognitive science, psychiatry, medicine, anthropology, and sociology. The first method consists in describing conscious experience as it is experienced, without influence by scientific or historical interpretation. Another method consists in interpreting conscious experiences by situating them in their social, material, and technological context. A third method consists in analyzing the essence of and conditions for different kinds of intentional states like perceptions, emotions, beliefs, and desires, pointing out their differences and similarities in relation to time, space, self, body, and interpersonal social relationships.

Phemenological analysis has been used in psychology and neuroscience to distinguish actions of our body that we feel a sense of agency over from mere movements we are not responsible for. This distinction is salient when you are, say, pushed or jostled: you experience your body moving but do not experience yourself as having performed that movement. In light of this distinction, psychologists and neuroscientists have designed experiments to investigate whether there are different mechanisms. responsible for these experiences. These experiments might help our understanding of symptoms of psychiatric conditions like the experience of thought insertion in schizophrenia, where an individual does not feel agency over some of their thoughts. In this example, phenomenological analysis helps clarify two distinct phenomena, which scientists can then probe with experiments and also compare with psychiatric patients’ accounts of their own experiences.

Phenomenological analyses can also play a role in medicine, particularly in relation to what it is like to experience illness and how healthcare providers communicate with patients. For example, phenomenological insight can inform the development of methods for better understanding a patient’s experience that go beyond verbal reports. Methods that tap into the experience of illness as an embodied phenomenon that affects one’s experience can yield insight into changes in movements and behaviors. This can help bridge the gap between patients’ experience of illness and healthcare providers’ understanding of the illness and, accordingly, improve patients’ trust in their doctors.

##### EXERCISES

4.7 Recall: Give a brief description and an example of natural experiments, longitudinal studies, and cohort studies, and then describe how each manages extraneous variables.

4.8 Apply: Look back at this section’s description of the study of standardized test scores of Ohio third graders in school districts in 2022, after educational disruption from Covid-19. Describe how direct and indirect variable control were each used in the study (without researcher intervention), how the researchers managed the extraneous variables of unemployment and poverty level, and why being a longitudinal study was important for variable control.

4.9 Recall: Give a brief description and an example of case studies and phenomenological analysis.

4.10 Think: Why are qualitative data essential for case studies and phenomenological analysis?

4.11 Apply: For each of the following hypotheses, decide whether it’s best investigated with an experiment or observational study and, if the latter, which variety of observational study (natural experiment, longitudinal study, cohort study, case study, or phenomenological analysis). Explain your reasoning, taking into account the hypothesis under investigation, the feasibility or ethics of experimentation, and other constraints.

- a. Whether rising interest rates make stock prices go up
- b. Whether men’s resumes are judged more positively than women’s, regardless of the resume content
- c. Whether Covid-19 patients admitted to a hospital sooner are less likely to die
- d. Whether a patient who is fidgeting feels greater pain (regardless of her reported pain level)
- e. Whether a new medicine is effective in decreasing symptoms of Parkinson’s disease

4.12 Think: Describe the example of phenomenological analysis in psychology and neuroscience or the example from medicine. In the example you’ve described, what do you think is added by considering a person’s subjective experience?

### 4.3 IMAGINATION AND COMPUTATION

After reading this section, you should be able to:

- Describe and give an example of thought experiments and computer simulations
- Define big data and machine learning and describe how these are used in scientific research
- Analyze the advantages and disadvantages of each of these non-experimental approaches

#### Thought experiments

The power behind experimentation is intervention and variable control. Observational studies employ a variety of different techniques to approximate this combination of intervention and variable control. Another way to proceed when direct or indirect variable control needed to run an experiment isn’t possible is to perform an intervention on something else more under our control. An opportunity for this is provided by our rich imaginations.

Thought experiments involve an imagined intervention on an imagined system to learn about the role of the independent variable in the real world. Thought experiments may supplement empirical investigation or, in some cases, can replace it entirely. In the right conditions, your imagination can be a reliable guide to learn about reality.

Here’s a simple example. Someone who does not often drink in bars stays out late one night in a bar with their friends. They awake in the morning feeling physiologically and psychologically poor. They might ask themselves how they would feel if, instead, they’d gone home earlier from the bar. They know enough about the circumstances and their own propensities to be able to infer that they’d have had fewer drinks, slept a few more hours, and now would be less dehydrated and better rested. They can’t go back in time to actually perform this intervention, and so they use this informal thought experiment to arm themselves with knowledge about how staying out late drinking in bars rather than going home to sleep (the independent variable) affects their physiological and psychological health the next morning (the dependent variable).

In science, thought experiments can be used to test a hypothesis, to show that nature does not conform to one’s previously held expectations, or to suggest ways in which expectations can be revised. In 16th‐ to 17th‐century Italy, Galileo Galilei used many thought experiments in his investigations of physics and astronomy. In one instance, he wished to investigate an idea shared by many “natural philosophers” of his time that objects with different weights fall at different speeds. Galileo asked his readers to assume that this was true: that heavier objects fall faster than lighter objects. He then imagined two objects, one light and one heavy, connected to each other by a string and dropped from the top of a tower. If the heavier object fell faster, then the string would pull taut. But, Galileo reasoned, both objects together are heavier than the heavy object on its own. So, the two objects together should fall faster than either object alone. The objects cannot simultaneously fall both faster and slower, and so the idea that was the starting point for this thought experiment could not be right. Galileo thus conjectured that the speed of a falling body is not dependent on its weight.

Newton also used thought experiments to help show how his theory of gravitation worked. He had readers imagine a cannon at the top of an extremely tall mountain and then asked: what would happen if somebody loaded the cannon with gunpowder, and then fired? Plausibly, Newton reasoned, the cannonball would follow a curve, falling faster and faster because of gravity’s force, and would hit the Earth at some distance from the mountain. But what if one used more gunpowder? The velocity of the cannonball would be greater, and it would travel farther before falling back to Earth following a curve trajectory. But if one used vastly more gunpowder, then, Newton suggested, the cannonball would travel so fast that it will fall all the way around the Earth, never landing. The cannonball would be in orbit, going around again and again just like the Moon! If the cannonball went even faster, then it would escape Earth’s gravity heading out in space. Newton’s theory of gravitation provided the resources to arrive at these same conclusions through mathematical calculations. Yet, imagining this situation gives a satisfying, intuitive sense for how an object like the Moon can stay in orbit by remaining in constant free fall.

In the 20th century, thought experiments were central to the development of both transformative theories in physics: the theory of relativity and quantum mechanics. An example that’s received some popular attention is the thought experiment about Schrödinger’s cat. Quantum mechanics treats subatomic particles mathematically as if they are not in discrete locations but probabilistically spread over possible locations, and there’s a longstanding and unresolved debate about how to interpret this mathematical characterization. When a technological apparatus is used to detect an electron, it is always in a single, discrete location. Are subatomic particles like electrons really not in discrete locations until they are measured? If so, what changes when they are measured?

Erwin Schrödinger, Nobel Prize‐winning physicist, asked us to imagine a cat, a readily observable living entity, in an apparatus that entangled its state with a subatomic particle such that the cat is killed if some quantum event occurs and not otherwise. Yet, quantum mechanics gives us just probabilities for whether the event occurs. If this is truly the state of the particle, then the cat is not definitively alive or definitively dead but in a probabilistic state between these. This result is inconsistent with our experience of reality, of the possible ways cats could be, and is meant to show that an answer is needed for how the mathematics of quantum mechanics should be interpreted for everyday experiences of reality. Note that this thought experiment was not intended as a challenge to quantum mechanics, which has significant evidence in its favor, but to demonstrate the need to offer an interpretation for how that theory relates to our everyday observations

Just like experiments, thought experiments may suffer from poor experimental design or from scientists inferring unjustified conclusions from them. An additional, very significant limitation is that experimental results are always limited by scientists’ powers of imagination. The world can surprise us, including in experimental results, in ways that thinking through the implications of ideas generally cannot. One possible response to the challenge of Schrödinger’s cat, for example, is just to point out that our imagination may be ill‐equipped to comprehend what we have never directly experienced, like the behavior of subatomic particles.

#### Computer simulations

As thought experiments can be used to imagine fictive interventions, computers can be used to simulate interventions. Computer simulations are computer programs developed from data to mimic a phenomenon. Examples of simulated phenomena might include ecological effects of global climate change, likely shapes of galaxies after two collide, and the progression of a pandemic under different circumstances.

Computer simulations play key roles in many fields of contemporary science, including climate science, astronomy, and epidemiology (the fields of the computer simulations used as examples in the previous paragraph). Computer simulations may be used in combination with experiments or observational studies, or they may be used when experiment or observational studies are not possible. Regardless, a significant amount of background knowledge about the phenomenon is required in order to develop computer programs that can adequately simulate the behavior of a phenomenon. This limitation is similar to the limitations of thought experiments: computer simulations are only as accurate as the data they are based on and how they are programmed.

By running computer simulations and intervening on their features, scientists can learn what would happen to a phenomenon in different circumstances or explore particular features. For example, computer simulations of the Earth’s climate use dynamical equations to model the interactions of solar energy, chemicals in the atmosphere, ice, and other factors over time. These simulations can then be studied to yield insight into how climate change is progressing, its variable impact on temperature and weather in different parts of the world, and the potential of different changes to slow or reverse its progression.

Computer simulations allow researchers to have extensive control over extraneous variables. After all, in computer simulations, the researchers decide what data to base the simulations on and what factors to take into account in the program. Computer simulations often can be easily evaluated for their degree of external experimental validity, in the sense that we can evaluate how well their results generalize from the contrived conditions to real‐world phenomena by comparing the results of the simulations to empirical measures of the phenomena. To the extent the simulation and the real‐world system it describes have relevant similarities, we can be more confident the computer simulation produces trustworthy, generalizable results.

There was more public attention to computer simulation in science during the Covid‐19 pandemic than perhaps at any previous time. Epidemiologists began to use computer simulations very early in the pandemic to predict rates of transmission, hospitalization, and mortality and to influence policy decisions on stay‐home orders and school and business closures. Early in the pandemic, these simulations were by necessity based on limited data that were rapidly developing as researchers learned more about the SARS‐CoV‐2 virus, its transmission, and its effects. Models provided broad ranges of possibilities for pandemic progression, and different models often varied radically in their predictions. Yet sometimes these limitations were overlooked or brushed aside, and scientists, policymakers, or the public interpreted the models as making highly specific predictions and different models as providing contradictory predictions.

This instance of computer simulation in science was typical in the sense that early simulations of novel phenomena—like exploratory experiments or early scientific investigations of other kinds as well—begin with some guesswork and involve iterative improvement. But this instance was highly atypical in the extensive publicity received by early predictions of computer simulations. Because that publicity was so unusual, there is a risk that people who don’t ordinarily pay attention to computer simulation in science will infer from its limitations early in the Covid‐19 pandemic that it is an untrustworthy technique. As we have noted, computer simulations are limited by the existing knowledge used to develop the computer program, as well as by what factors scientists include or exclude from the simulation.

#### Big data and machine learning

Experiments ultimately are valuable because they generate data and because we know certain things about the conditions in which the data were generated. Observational studies, thought experiments, and computer simulations seek to approximate this approach or seek other kinds of data. A very different approach is to simply maximize data and see what you can learn.

Big data are very large data sets that cannot be easily stored, processed, analyzed, or visualized with traditional methods. Big data sets can reveal unexpected patterns, trends, and associations. Scientific researchers use big data to study weather patterns, DNA, and risk factors for disease, among many other phenomena. Cameras, medical devices, e‐mails, social media, and the internet, have produced an ever‐increasing stream of data in recent years. Some scientific investigations also produce a tremendous amount of data to be processed and analyzed, especially those relying on computer technologies such as telescopes in astronomy and the Large Hadron Collider (LHC) at CERN. For example, if all the sensor data in LHC were recorded, this would approach 500 exabytes per day, or 500 quintillion (5 × 1020) bytes. And, the processing of scientific data has also gotten much faster. While it originally took ten years to sequence the human genome, completed in 2003, a genome can now be sequenced in less than one day.

Generally, an algorithm is a procedure for obtaining some outcome that halts in a finite number of steps. Machine learning algorithms in particular are step‐by‐step procedures run on powerful computers that enable scientists to mine large data sets for patterns or to perform other tasks. Machine learning algorithms have begun to play numerous roles in science, as well as business and our everyday life. When, for example, you search the internet, access social media, or order food online, there is some learning algorithm operating in the background that has learned how to rank web pages, make personalized suggestions about content you will probably like on social media, and coordinate food orders and timely deliveries. Once the algorithm learns what to do with data, it will perform such specific tasks automatically.

In scientific research, machine learning algorithms can mine data for patterns, process images and audio files, and make predictions. For example, imagine that you want to determine general trends in food preferences, and you have at your disposal a data set containing all social media posts produced in the past year. Filtering those posts to a subset relevant to food preferences is extraordinarily valuable, as is visualizing the data about the popularity of various foods. The patterns and trends uncovered by analyzing a large amount of data about some subject can give insight into relationships among variables of interest and can be used to make predictions.

Big data and machine learning can help limit the influence of researchers’ expectations on findings. For example, current classifications of mental illness, such as schizophrenia, are often criticized for being too coarse-grained and ill-defined to help clinicians and therapists make a reliable diagnosis and provide patients with adequate treatment. Because psychiatric classifications lump together several different psychiatric symptoms and variables that may have little in common, studies relying on machine learning for mining large sets of behavioral, biological, and other types of data from many patients and healthy subjects (as a control group) might discover more useful ways of classifying psychiatric conditions, even if these classifications are not intuitive to us.

The analysis of big data can even help us better understand how science works. For example, bibliometric methods, including the analysis of networks of citations in published work, can be used to investigate the level of productivity of a certain field of research, trends in the topics of scientific research, and even the social dynamics underlying scientific practice. The number of citations of a published article is an index of recognition, which is one of the primary rewards for scientists. So, citation rates and patterns can be used to quantify scientific impact and to predict what factors might affect the course of science.

But studies relying on big data and machine learning also raise distinctive challenges. One challenge is their opacity. The algorithms used in machine learning applications are sometimes unknown to outside researchers, because of security, business, or copyright reasons. This goes against the culture of open exchange that is typical of the social institution of science. Beyond this, how and why an algorithm returns a certain output—for example, a certain mental illness classification decision—can be difficult or impossible to explain even for the researchers who designed it. Finally, even the data on which the algorithm is trained may be unknown to the users of the algorithm.

This opacity is especially problematic because outputs or the underlying data may be misleading or biased, or researchers’ assumptions that influenced the algorithm may be wrong. In 2008, researchers from Google claimed that they could immediately predict what regions experienced flu outbreaks based simply on people’s online searches. The assumption was that when people are sick with the flu, they often search for flu-related information on Google. Unfortunately, this idea wasn’t borne out. Google Flu Trends made very inaccurate predictions, significantly overestimating flu outbreaks, and was shut down.

Another challenge with big data and machine learning techniques is how they may inherit researchers’ biases, an outcome they were designed to avoid. This is a negative result for scientific investigation in general, but it is especially problematic when the biases in question reflect sexism, racism, and other prevalent societal prejudices with actual real-life consequences. A prime example is a machine learning algorithm developed by the company Amazon in 2014 for employee recruitment. The algorithm was trained to review job applications automatically, indicating which applicants would be the best to hire. The algorithm had the unintended effect of systematically ranking male applications higher than female applications. Investigation revealed that the algorithm was trained on historical data about the performance of past employees at Amazon, and these employees were predominantly men. Because it was trained on this data set, the algorithm predicted that high‐performing employees would likely be men. When Amazon researchers realized this in 2018, they abandoned the hiring approach. This example illustrates how the opacity of machine learning algorithms can have unintended consequences with a real impact.

##### Box 4.3 Algorithmic fairness and justice

In many domains like business, law, insurance, police work, and healthcare, human decision-making is increasingly supported—and sometimes replaced—by machine learning algorithms. These algorithms attempt to compute predictions based on historical data on which the algorithms were trained. Algorithmic predictions can be objective, but they can also unwittingly reflect unfairness and human prejudices without any deliberative effort by programmers to include these in the algorithm. For example, Tay was a chatbot released by Microsoft Corporation in 2016, and shutdown shortly thereafter because it produced sexist and racist content on Twitter. COMPAS (Correctional Offender Management Profiling for Alternative Sanctions) was used by US courts to predict criminals’ risk of recidivism, but it produced a higher rate of false positives (non-recidivists incorrectly labelled “high risk”) for Black defendants than for White defendants and a higher rate of false negatives (recidivists incorrectly labelled “low risk”) for White defendants than for Black defendants. Cases like these raise difficult ethical and political questions, often grouped under the headings of algorithmic fairness, algorithmic justice, or algorithmic bias. One question concerns the right criterion of fairness—when it comes to recidivism, for example, should the criterion be equal rates of false positives and false negatives between two given groups, or should it be absolutely equal predictive accuracy across all individuals? A second question is whether algorithms are at least less biased than human decision-making without algorithms. Another question is whether, and why, algorithmic justice should be informed by secular, egalitarian, and liberal values rather than, say, Confucian values or politically conservative values.

##### EXERCISES

4.13 Recall: Watch Video 8 Describe and give an example of a thought experiment and a computer simulation.

4.14 Think: Describe the similarities and differences between thought experiments and computer simulations.

4.15 Recall: Define big data and machine learning algorithm and describe how these are used in scientific research.

4.16 Think: Describe how each of thought experiments, computer simulations, and machine learning algorithms are useful to gaining scientific knowledge. For each, what are the limitations in their usefulness?

4.17 Think: Describe three advantages and three disadvantages of scientific studies relying on big data and machine learning algorithms.

4.18 Apply: Algorithms and big data have an ever-increasing impact on our daily activities. Consider the following activities:

- a. Online dating
- b. Autonomous vehicles
- c. Police profiling
- d. Online trading
- e. Urban planning

Choose three of these activities, then, for each of the three, write a short paragraph describing one task an algorithm might perform and what type of data the algorithm might be trained on to learn that task. Then, formulate a question or concern about the behavior of the algorithm in that domain, explaining its importance. What reasons or values are relevant to addressing the question or concern?

### 4.4 MULTIPLE SOURCES OF DATA

After reading this section, you should be able to:

- Describe the steps of meta‐analysis and how meta‐analysis improves experimental validity
- Define methodological omnivory and indicate the circumstances in which it’s useful
- Characterize how methods of empirical investigation depend on the phenomenon under investigation, the circumstances, and the aims

#### Meta-analysis

As we’ve seen, observational studies employ various methods to control or account for extraneous variables. Nonetheless, many studies have limited utility. There may be fewer subjects than needed, confounding variables, no control group, or other foibles that limit their explanatory power. But experiments can have some of these same downsides, too; as emphasized in Chapter 3, most experiments cannot adhere to ideal experimental procedures.

The technique of meta-analysis offers a way to combine the results of multiple experiments or observational studies of the same hypothesis to strengthen the conclusions that can be inferred. The idea is that several studies, each with different limitations, can be combined to additionally account for extraneous variables and correct for other shortcomings. Meta‐analysis is thus used to better estimate the real extent of the independent variable’s influence on the dependent variable by combining the different findings of several distinct studies. Meta‐analysis can also identify patterns in study results, including helping to reveal and analyze possible reasons for conflicting results.

Meta‐analysis is especially common in healthcare research, but it is increasingly employed in other fields as well. To conduct a meta‐analysis, researchers first identify a question that has been targeted in existing scientific research—for example, whether and to what extent patients experience the placebo effect when they know they are receiving a placebo. (See Chapter 3 on the placebo effect.) Then, researchers conduct a literature search and decide which studies should be included in the meta‐analysis.

For each included study, an effect size (a quantitative measure of the strength of a phenomenon) is estimated from the study’s results, and then the effect sizes are combined using statistical methods that are beyond the scope of this book. This results in an estimate of the common effect size across the studies and also a measure of how much the study outcomes deviate from one another.

In the meta‐analysis of the placebo effect, researchers screened 1,246 studies and selected 11 to analyze. These included randomized controlled studies of any medical condition or mental illness that compared administration of a placebo with patients’ knowledge to no treatment at all. The application of relevant statistical methods resulted in the finding of a large overall effect size but also high deviation in effect sizes across studies. The studies included in the meta‐analysis assessed the placebo effect on improving symptoms from back pain, fatigue from cancer, attention deficit hyperactivity disorder, nasal allergies, depression, irritable bowel syndrome, and hot flashes from menopause.

From the large overall effect size, the researchers conclude that administering placebo medications, even with patients’ knowledge that they are receiving placebos, may be a promising treatment for several difficult‐to‐treat medical conditions and mental illnesses. The researchers also note that more research is required, especially regarding efficacy of the placebo effect for different conditions, how patients are notified of the placebo, and how patient expectations influence the treatment. Comparison across studies included in the meta‐analysis is used to identify these potential sources of variation to target for further study.

Meta‐analyses offer a way to consider and integrate the results from many existing studies, thereby increasing the knowledge gained from them and identifying sources of discrepancies in their results. Sources of discrepancies can include differences in the specific phenomena investigated (such as which health condition patients have), the experimental design (such as how patients are notified about the placebo), techniques of data analysis, and confounding variables (variation in patients’ mindset or expectations). All of this can be used to improve internal experimental validity by accounting for confounding variables as well as external experimental validity, including both ecological validity, through variation in study circumstances, and population validity, through variation in subject inclusion across studies. (See Chapter 3 for more on internal and external experimental validity.)

There are also some drawbacks and limitations to meta‐analysis. First, the results of meta‐analyses inherit any systematic flaws of the studies they combine. It can also be  difficult to control the influence of researcher bias, as there are unavoidable judgment calls in which studies to include in the analysis and whether some study has flaws that warrant its exclusion. Finally, the whole point of a meta‐analysis is to combine studies with different specifics and different findings to see what they reveal together.

The measure of deviation across study outcomes can identify the extent to which findings of individual studies vary, but beyond this, meta‐analysis ignores differences across studies that may provide important information. For example, it could be that the placebo effect is an especially promising treatment for some conditions but not others. Focusing on the strength of the placebo effect across a wide variety of medical conditions and mental illnesses may lead researchers to overlook or insufficiently attend to variation across these conditions.

#### Methodological omnivory

Recall the paleontology research into woolly mammoth and mastodon life histories from the beginning of the chapter. Experiments on living mammoths and mastodons simply aren’t possible, and scientists can’t conduct observational studies of these prehistoric creatures either. The targets of investigation are separated from the investigators by eons; they can’t observe behavior or collect direct evidence. Instead, as we saw, paleontologists creatively employed techniques of chemical analysis on the tusks of these extinct creatures with reference to ecological data and knowledge about modern‐day related animals in order to draw conclusions about long‐ago happenings that we can never observe directly.

Philosopher Adrian Currie has dubbed this approach in the historical sciences methodological omnivory, which is the use of multiple methods and specially tailored tools to generate evidence about specific targets. This approach is identifiable from scientists combining a number of distinct methods, often from multiple scientific fields, and also from significant investment in developing special tools tailored to specific evidential roles.

For example, the mammoth and mastodon studies used highly specific isotope analyses of layers of a tusk and extensive measurements of isotope ratios in the surrounding geologic formations to piece together a specific animal’s movements through its range during the different parts of its life. Comparison with migration and life history patterns of modern elephants enabled the researchers to draw other inferences from the animal’s movements, such as whether it moved with a herd and that it annually travelled long distances to a mating ground. These investigations were also supported by other past research into mammoth and mastodon physiology, lifespan, and more. Across studies like these on related phenomena, paleontologists can piece together more and more evidence to develop increasingly extensive knowledge of long‐ago creatures.

Another technique involved in the mastodon study was the development of a computer simulation that used the isotope data to calculate likely distances travelled and geographic locations. As this illustrates, computer simulations can be an important feature of methodological omnivory, as simulations are one way of drawing broader inferences from the data scientists are able to assemble.

When experimental data aren’t readily available, a variety of techniques from observational studies to computer simulations, big data, and meta-analysis are available for potential use. As we’ve seen, there’s no single answer to which of these methods is best. There are different recipes; and which ones are effective depend on the phenomenon under investigation, the circumstances of investigation, and the aims of the research.

Depending on the circumstances of the investigation, some phenomena lend themselves to data collection in quasi-experimental circumstances or to other forms of direct and indirect variable control. Sometimes, when ecological validity is important, these types of observational studies are better than experiments. Variability in a phenomenon and prioritizing first-hand experience increases the value of case studies and even phenomenological analysis. Thought experiments and computer simulations can provide indirect access to features of phenomena not available for experimental manipulation. And when phenomena produce a vast store of data, big data techniques and machine learning algorithms can be useful. If many empirical studies already exist, a meta-analysis of those studies can be more useful than direct empirical investigation. Finally, some phenomena are so distant in time or space that they can only be studied very indirectly, using various tools of simulation and studying their distant effects, as in paleontology and astrophysics.

##### EXERCISES

4.19 Recall: Describe the steps of meta-analysis. Then, describe how a meta-analysis can improve both internal and external experimental validity.

4.20 Apply: Find a published meta-analysis and look over the article (or, your instructor may provide one for you to analyze). Summarize the study, including how many studies were included, how the researchers selected those studies, if any were subsequently excluded, what conclusions they reached, and any concerns or open questions they indicated.

4.21 Recall: Define methodological omnivory and describe how the paleontology research into woolly mammoths and mastodons in section 4.1 illustrates its use.

4.22 Apply: Describe a new example of scientific research where methodological omnivory is used. What about this research and the circumstances in which it’s conducted make methodological omnivory useful? (Hint: you might consider research in a historical science, like anthropology or cosmology.)

4.23 Recall: List all the kinds of empirical investigation without experiments we’ve discussed in this chapter. (By our count, there are 11.) For each, briefly describe how it generates empirical evidence and in what kinds of circumstances it’s useful.

##### FURTHER READING

For a concise treatment of qualitative research and its methodology, see Golafshani, N. (2003). *Understanding reliability and validity in qualitative research*. The Qualitative Report, 8(4), 597–606.

For more on the role of thought experiments in science, see Horowitz, T., & Massey, G. (Eds.). (1991). *Thought experiments in science and philosophy*. Rowman & Littlefield.

For more on the use of big data in science, see Leonelli, S. (2020). “Scientific research and big data”. In E. N. Zalta (Ed.), *The Stanford encyclopedia of philosophy* (Summer 2020 ed.). https://plato.stanford.edu/archives/sum2020/entries/science‐big‐data/.

For an introduction to phenomenology in philosophy and cognitive science, see Kaufer, S., & Chemero, A. (2015). *Phenomenology: An introduction*. Polity.

For more on meta-analysis and how it varies across fields, see Kovaka, K. (2022). “Meta-analysis and conservation science”. *Philosophy of Science*, 89(5), 980–990.

For a discussion of methods in the historical sciences and an articulation of “methodological omnivory,” see Currie, A. (2018). *Rock, bone, and ruin: An optimist’s guide to the historical sciences*. MIT Press.

## CHAPTER 5 Scientific modeling

###  5.1 THE SAN FRANCISCO BAY AND THE VALUE OF SCIENTIFIC MODELS

After reading this section, you should be able to:

- Describe how the Bay model was developed and how it was used to evaluate the Reber plan
- Define scientific model and target system, and indicate why models need to be partly similar to and partly different from their target systems
- Analyze the similarities and differences between the Bay model and the San Francisco Bay and how each is valuable or problematic

#### The Bay model

In an unassuming warehouse in northern California, there lies an enormous model of the San Francisco Bay and the surrounding Sacramento–San Joaquin River Delta. The San Francisco Bay area is a large body of ocean water surrounded by a large urban population living in diverse geological terrains and climates. The delta surrounding the bay is an area the size of the US state of Rhode Island, stretching from the Pacific Ocean almost halfway across the width of California. The Bay model is huge: it’s over 1.5 acres in size (more than 6,000 square meters) and is made of 286 five‐ton concrete slabs pieced together like a jigsaw puzzle. Still, as large as it is, the Bay model is 1,000 times smaller than the actual San Francisco Bay.

The Bay model is a hydraulic model. Pumps move hundreds of thousands of gallons of water (1 gallon is 3.785 liters) to mimic the tides and currents of the real bay. This procedure works because the model is three‐dimensional and proportional; the different parts of the bay and river delta in the model are the right amount lower than sea level, and the surrounding land is the right amount above sea level. The Bay model also includes other features that affect water flow, like rivers, canals in the delta, wharfs, bridges, and breakwaters.

The Bay model is not just a toy model made for tourists. Instead, it’s a scientific model. Scientific models are constructed to represent phenomena of interest and investigated to learn about those phenomena. This particular model is a terrific tool for

DOI: 10.4324/9781003300007-6
---

# Scientific modeling

 

  

View of the San Francisco Bay model, looking toward the Golden Gate Bridge and Pacific Ocean

# FIGURE 5.1

learning about the San Francisco Bay and how human activities can affect it. Teachers, students, and scientists use the Bay model to study geography, ecology, human and natural history, and hydrodynamics. It has been used to help answer questions about how dredging new shipping channels would affect the delta, about how mining during the California Gold Rush changed the rivers, and about what would happen if the system of dikes and levees in the delta failed.

A look at how and why the Bay model was first constructed will help us start to get a sense for the roles that models play in science. John Reber moved from Ohio to California in 1907 and set up as an amateur playwright, dramatist, and theatrical producer. Because of his work, he enjoyed social connections with numerous businessmen and politicians. In the 1940s, Reber became dismayed that the transcontinental railroad ended in Oakland rather than San Francisco, and he came to believe that the extensive bay between San Francisco and the mainland interfered with industry by isolating San Francisco from the rest of California and the US. He came to believe that this large body of water is a “geographic mistake” needing to be corrected.

Reber’s career was in entertainment; he had no expertise in science or engineering. Nonetheless, he intrepidly proposed a grand plan to renovate, and then exploit, natural features of the bay that he thought would enable more efficient use of it. Reber suggested filling some parts of the bay to create additional land for things like

# Scientific modeling

 

  

# The Reber plan: shaded areas were parts of the bay Reber proposed filling to create land

Figure 5.2: The Reber plan

This would also establish two freshwater lakes supplied by the rivers that empty into the bay. As freshwater has always been a limited resource in the San Francisco Bay area, it could be valuable to repurpose the bay for potable drinking water and irrigation.

Reber’s plan was taken seriously by politicians and capitalists, and the US Army Corps of Engineers decided to test it out. An immediate problem, though, was that the Corps couldn’t effectively do so in the actual bay without first implementing it, and, wisely, the Corps wasn’t prepared to radically alter the bay and surrounding river delta before knowing what the results would be. They recognized that such changes might have unintended negative consequences for the local water supply, wildlife, vegetation, agriculture, and human population. What to do? How could they consider the effects of the plan without going ahead and carrying it out?

This highlights one way in which scientific models can be useful. When performing an intervention on a system of interest isn’t possible, practical, or desirable, a model of the system can be used instead. The Army Corps of Engineers built a hydraulic model designed to be like the San Francisco Bay in some important respects. Once the model was sufficiently similar to the real San Francisco Bay, predictions about the bay could be made based on what was observed in the Bay model. The model could then be manipulated to determine what would happen in the real bay if the Reber plan were implemented. The scientists added scale models of Reber’s proposed dams to the Bay model to create the lakes and landmasses Reber had in mind, and then they sat back to see what would happen.

As it turned out, when the Reber plan was implemented in the Bay model, its unintended consequences were disastrous. Rather than lakes, the dams created stagnant pools of poor‐quality water that couldn’t support ecosystems or be used for drinking or irrigation. Altering the dam configuration in the model to solve that problem just created another problem: fast currents that again destroyed ecosystems and made travel in the bay significantly more dangerous. When the Corps reported these findings, the Reber plan was abandoned.

### Models and targets

The real‐world system or phenomenon that scientists want to study using a model is called a target system, or just a target. Because scientists investigate models to draw conclusions about target systems, a model needs to be like the target system in some ways; that is, it should be similar to, or resemble, the target. And not just any similarity will do. Scientific models need to be similar to their targets in relevant ways for what is being studied. This is why the Bay model replicated tides and currents and other important features to water flow in the San Francisco Bay. If the model were being used to study traffic flow across the bridges, different features would need to be similar.

The relevant similarities between a model and target system are what makes it possible to gain knowledge about a target system from studying a model. Relevant similarity can be achieved in different ways. The Bay model uses real water and simulated tides to mimic water flow, but depth and water resistance of the model had to be adjusted before the water flow was right. Different adjustments could have been made, so long as they also mimicked the real water flow. Or, the model could have been made a different size or out of different materials.

The differences between a model and target system are just as important as the similarities. The Bay model’s different spatial and temporal scales are two features that made it useful for learning about the real San Francisco Bay and delta. The model is much smaller than the real bay, with much faster tidal cycles. This allowed scientists to observe what would happen with a spatially distributed, long‐lasting sequence of events in a short time and without having to leave the model’s warehouse. Had the Corps tried to build a model exactly like the San Francisco Bay, it would have been too large to put anywhere, and it would have changed so slowly, they would have had to wait years to find out about the consequences of the Reber plan.

Some features of the bay either didn’t matter or would have been too difficult to accurately incorporate in the model. The Bay model ignores people and buildings, since these are unimportant for water flow. And being inside a big warehouse means the model isn’t exposed to changing weather like the real bay is. The model also doesn’t incorporate the oceanic wind currents that affect the bay; it’s tricky to see how those could be replicated and whether the outcome of doing so would be worth the effort.

The scientists who built the Bay model thus had to decide which features of the model should be similar to the real bay and which could, or should, be different. They also had to decide what to do about changing features of the San Francisco Bay, like whether the model should be like the actual bay during dry seasons, wet seasons, or some combination of these. These decisions were all important to constructing a useful model that could provide reliable information about how the bay would change if the Reber plan were implemented. As it turned out, the model they developed was sufficiently similar to the real bay not only to serve this purpose but for it to be put to other uses as well. For example, the Bay model was also used to study how a later plan of deepening water channels would affect water quality.

Some models are similar to their targets by exemplifying them. An exemplar is a model that is one of the target systems it is used to represent. Researchers can use exemplars to represent a broader class of targets that includes the exemplar, drawing conclusions about the whole class of targets by investigating just the exemplar. For example, the fruit fly (Drosophila melanogaster) is a common model organism in genetics and developmental biology. Biologists have used the fruit fly to learn how genes influence physical traits and how embryos develop from single cells to mature organisms.

The fruit fly’s features make it a good model for many purposes. Fruit flies are small and reproduce quickly, and large populations are easily maintained in labs. Their genome is very simple, with only four chromosomes, and scientists have it entirely mapped; so they can make precise interventions in their genes. As an exemplar, the fruit fly is used as a model organism to learn about genes in general, to show how development works in all insects, and for other applications. But, for some investigations, the differences from other organisms that make fruit flies particularly convenient models can also hinder their usefulness, like when genomic complexity is important.

##### EXERCISES

5.1 Recall: Define the terms model and target system, and indicate the model and target system(s) in one example of scientific modeling.

5.2 Apply: For both the Bay model and the fruit fly as a model organism, say what the model is, what the target system is, how the model is related to the target system, and what the model is useful for.

5.3 Recall: Describe the Bay model of the San Francisco Bay, explaining the purpose for which it was built and what one could learn about the real world from this model. Describe three similarities between the Bay model and its target and three differences, explaining the purpose of each.

5.4 Think: Identify two reasons why researchers often use simpler model organisms like the fruit fly to study human biology.

5.5 Apply: List three examples of scientific models not introduced in this section. For each, indicate what the model is used to investigate.

### 5.2 THE MODELING PROCESS

After reading this section, you should be able to:

- Compare and contrast the features and uses of the Lotka-Volterra model with the Bay model
- List three main steps involved in modeling and describe what happens in each
- Define variable, parameter, assumption, idealization, and giving an example of each from the Lotka-Volterra model

#### Specifying target systems

Scientific modeling is a way of gaining knowledge about a target system by investigating a model. The modeling process must include some initial analysis of the target system. Scientists need to decide what they are trying to learn about in order to construct a useful model. Do they want to predict the effects of proposed changes to the San Francisco Bay? Examine the genetic influences on some trait? Or, say, learn more about how number of predators influences a population of animals? All of these projects require models with different features.

An archer cannot accurately hit a target with their arrow if they don’t know where the target is or what it looks like. Without some knowledge about the target system, scientists can’t evaluate whether their models are similar enough, and in the right ways, to usefully study the target. So, at the beginning of the modeling process, scientists need to have a sense for what a model should be about and what they want to learn from the model. This can be preliminary and partial, just enough to get the process going.

For the Bay model, the task was to evaluate the feasibility and consequences of the Reber plan for damming up the bay. This was a starting point, even though scientists didn’t know exactly what would matter—currents, salinity of the water, and so on—or what they’d find—plentiful freshwater, excessive evaporation, or something else.

Once the goal of a model is settled by deciding what is to be learned about the target system, scientists also need to know something about which features of the target system are important and what those features are like. This is so they can construct a model that is similar to the target in the proper ways to be useful. When planning the Bay model, scientists figured that the tides and currents might be important to the Reber plan’s effects. To calibrate the model to have the same tides and currents as the real San Francisco Bay, researchers needed extensive data about these features of the real bay. Eighty people took measurements at different locations throughout the 1,424 square kilometer (550 square mile) bay every 30 minutes through a full tidal cycle of 48 hours. They recorded tide velocity and direction, changes in the water’s salinity (salt content), and the concentration of sediment. These and other data were needed in order to decide what features a model of the bay should have.

#### Constructing the model

After specifying the target system, researchers construct the model. This stage of modeling involves choices regarding how a model is designed to be similar to its target, what its other features are like, and to how many different circumstances or different targets a model should apply.

For the Bay model, researchers elected to construct a physical replica of the target. The San Francisco Bay is a complex system, and one advantage of a physical model is that the scientists didn’t need to understand how changes occur in the bay to predict those changes. Instead, their approach was to make the replica as similar as possible to the bay in all the ways they thought might matter, and then sit back and see what happened. Still, the model required extensive calibration—comparison with the real bay followed by adjustment—before it was accurate enough to make trustworthy predictions. The engineers used their extensive measurements of the bay’s tides and currents to ensure patterns of water flow in the Bay model were similar to those of the real bay. They had to tinker with the scales used for depth and width of the bay and the water resistance of the surface in order to get the proper water flow.

Other modeling approaches that don’t involve constructing a physical replica offer different advantages and challenges. For example, the Lotka‐Volterra model is an influential model in ecology developed independently by Alfred Lotka and Vito Volterra in the 1920s. Unlike the Bay model, the Lotka‐Volterra model does not lie in any warehouse. It’s a simple, abstract mathematical model. The Lotka‐Volterra model uses mathematical equations to represent the interactions of predators and their prey, like foxes and hares, lions and wildebeest, polar bears and seals, and so on. Here are the equations:

d x /d t = αx − βxy

d y /d t = δxy − γy

One variable, x, stands for the number of prey animals (for example, seals). Another variable, y, stands for the number of predator animals (in this example, polar bears). With these equations, biologists can calculate how predator and prey populations change over time (represented in the model as the derivatives d x /d t and d y /d t) from the combination of those population numbers and a few other parameters. A parameter is a quantity whose value can change in different applications of a mathematical equation but that only has a single value in any one application of the equation. In this equation, α, β, δ, and γ are parameters. These help the model account for, respectively, the prey population’s rate of growth without predation, the rate at which prey encounter predators, the predator population’s rate of growth, and the loss of predators by either death or emigration.

The Lotka‐Volterra model represents predator‐prey interactions, but there’s no straightforward way in which these equations are similar to animals eating other animals. Instead, the similarity is between the numbers that solve these equations for certain values of the variables and parameters and how predator and prey populations change in size over time. Recall that different choices can be made in how to achieve similarity with the target system; for models like this one, the similarity is simply in mathematical description. Mathematical models like the Lotka‐Volterra model require a firmer grasp of what about the target system is important and how these features interact than physical replicas do.

Variables and parameters are explicit parts of the Lotka‐Volterra model. What doesn’t appear are the model’s assumptions, but these are no less important. In this context, an assumption is a specification that a target system must satisfy for a given model to be similar to it in the expected way. In the Lotka‐Volterra model, numerous assumptions must be satisfied for the numbers solving the equations to indicate the actual change in predator and prey population sizes. For instance, the model assumes that prey populations will expand if there are no predators and that predator populations will starve without prey. Both assumptions are plausible. The model also assumes that prey populations can always find food, that predators are always hungry, and that predators and prey are moving randomly through a homogenous environment. These three assumptions are idealizations. An idealization is an assumption made without regard for whether it is true, often with full knowledge that it is false. These idealizations enable scientists to focus on the essentials of predator-prey interactions in general, without getting lost in complicating details of specific populations’ circumstances. Idealizations are discussed in more depth later in the chapter.

Because models can be similar to target systems in different ways, a single target is sometimes represented by multiple models. This can be useful when the real-world phenomenon is so complex that no single model can provide scientists with all they want to know about it. Weather patterns are a good example. Meteorological models normally represent only some of the factors needed to generate reliable predictions. Some may invoke humidity, temperature, and dew point to describe and predict certain basic weather patterns like precipitation. Other models may invoke other parameters, such as central pressure deficit and wind speed and direction, to better predict particular phenomena, like hurricanes. Sometimes meteorologists aim to make more reliable predictions by carefully cobbling together the results of different models of a given weather system.

It’s also possible for a single model to have more than one target system. A model might be designed to represent a type of event that recurs often. The Lotka-Volterra model is like that; it is designed to capture something important about seal and polar bear populations, wildebeest and lion populations, and many more prey and predator populations. And the same meteorological models can be used to study different hurricanes, as well as typhoons and cyclones. In contrast, the Bay model is designed to specifically represent the San Francisco Bay and surrounding delta. A new model would need to be designed to represent any other bay.

#### Analyzing the model

Once a target has been specified and a model constructed with that specification in mind, the model must be analyzed to learn about the target. Models that involve equations, like the Lotka-Volterra model, can be mathematically analyzed by inputting values for parameters and variables representing specific information about a target population. Analysis may also involve manipulating a model to see the effects of changes. This kind of physical manipulation was performed on the Bay model to test the Reber plan. For model organisms like fruit flies, scientists may alter a gene and see how the offspring change to explore the gene’s effects.

Such manipulations produce data that, if all goes well, can be used to learn about the target. This is a central purpose of analyzing a model: to draw conclusions about the target system(s). The Bay model revealed that freshwater lakes couldn’t be maintained in the San Francisco Bay, as the Reber plan called for, and that the planned dams would have disastrous unintended consequences to the local environment. It was thereby concluded that the Reber plan shouldn’t be implemented in the real San Francisco Bay. The Lotka-Volterra model, in turn, reveals that predator and prey population numbers are tightly linked. More prey leads to an increase in predators, and more predators leads in turn to a decrease in prey. This results in a cyclical relationship between predator and prey population sizes, where the population sizes go up and down together.

Visual representation of solutions to the Lotka-Volterra equations; these are values of x and y that solve the equations, which predict how prey and predator populations will covary.

The main purpose of analyzing a model is to learn about the target system(s). But another important purpose is to use existing data to assess and improve the representation of target systems. Because specifying the target and constructing the model can involve some guesswork, and because models differ from their target systems, researchers may not trust that what happens in the model will happen exactly as it does in the target. Analyzing the model’s behavior and comparing it with the target’s behavior can be used to assess the model’s success.

An example of this use of model analysis is the process of calibrating water flow in the Bay model to match water flow in the real San Francisco Bay. Engineers used their extensive measurements of tides and currents in the bay to adjust the model’s depth, width, and water resistance until its water flow matched. Ultimately, they made the model bay much deeper proportionally than the real bay, which helped. But this resulted in water moving too quickly in shallow parts of the model. Researchers compensated for this by adding 250,000 copper strips to the bay floor in the model to increase water resistance. They chose how many copper strips to add to any given place by comparing the model’s water flow with that of the real bay.

Different models with the same target are sometimes analyzed together to see whether and to what extent they have the same results. This technique is called robustness analysis. It can help determine whether models are accurate of the target when direct comparison with the target isn’t possible, like when the target is highly complex like the climate or a country’s economy. If multiple meteorological models with different variables, parameters, and assumptions all predict an upcoming increase of temperature in a region, this prediction is robust and seems to have more evidence backing it. Similar predictions from different models also can help scientists identify common features of the models, which might relate to stable relationships involved in the complex phenomenon under investigation. In this way, climatologists and other scientists studying complex systems can learn whether and to what degree the predictions of a model should be taken seriously.

##### EXERCISES

5.6 Recall: List all of the parameters and variables in the Lotka-Volterra model and what each stands for. Then, describe the difference between variables and parameters. Finally, list at least three assumptions of the Lotka-Volterra model and indicate which are idealizations.

5.7 Think: Suppose that you are modeling interactions between alligators (predator) and ducks (prey). Make a list of five features of the target system you think your model should take into account. Then, for each feature, say how it is similar or different in other predator/prey systems. For any features that are different, can you think of a related feature that would be similar between the systems?

5.8 Apply: Indicate at least three important differences between the Bay model and the Lotka-Volterra model, and describe a reason for each of the differences.

5.9 Recall: List the three steps of modeling outlined in this section and state the goal(s) of each.

5.10 Think: Recall how experiments involve the three steps of generating expectations, performing an intervention, and then analyzing the resulting data. State the three main steps in modeling, and describe the similarities between those and the three main steps in experimenting. Then, describe how modeling and experimenting are different.

5.11 Think: Suppose that we have a model of the Earth’s climate and we derive several predictions about average global temperature from the model. The assumptions of the model are somewhat unrealistic of the real-world climate, but replacing those assumptions with slightly different ones leads to similar predictions. Define robustness analysis and describe how this is an instance of it. What might you be able to learn from this invariance across the models?

### 5.3 VARIETIES OF MODELS

After reading this section, you should be able to:

- Define data model, say how data models are used, and list the three steps to construct one
- Give examples of models of these five types: scale, analog, mechanistic, mathematical, computer
- Describe the prisoner’s dilemma and iterated prisoner’s dilemma models and what scientists learned from each

 

#### Models of data  

The range of things that count as scientific models is extremely broad. Scientific models can be concrete physical objects, like the Bay model, mathematical equations, like the Lotka‐Volterra model of predator/prey interaction, or even implemented by computers. We’ll explore this variety in this section.

To start, let’s distinguish between models of phenomena and models of data. So far in this chapter we’ve only discussed models of phenomena, models used to represent target systems to investigate those systems. Models of data are also representations that are used in place of what they represent, but they represent data instead of target systems, and they play a different role in scientific reasoning by facilitating the use of data in testing hypotheses. A data model is a regimented representation of data, often with the aim of discerning whether the data count as evidence for a hypothesis.

Recall that data are any public records produced by observation, measurement, or experiment; because they are public, data enable observations to be recorded and compared. Thermometer readings, video recordings of capuchin monkey gestures, notes about the observed positions of planets, clicks on a website, and participants’ answers on a questionnaire are all examples of data. Such records are raw data, which must be processed before they are useful to scientists. For instance, the video recordings of monkey behavior would need to be edited, organized by time and day, and rendered into a software‐compatible visual format before they can be used to learn about monkeys’ gestures. This process of data correction, organization, and visualization results in a model of the data.

Data models are developed by first eliminating errors, then displaying measurements in a meaningful way, and finally extrapolating from those measurements to expected data for measurements that weren’t taken.

Consider measurements of the positions of a planet—say, Neptune—over a period of months. Those measurements will be influenced by more than Neptune’s position. They will also reflect some combination of human mistakes, flaws and limitations of instruments used, like a telescope, and inaccuracies from changing atmospheric conditions. Scientists can try to identify such errors by calibrating the telescope and recording the atmospheric conditions along with their measurement of Neptune’s position. This is called data cleansing: identifying and correcting errors in a data set by deciding which data are questionable and should be eliminated.

Then, the next step is to represent the data in a meaningful way. Data of Neptune’s position over a period of months may be visualized as charted points. Finally, these points can be used to draw a curve of Neptune’s progression. The points represent scientists’ measurements, and the curve represents the scientists’ best guess for Neptune’s path through the sky. This curve is the data model.

This is a complicated enough task that it has its own name: the problem of curve fitting. Curve fitting is extrapolating from a data set to expected data by fitting a continuous line through a data plot. The problem is that data, no matter how much you collect, are always consistent with multiple different curves. Suppose that you have data for two variables—say, air pollution and life expectancy in different cities—and you want to figure out the mathematical relationship between the two. That is, you want to learn how people’s life expectancy relates to the level of air pollution where they live. Your data are represented by the points in Figure 5.5. Figure 5.5 also shows different curves, representing different relationships between air pollution and life expectancy, each of which appears to fit the data pretty well. Put in terms of underdetermination, introduced in Chapter 3, the data underdetermine which curve best captures the relationship between these two variables.

There’s no easy answer to how scientists should decide which curve fitting the data is best. Finding the curve that best fits all data isn’t usually the best approach. Data models can fit the data too well; the problem with sticking too closely to the actual data is that those data are never perfect. There might be outliers, or values that deviate from the norm for one reason or another, and noise, influences on data that are incidental to the focus. Scientists want their data models to be better than the actual data they’ve collected. In the end, they must choose a data model based on their background knowledge about the phenomenon and what they want to use the data model for. New data can be used to check how well the selected data model works, just as models of phenomena can be calibrated with comparison to their targets. Big data approaches, discussed in Chapter 4, make data modeling even more challenging. A lot of data without a lot of background knowledge about the data makes it even more difficult to solve the curve-fitting problem.

#### Scale models

Data models are used in experiments and non-experimental studies, where the phenomena are investigated directly. In contrast, models of phenomena, our main focus in this chapter, are used to indirectly investigate phenomena: the model is studied in order to draw conclusions about its target. This can be especially useful when direct investigation, experiments and studies, aren’t feasible—like how the Reber plan would affect the San Francisco Bay—or scientists want to draw broad conclusions about a class of phenomena—like how predator and prey population numbers influence each other. As we’ve already seen with the Bay model and the Lotka‐Volterra model, there are many different types of models of phenomena.

**Scale models** are concrete physical objects that are downsized or enlarged representations of their target systems. Architectural models of buildings or urban landscapes are a familiar example; these are widely used in civil engineering. The Bay model is also a scale model. Its spatial scale is 1:1000 in length (one meter in the model represents 1,000 meters in the real world) and 1:100 in depth (one meter in the model represents 100 meters in the real world). The Bay model also has a shorter timescale; 14.9 minutes in the model represents a 24-hour day in the real world.

Other scale models are enlarged representations of their targets. In 1953, James Watson and Francis Crick announced the historic discovery that the structure of DNA is a double helix. Watson and Crick had spent a couple of years building scale models out of wire and tin plates in the shape of the building blocks of DNA. After several failures, the two scientists recognized, in part from the x-ray crystallography work of Rosalind Franklin and Maurice Wilkins, that a double helix structure best fit existing knowledge about DNA. Their model had a spatial scale of roughly 1 billion:1. That is, one centimeter in the double helix model represented one-billionth of a centimeter in a real DNA molecule. (See Chapter 13 for more discussion of this discovery, including Rosalind Franklin’s role.)

#### Analogical models

Analogical models are representations with features similar to focal features of a target system. The Bay model is also an analogical model, as it shares physical properties like tides and currents with its target. But analogical models don’t need to be concrete. An example of an abstract analog model is the computer model of the mind, which is based on formal similarities between computers and minds. Like computers, the human mind is often thought of as an information-processing system that can be described in functional terms—that is, without talking about its actual physical composition, or hardware, but referring to what it does. Like computers, minds can be understood in terms of the operations they carry out to solve certain tasks, or in terms of their software.

Another example of an analogical model—located somewhere between the Bay model and the computer model of the mind on the concrete/abstract spectrum—is the Monetary National Income Analogue Computer (MONIAC). Also known as a Phillips machine, MONIAC is a hydraulic model that uses water flow, like the Bay model, but to represent the British economy. William Phillips built MONIAC in 1949 using a collection of plastic tanks, each representing some aspect of the economy, connected by pipes and sluices and different valves. The machine used an old airplane motor to pump around dyed water, representing money, to simulate the flow of money in an economy. An overhead tank, representing a treasury, could be drained so that the water inside could flow to other economic sectors (education, healthcare, infrastructure and investment, savings, etc.). Water could be pumped back to the treasury tank to represent taxation and state revenue. Exports and imports could also be simulated by adding or draining water from the model. MONIAC is a physical model, but not a scale model. The British economy isn’t operated hydraulically, of course. MONIAC used water as an analog to money; changes in water level and flow were analogous to changes in amounts of money in and transfer among various sectors of the British economy. In its day, this was an amazingly accurate tool for studying how changes in different economic sectors affect others.

One type of analogical model is the mechanistic model, a model that represents the component parts and operations constituting some recurring process. Various processes in living organisms can be construed mechanistically, such as blood circulation, protein synthesis, and cellular respiration. A mechanistic model helps illuminate how the phenomenon depends on the orchestrated functioning of component parts. Mechanistic models can be physical structures, but most mechanistic models are schematic representations of structures, functions, and the relationships among them. For example, the mechanistic model of the cellular sodium-potassium pump depicted in Figure 5.8 is a generic representation of how sodium and potassium are exchanged through cell membranes.

Relying on analogies is a particularly useful strategy in early stages of modeling, when scientists may have little or no knowledge of the target system. This enables scientists to focus on the salient features of the target and to let the discovery of analogous features guide modeling approaches. For example, spiral staircases were an inspiration to Watson and Crick, guiding their modeling efforts of DNA toward a double helix structure. As knowledge about the target develops, analogical models may give way to models less obviously related to the target systems they represent.

#### Mathematical models

Mathematical models are mathematical equations that use variables, parameters, and constants to represent one or more target systems. The Lotka‐Volterra model is an example. It uses a pair of first‐order differential equations to represent changes in predator and prey populations over time. The first equation, d x /d t = α x − βxy, describes the fluctuations of a prey population, d x, over time, d t, where αx represents its exponential growth and β xy represents the rate of predator/prey interaction. The number of mice at a time, for example, is determined by their population growth, minus the rate at which they’re preyed upon by, say, hawks. In contrast, the number of hawks is fixed by their population growth given the supply of prey, minus their mortality rate. Hence, the second equation, d y /d t = δxy − γy, describes the fluctuations of a predator population, d y, over the same time interval, where δ xy represents predator population growth and γ y represents loss of predators due to events like death, disease, or emigration. (When we introduced the Lotka‐Volterra model earlier in this chapter, we said that x is a variable representing the prey population size and y is a variable representing the predator population size, while α, β, δ, and γ are parameters for, respectively, the prey population’s rate of growth without predation, the rate at which prey encounter predators, the predator population’s rate of growth, and the loss of predators by either death or emigration. Look at what we say about each part of each equation here with those definitions in mind to get a better sense for what each equation is used to represent.)

Another example of a mathematical model is a game theory model called the prisoner’s dilemma. Suppose that you and your friend Dominik have been arrested for robbing a bank, and you’ve been placed in different jail cells. A prosecutor makes this offer to each one of you separately:

You may choose to confess or to remain silent. If you confess and your accomplice keeps silent, all charges against you will be dropped, and your testimony will be used to convict your accomplice. Likewise, if your accomplice confesses and you remain silent, your accomplice will go free while you will be convicted. If you both confess, you will both be convicted as co-conspirators, for somewhat less time in prison than if only one of you is convicted. If you both remain silent, I shall settle for a minor charge instead.

Because you are in a different cell from your friend, you cannot communicate or make agreements before making your decision. What should you do? Assuming that neither of you want to be imprisoned, you face a dilemma. You will be better off confessing than remaining silent, regardless of what Dominik does. Look at the prior passage and think through what happens to your jail time if Dominik doesn’t confess and if Dominik does confess; in either case, it’s better for you if you confess. So, it looks like you should confess, right away! The problem is that Dominik is in the exact same situation. And the outcome where both of you confess is worse than the outcome where you both remain silent. If you and Dominik do the same thing, it’s better to both remain silent.

The prisoner’s dilemma seems to raise a puzzle for rationality. You are better off confessing, regardless of Dominik’s choice, but if you both are inspired by that fact to confess, you are both worse off than if you had both remained silent. Reasoning independently, it seems you should confess. But if you could plan what to do together, you’d both choose to remain silent. What to do?

The prisoner’s dilemma is usually represented using the mathematical formalism of game theory. The prisoner’s dilemma we described is depicted by the payoff matrix in Table 5.1.

Although this situation may seem contrived, numerous real-life scenarios can be modeled with a generic version of the payoff matrix, as shown in Table 5.1. The numbers represent generic payoffs or consequences of each decision. The higher the number, the more desirable the payoff. The first number in each set of parentheses represents Player 1’s payoff, the second number Player 2’s payoff. What’s important about these payoff numbers is just that the number for defecting is always higher than the number for cooperating, but the number when...

**Table 5.1** (a) Game theory payoff matrix for the prisoner’s dilemma (top); (b) Version of the prisoner’s dilemma generic to any choice of cooperating or defecting (bottom)

|      | Dominik | Remains Silent                | Betrays                        |                   |
| ---- | ------- | ----------------------------- | ------------------------------ | ----------------- |
|      | You     | get 3 years of prison         | Each pays a minor fine         | Dominik goes free |
| You  | go free | Each serves 2 years of prison | Dominik gets 3 years of prison |                   |

|          | Cooperate | Defect |        |        |
| -------- | --------- | ------ | ------ | ------ |
| Player 1 | Cooperate | (2, 2) | (0, 3) |        |
|          |           | Defect | (3, 0) | (1, 1) |

Both players cooperating is higher than the number when both players defect. In Table 5.1 b, 3 > 2 and 1 > 0, but 2 > 1. These numbers capture the dilemma: you do better if you defect regardless of your partner’s choice, but things will go better for you if your partner cooperates. The bank robbery scenario is just a vivid illustration; the prisoner’s dilemma can model lots of real-world situations involving people, businesses, nations, animals, or even bacteria. Any real-life scenario in which entities vary their strategy in ways that affect each other can be represented by the prisoner’s dilemma game if the desirability of the consequences can be represented by these payoff numbers.

The prisoner’s dilemma has been used to model many scenarios involving cooperation, in human societies and the biological world alike. For example, consider the symbiotic relationship of cleaner fish. Individuals of one species (the cleaner) remove parasites and dead skin from individuals of the other species (the client). Cleaner fish may choose to cooperate by cleaning the client fish or to defect by eating extra skin from the client fish. Client fish may choose to cooperate by allowing the cleaner fish to clean safely or to defect by threatening or eating the cleaner fish. Both fish types are better off if they cooperate: the client fish gets an important cleaning while the cleaner fish gets dinner. But there’s a benefit to defecting for each: the cleaner fish would get a bigger dinner by eating more from the client fish, and the client fish would get to eat the cleaner fish. The prisoner’s dilemma has been used to reveal the circumstances that can enable cooperative symbiosis like this to evolve.

#### Computer models

While many real‐world situations can be modeled as cases of the prisoner’s dilemma, what we’ve seen so far isn’t enough to show why businesses, gangsters, fish, and nations so often cooperate in real life. One important reason is that, in many real‐life scenarios, decisions about whether to cooperate aren’t made in an isolated room, separated from your partner. Instead, businesses, gangsters, fish, and nations all tend to signal their intentions, negotiate while making decisions, or interact repeatedly over time, allowing reputations to form.

The prisoner’s dilemma model can be extended to represent these kinds of interactions. One common extension is the iterated prisoner’s dilemma, where we suppose that two agents play the prisoner’s dilemma with each other repeatedly. This is one way in which cooperative behavior can win out over the selfish choice to defect. In the 1980s, a computer game provided insight into how this can happen. The political scientist Robert Axelrod invited social scientists to submit computer programs for a tournament of the iterated prisoner’s dilemma. Fun! Each program had its own strategy governing the circumstances in which it would cooperate or defect, and these programs were pitted against one another to see which would perform best in the long run. This tournament was a computer model.

In Chapter 4, we introduced computer simulations: computer programs developed from data about a phenomenon to simulate its behavior. Computer simulations are a variety of model; we can equivalently call them computer models. Axelrod’s tournament wasn’t a computer simulation of a specific phenomenon of interest but a simulation of iterated exchanges in which cooperation is valuable but there’s a temptation to defect.

By inviting open participation from other modelers, Axelrod made it so that the strategies deployed in his model weren’t limited by his own preconceptions, and the results did turn out to be surprising. The winning strategy, accumulating the most points in the iterated prisoner’s dilemma tournament, belonged to a program named Tit‐for‐Tat, submitted by psychologist Anatole Rapoport. The program was so simple that it had only a few lines of programming code. Tit‐for‐Tat cooperated in the first round of any game it played, and then it mirrored the other player’s previous action in every subsequent round. So, when Tit‐for‐Tat played against generally cooperative programs, it behaved cooperatively and reaped the rewards of that mutual benefit. But when Tit‐for‐Tat played against players that frequently defected, it too played selfishly after that initial cooperative move. This protected it from exploitation by selfish programs. Axelrod’s computer simulation thus demonstrated the strategic success of emulating the cooperation of others, which has been dubbed reciprocal altruism.

##### EXERCISES

5.12 Recall: Characterize models of data and models of phenomena, and give an example of each. How are these types of models similar? How are they different?

5.13 Apply: List the five types of models of phenomena described in this section, and give an example of each. For each example, indicate why it counts as a model of that type, and what target system(s) it is supposed to represent. Then, rank your examples from 1 to 5, where 1 is the most concrete relationship to the target system(s) and 5 is the most abstract.

5.14 Recall: List the three steps of data modeling. Then, describe the curve-fitting problem and indicate how it complicates those steps.

5.15 Think: Describe the prisoner’s dilemma and iterated prisoner’s dilemma models, and indicate what type of model each is. Considering both models, what do you take the target system(s) to be, and what do you think scientists can learn from these models?

5.16 Recall: Mathematical models are among the most abstract representations of target systems. Describe how mathematical models are nonetheless similar to target systems, using the example of the Lotka-Volterra model. (Returning to section 5.3’s discussion of the Lotka-Volterra model might be helpful.)

### 5.4 LEARNING FROM MODELS

After reading this section, you should be able to:

- Describe how models can play an experimental role and how they can play a theoretical role
- Identify three features that all models share
- List five desirable features of models and describe tradeoffs among these features

#### Modeling as experimentation and theorizing

Constructing and analyzing a model shares some similarities with experimentation. Both experimenters and modelers perform interventions to test expectations based on a hypothesis; like experiments, modeling can provide evidence for or against hypotheses about target systems. Expectations about the consequences of the Reber plan for the San Francisco Bay were tested with interventions on the Bay model. Animal models like the fruit fly are used to test expectations about the genetic causes of human diseases, like diabetes and lymphoma. And studying the iterated prisoner’s dilemma helps test expectations about the conditions that enable cooperative behavior to emerge among self‐interested individuals.

In each example, the models were used to test scientists’ hypotheses about real‐world systems, sometimes with surprising results. So, models can play a role similar to experiments. One important difference is that, with experiments, scientists intervene directly on the target system, whereas with models, interventions to models are used to draw conclusions about the target system. This is why models must accurately represent their targets.

Getting models to reflect their targets more accurately is a primary task of modeling. When a model is known to accurately represent its target, it can play a role similar to a scientific theory by representing core features of that phenomenon. When a model behaves similarly to the expected target system(s) in many instances and across different circumstances, it may become accepted as part of a theory of how the target behaves. An example of such a theoretical use of modeling is the Lotka-Volterra model of predator-prey interactions. If one sets the model’s parameters based on observations or estimates of specific predator and prey populations, one can then use the model to predict changes over time in the sizes of these populations. These predictions are a good account of how real predator-prey populations behave, and when they go wrong, one can usually figure out why by comparing the model’s features to the target system’s features.

So, models can play an experimental role by helping to investigate phenomena empirically, and they can play a theoretical role by providing an account of phenomena. Sometimes the same model can even play both experimental and theoretical roles. In Axelrod’s tournament, computer simulations served as virtual environments to test which strategies would perform best in an iterated prisoner’s dilemma game. While there were no expectations that Tit-for-Tat would win, this outcome accorded with an existing theory in evolutionary biology, namely reciprocal altruism. The basic idea is that it can be evolutionarily advantageous for an organism to help another at some cost to itself if there is a chance the favor will be returned in the future. The success of Tit-for-Tat was based on reciprocity, and so was consistent with this theory. Thus, the success of Tit-for-Tat in Axelrod’s computer tournament confirmed the idea in evolutionary theory that natural selection can favor cooperative behavior, even when there are costs, if the behavior is reciprocal.

#### Common features of models

This chapter has emphasized how different models can be from one another. Still, all models share three important features. First, all scientific models are used to learn about the world. Data models represent data to enable hypothesis-testing. Constructing and investigating models of phenomena enable scientists to reason about target system(s) in hopes of gaining new scientific knowledge. In both cases, the models are used as vehicles for learning about natural phenomena investigated in science.

Second, all models are used to represent: they are about, or stand for, the phenomena they target—or, for data models, the data they characterize. For a model to represent a target, it must be like the target in the right ways. Often, this likeness is understood in terms of similarity. But we have said that models aren’t exactly like the target systems they represent; they are also dissimilar from their targets in important ways—smaller or larger, mathematical or computerized. What similarities and differences are intended between a model and a target governs how the model should be interpreted and used.

Third, all scientific models involve idealization and abstraction. When constructing a model, scientists leave out some features of the target system and incorporate features the target does not have. Omitting or ignoring known features of the system is called abstraction. Misrepresenting features of the system with false assumptions is idealization (defined earlier). Abstraction and idealization can be used to set aside or simplify some features of target systems to focus on only those features deemed important for the purposes at hand.

The Lotka-Volterra model, for example, abstracts away from properties of prey and predators, like their speed, size, and capacity for camouflage. Those features aren’t essential to how predator-prey interactions influence population size and so have been abstracted, or removed, from the model. The Lotka-Volterra model also incorporates idealizations of predator-prey interactions. That model’s idealizations include the assumptions that prey can always find food, that predators are always hungry, and that both predators and prey are moving randomly through a homogenous environment. Scientists know these assumptions aren’t true, but they are helpful simplifications that usually don’t interfere with the model’s usefulness.

These three features of scientific models—their use to learn about natural phenomena, their representation of target system(s), and their incorporation of abstractions and idealizations—all relate to one another. Abstraction and idealization are features of models that affect how they represent their targets, and the ways models represent their targets partly determines what can be learned from them. Representation, then, is at the heart of scientific modeling.

#### What makes a model good?

We’ve seen that a target system can be represented in many ways. A physical model of a hydrological system, like the Bay model, represents water flow in ways that differ from mathematical models of fluid dynamics. And both of those are different from the computer model that eventually took over the work of the Bay model. There’s no one perfect model of a given phenomenon. Instead, the goodness of a model is determined by what the modelers want to learn from the model. Other factors, such as cost or ease of developing or using the model, can also be important. Sometimes one model will be enough for learning about a target system; other times, multiple models of the same target will be necessary to gain knowledge.

It is desirable for models to be accurate, general, precise, tractable, and robust. Each of these features helps make a model valuable, but attempting to maximize all of these features is futile. This is because these features trade off against one another: gaining more of one desirable feature of a model often requires losing ground on some other desirable features. For example, a model that is more general by applying to more target systems is also often less accurate of any one target system. This is because targets differ from one another in some regards. So, when constructing models, scientists must decide which desirable features to emphasize and which to compromise on.

##### Box 5.1 Values in Modeling

Models always are similar to their target systems—but are also different from them in various ways. This creates an opportunity, or an inevitability, really, for the influence of social values on scientific modeling. Recall from Chapter 2 that social values are the priorities and moral principles accepted in some community. One way social values influence modeling is in shaping what features of a target system scientists choose to represent accurately in a model and what features they ignore or distort. These choices depend on modelers’ aims. The influence of values on these choices is salient especially (but not only) for models in social science, as how a phenomenon should be defined and measured given a certain purpose and what factors are important to understand often relate closely to social values.

For example, philosopher of science Eric Winsberg has criticized predictive models of the Covid-19 pandemic that were used to justify governmental stay-at-home orders for including consideration of illness and death from Covid-19 but excluding consideration of the health impacts of school closures, social isolation, and deferred healthcare. There’s not one single right way to develop a model. What’s important is that similarities and differences from a target system be thoughtfully designed and open to scrutiny from others. Multiple models of one target phenomenon also can be developed; this was done for models of the Covid-19 pandemic, and it also occurs in climate change modeling and modeling of many other phenomena of widespread social importance. Multiple models of the same target can lay bare how modeling choices based on different aims and values influence what we understand about a phenomenon.

#### Accuracy

Accuracy is the extent to which a model represents the actual features of its target system; models that are more accurate better represent more features of a target system. A model that represented all and only the actual features of its target would be maximally accurate, but maximal accuracy is unhelpful; recall that models are improved by some differences from their targets. For example, the Bay model improved its representation of water flow by introducing inaccuracies of water depth. Overemphasizing a model’s accuracy can come at significant costs to tractability and generality—making the model difficult to develop and inapplicable to target systems that differ in minor ways.

#### Generality

Generality is a model’s applicability to a greater number of target systems; a model is more general when it applies to a greater number of target systems. Generality is a desirable feature of models insofar as it enables models to be reused in various circumstances. General models also highlight what various phenomena have in common with one another. Because the prisoner’s dilemma can apply to nations, squirrels, and pirates, this is a general model with numerous applications. This generality reveals something that these scenarios have in common: repeated interactions can enable cooperation to spontaneously emerge. However, sacrificing some generality in a model can be worthwhile, depending on the aim of the model, if this enables the model to represent its target more accurately. A general prisoner’s dilemma model might be supplemented with information about, say, how natural selection favors bacteria that can persist near one another (a form of cooperation). The resulting model will give more insight into bacteria cooperation in virtue of this additional detail. But it also will be less general—it will no longer apply to humans or corporations. Which is better depends on the modelers’ aims.

Precision is the extent to which a model finely specifies features of a target system; a more precise model more finely specifies features of the target. For example, climate models that allow scientists to predict how much warmer the global average temperature will be in 30 years within a range of ±0.05° Celsius are more precise than models that allow them to predict a ±1° Celsius range of temperature increase in 30 years. Notice that precision is different from accuracy. Whereas accuracy is a matter of a value’s proximity to the true value, precision is a matter of how finely specified a value is. So, a model can be very precise but inaccurate. Think of an archer loosing arrows at a target. Arrows that are scattered all around the bull’s eye but near it are accurate but imprecise. Arrows that are tightly clustered together but off center, away from the bull’s eye, are precise but inaccurate (see Figure 5.9).

Greater precision benefits a model by enabling it to give a more specific characterization of its target and to make more specific predictions. But increasing precision usually comes at the cost of a model’s generality, its tractability, and sometimes its accuracy. Highly precise models are less generally applicable and more difficult to develop. And, the more specific a prediction is, the easier it is for that prediction to be incorrect.

Tractability is the degree of ease in developing or using a model. More tractable models are easier to construct, manipulate, or analyze. This may involve different considerations, like the time it takes to run a model on a computer, whether the equations of a mathematical model have exact solutions, or even whether a modeler happens to be already familiar with one approach but not another. For example, because the iterated prisoner’s dilemma involves agents having repeated encounters, this model is less tractable than the original prisoner’s dilemma. One consequence of this decreased tractability is that scientists know exactly what the possible outcomes are for the original prisoner’s dilemma, but they cannot easily predict the outcomes for the iterated version. This is why Axelrod ran a computer tournament to explore some of the possible outcomes. Tractability is never maximized, though: the easiest thing to accomplish is nothing at all, and more complicated models regularly result in more accurate, precise, and useful findings. For instance, the iterated prisoner’s dilemma reveals how repeat encounters can overcome the dilemma, making cooperation directly beneficial.

Robustness is a measure of insensitivity to features that differ between a model and the target system, including abstractions and idealizations. Normally, scientists don’t want their model’s predictions to be influenced by those features, since they aren’t shared by the target. So, a more robust model is one that changes less despite variation in its assumptions. But limited robustness is inevitable. Models incorporate assumptions, including idealizations, that are needed for them to do the tasks they are designed for. If they didn’t matter, they wouldn’t be needed. What scientists aim to avoid is overreliance on specific assumptions that are unlikely to be true or even known to be false. Multiple models are sometimes used to determine how robust a model’s predictions are. If different models, with different assumptions, predict roughly the same result, that prediction seems more trustworthy than if it had been generated by just one model with uncertain assumptions and parameters. This is robustness analysis, introduced in section 5.2.

There is no single answer to how a model should best incorporate these desirable features, nor is there a perfect tradeoff among the features. Instead, scientists strategically develop their models to be tractable enough for their current circumstances; robust enough to be certain to some reasonable degree; accurate and precise enough to make interesting, trustworthy predictions; and general enough to be enlightening across the range of phenomena they are interested in. The balance struck thus depends in subtle ways on the phenomena under investigation, the scientists’ circumstances, and the purposes to which the models are put.

##### EXERCISES

5.16 Recall: Describe how models can play an experimental role and how they can play a theoretical role, giving an example of each.

5.17 Recall: List the three main features that scientific models share, and articulate how these three features relate to one another. Use one example model to illustrate all three features.

5.18 Apply: Locate and investigate a scientific model not already discussed in this chapter. Classify its type of model, and describe what target system(s) it’s used to represent. Describe how the elements of the model represent features of the target system(s) and what scientists have learned about the target system(s) from the model. With reference to ideas from this chapter, discuss why this model is a helpful way for scientists to investigate this phenomenon.

5.19 Recall: Define abstraction and idealization. What is the difference between them?

5.20 Think: Choose one of the models discussed in this chapter. Formulate a list of the abstractions involved in using the model to represent its target system and a separate list of the idealizations involved in using the model to represent its target.

5.21 Apply: In your own words, describe the five desirable features of models characterized at the end of this section. Then, for each feature, compare two models: the classic mathematical model of the prisoner’s dilemma and the computer model of the iterated prisoner’s dilemma. For each feature, write down whether you think one model is better and which one. Explain your answer.

##### FURTHER READING

For more on the use of models in science, see Weisberg, M. (2013). *Simulation and similarity: Using models to understand the world*. Oxford University Press.

For more on idealization, abstraction, and tradeoffs, see Potochnik, A. (2017). *Idealization and the aims of science*. University of Chicago Press.

For a discussion of computer simulation, see Frigg, R., & Reiss, J. (2009). The philosophy of simulation: Hot new issues or same old stew? Synthese, 169, 593–613.

For discussion of computer modeling and attention to climate change models, see Winsberg, E. (2010). Science in the age of computer simulation. University of Chicago Press.

For discussion of computational methods in science, see Humphreys, P. (2004). Extending ourselves: Computational science, empiricism, and scientific method. Oxford University Press.

## CHAPTER 6 Deductive reasoning

### 6.1 THE AGE OF THE UNIVERSE AND SCIENTIFIC ARGUMENTS

After reading this section, you should be able to:

- Summarize Hubble’s three scientific arguments regarding the size, expansion, and age of the universe
- Define reasoning, inference, premise, conclusion, and argument and describe the relationships among these concepts
- Describe the nature of a valid deductive argument

#### How old is the universe?

In Chapter 1, we mentioned Clair Patterson’s involvement in the campaign to remove lead from gasoline because of lead’s disastrous health effects. Patterson was a geochemist; using radiometric dating methods on elements like uranium and lead, he correctly calculated that our planet Earth is 4.5 billion years old. If the Earth is that old, how much older is the universe itself?

This question has been asked for a very long time, and answers to it have, of course, changed with advancing knowledge. The philosopher Aristotle argued that the universe must be eternal. He reasoned that everything which comes into existence requires some preexisting matter from which it comes. (You may have heard of the saying *ex nihilo nihil fit*, which is the similar idea that from nothing comes nothing.) This implies that if the universe came into existence, then it came into existence from some preexisting matter. But this is not possible if the universe is the totality of what there is. Further, any preexisting matter must have itself come from some other prior matter. The result is an infinite regress: no starting point is possible. Aristotle concluded that the universe must be eternal.

From the early Middle Ages to the end of the Renaissance, roughly the 7th through 16th centuries, scholars and theologians in Europe, the Mediterranean Basin, and the Middle East continued to engage with questions about the age of the universe. The structure of Aristotle’s reasoning was largely kept, but the eternality of the universe was replaced by the eternality of God in order to fit with ideas about religious creation.

Some theologians estimated the universe to have come into existence around 4,000 BCE—that is, about 6,000 years ago. The estimate was derived from arithmetical calculations from genealogical records in various religious texts.

By the 19th century, many scientists believed that the universe—whatever its age—is in a steady state. In the 1920s, Edwin Hubble made two discoveries that were inconsistent with that belief: first, that the universe is much larger than previously thought and, second, that the universe is expanding. These discoveries also provided new evidence about the age of the universe.

Using a telescope with a 2.5‐meter aperture at Mount Wilson Observatory in Southern California, Hubble observed Andromeda, an astronomical entity visible to the naked eye and identified over 1,000 years ago. He saw stars similar to those nearer to Earth, only dimmer. One of those stars is called a Cepheid variable, a star whose brightness changes periodically. The period of time it takes a Cepheid’s brightness to change is related to the star’s luminosity, the amount of energy it emits in one second.

From the star’s periodicity and that relationship, Hubble could calculate the star’s luminosity, thereby determining how much brighter it was than the Sun. Hubble then used his knowledge of the speed of light, which Einstein had recently shown to be constant, and the apparent brightness of the star compared to what he had calculated to be its luminosity to calculate the star’s distance from Earth. Based on the distance of that star, Hubble reasoned that Andromeda is actually a different galaxy from our Milky Way galaxy. This discovery of a separate galaxy, announced in 1925, confirmed that the universe is much larger than previously thought.

Hubble also discovered that the universe has not always been this large. It’s expanding. Like sound, light changes its frequency depending on the relative movement of the object emitting it and the observer. An example is the change in frequency of an ambulance siren as it moves toward, and then away, from an observer. The siren’s pitch sounds higher as it approaches, and then lower pitched as it passes. This frequency change, called the Doppler effect, was discovered in the mid‐19th century by the Austrian physicist Christian Doppler. For Hubble’s purposes, the important implication is that a star moving away from Earth appears redder, while a star moving toward Earth appears bluer. The degree of redness of receding stars is called redshift.

Using the technique of astronomical spectroscopy, Hubble discovered that the redshift of starlight from any galaxy increased in proportion to the galaxy’s distance from Earth. In 1929, he announced his discovery that galaxies are moving farther and farther away from Earth. By implication, the universe itself is expanding. According to recent estimates, the universe’s expansion rate, known as Hubble’s constant, is about 68 kilometers per second per megaparsec (km/sec/Mpc), where one megaparsec (Mpc) is approximately three million light‐years—an extremely long distance!

How do Hubble’s discoveries about the size and expansion of our universe help determine its age? As we’ve seen, knowledge of the speed of light and a star’s brightness can be used to calculate the distances to faraway stars and galaxies. This distance measurement in turn indicates the amount of time the star must have been producing light in order for that light to reach Earth. Observing light from very distant stars and galaxies thus indicates their minimum age as well as the minimum age of the universe containing them. Using this reasoning, Hubble was able to show that the universe was at least 10 billion years old.

More recently, revised estimates suggest that the universe is approximately 13.8 billion years old. In 2020, astrophysicists used the 6‐meter‐aperture Atacama Cosmology Telescope in Chile to confirm this estimate and give a more precise estimate of the value. This finding has also been supported by convergent evidence from sciences like cosmological physics and geochemistry. The newest successor to the Hubble telescope, the James Webb Space Telescope, is set to provide additional confirmation of the universe’s age.

#### Reasoning, inference, and argument

In past chapters, we have seen that empirical evidence is essential for developing scientific knowledge. But for observations to lead to knowledge, scientists must assess their significance and implications, and the relationships among them. In other words, scientific knowledge comes not from mere observation but from reasoning about observations. Hubble combined empirical observations with calculations of light’s travel over distances and through time, established scientific knowledge about the Doppler effect, and other resources to develop arguments in favor of his conclusions regarding the universe’s size, its expansion, and its age. Hubble appealed to empirical evidence in ways Aristotle did not, but like Aristotle, he also had to reason his way to conclusions.

This chapter and the next focus on inference patterns in scientific reasoning. Reasoning is a cognitive process of drawing inferences in support of some conclusion. An inference is a logical transition from one thought to another. Inferences move from premises, statements that provide support, to conclusions, statements that are supported by the premises. Inferences from premise(s) to conclusion(s) can be depicted as abstract derivations obeying rules that capture the logical transition(s) involved. So, while reasoning is a cognitive process, inferences can be thought of as simply logical relationships.

Reasoning processes can be made explicit by depicting inferences explicitly in an argument. While “argument” means different things in different contexts, here an argument is a set of statements in which some (premises) are intended to provide rational support or empirical evidence in favor of another (the conclusion). Recall Aristotle’s reasons for concluding that the universe is eternal. These reasons can be reconstructed into the following argument:

1. Everything that comes into existence must come from some prior material substrate.
2. ∴ If the universe came into existence, then the universe must have come from just such a prior substrate.
3. It cannot be the case that some prior material substrate existed before the universe.
4. ∴ It cannot be that the universe came into existence.
5. ∴ The universe is eternal.

The argument is an ordered list of statements. The first four statements are the premises; the argument’s conclusion is the last statement. Statements inferred from one or more premises are sometimes marked with the symbol ∴, which is notation for words like therefore, so, or hence. As this example shows, an argument may involve more than one inference. Here the second statement is inferred as an application of the first statement. The fourth statement is inferred from the second and third statement together. And the final conclusion is inferred from the fourth claim.

Scientific reasoning is similar to ordinary everyday reasoning but focused specifically on developing natural explanations for natural phenomena. Arguments in science also tend to incorporate empirical evidence. And then, scientific reasoning also tends to be more explicit than everyday reasoning, in part because scientists need to be able to assess each other’s reasoning.

**Logic** is the study of the rules and patterns of inference, which is crucial for evaluating scientific reasoning. Scientific reasoning can follow three patterns of inference: deductive, inductive, and abductive. The evaluation of each of these patterns of inferences focuses on two main questions: first, do the premises rationally support the conclusion? And second, are those premises true? The premises of a good inference should provide a logically compelling reason for thinking the conclusion either must be true or is likely to be true. In a deductive argument, the truth of the premises should guarantee the truth of the conclusion, while in inductive and abductive arguments, the premises provide support for the conclusion but do not guarantee its truth. This chapter focuses on deductive inference; Chapter 7 addresses inductive and abductive inference.

Again, in a deductive argument, the truth of the premises should guarantee the truth of the conclusion. If so, the argument is said to be valid. In nontechnical uses, “valid” can mean that something is believable, and, in Chapter 3, we discussed the external and internal validity of experiments. Here, in the context of deduction, validity has a different meaning. In a valid inference, the truth of the premises logically guarantees the truth of the conclusion. For a valid deductive argument or inference, it is impossible for the conclusion to be false provided that all premises are true.

##### EXERCISES

6.1: Recall: How did Hubble discover that galaxies are moving farther and farther away from Earth? Describe the observation(s) he made supporting this discovery and his reasoning based on the observations.

6.2: Recall: Briefly summarize Hubble’s scientific arguments regarding the size and age of the universe. For each of the two, start by identifying the conclusion, and then piece together his reasoning for that conclusion. You don’t need to put these in explicit premises that comprise a valid deductive argument, but you are welcome to use that approach if it is helpful.

6.3: Think: Aristotle reasoned that the universe did not become and has always been. His argument for that conclusion as enumerated in statements (1)–(5) in this section is a valid deductive argument; so if all the premises are true, the conclusion must be true. But we know the conclusion is false, and so at least one of the premises must be false. Which of the premises might be false? Describe your reasoning.

6.4: Apply: Hubble discovered that the universe is expanding from changes in redshift. Describe what changes he observed. If, in the future, the universe began to contract, what changes in redshift should scientists expect to see? How long after the universe began to contract would scientists see this change?

6.5: Recall: Define reasoning, inference, premise, conclusion, and argument and describe the relationships among reasoning, inference, and argument, as well as the relationships among premise, conclusion, and argument (or inference).

6.6: Recall: What is required for a deductive argument to be valid? Give a simple example of a valid deductive argument—about anything!—numbering the statements and indicating conclusion(s) with ∴.

 

### 6.2 RULES OF DEDUCTIVE INFERENCE

After reading this section, you should be able to:

- Define conditional statement, antecedent, and consequent and indicate the logical relationships among them
- Identify these common patterns of valid and invalid deductive inference: affirming the antecedent, denying the consequent, affirming the consequent, and denying the antecedent
- Assess an argument’s validity and soundness and, for an invalid or unsound argument, whether the argument should be revised or abandoned

#### Conditional statements

An important component of many deductive inferences is the conditional statement, statements in which one circumstance is given as a condition for another circumstance. These are often thought of as if/then statements: if you eat your vegetable, then you can have dessert. If a star is 13.8 billion light-years away, then the universe is at least 13.8 billion years old. The first circumstance (following “if”) is the antecedent, the condition for the other circumstance, while the second circumstance (following “then”) is the consequent, the circumstance arising from the antecedent.

You can think about the logical relationship between antecedents and consequents in terms of requirements and guarantees—or, more formally, necessary and sufficient conditions. In a true conditional statement, the antecedent is a sufficient condition for the consequent—a condition that, if met, guarantees the occurrence of the specified outcome (here, the consequent). Consider the true conditional statement: “If Lu is a dog, then Lu is an animal.” Lu being a dog guarantees that Lu is also an animal; being a dog is sufficient for being an animal. But this doesn’t work in reverse. In a true conditional statement, the consequent occurring doesn’t guarantee the antecedent will occur. Lu being an animal doesn’t guarantee that he’s a dog; perhaps he’s an alligator or a velociraptor. Instead, the consequent is a necessary condition for the antecedent—a condition that must be satisfied for the occurrence of the specified outcome (here, the antecedent). Lu being an animal is a necessary condition for Lu to be a dog: there’s no way Lu is a dog if he’s not an animal.

The meanings of antecedent and consequent relate to logical priority, not temporal succession. Sometimes an antecedent occurs before its consequent in time, as when a child has to eat their vegetable before being allowed to eat dessert. It’s not good enough for the child to promise they’ll eat the vegetable later. But, for the statement “if Lu is a dog, then Lu is an animal,” being a dog doesn’t come before being an animal; it’s just that being an animal is a consequence of being a dog. The time ordering of antecedents and consequents can also be reversed. In the statement “if you are still hungry, then you must not have eaten enough dinner,” the antecedent is logically prior, even though the consequent (not eating enough dinner) happened before the antecedent (still being hungry).  

##### Box 6.1 Conditional statements

Scientific inquiry and everyday reasoning often involve the formulation and evaluation of conditional statements, like if A then C. But conditional statements often are expressed in nonstandard forms. Instead of if A then C, one might say (where A is still the antecedent and C the consequent of the conditional):

- C if A
- A only if C
- A guarantees C
- Without C, A is not the case
- Not A unless C

And more. Here are some tricks for navigating nonstandard forms of conditional statements:

1. Identify the candidates for being antecedent and consequent: what is being related in the claim?
2. A consequent states a necessary condition for the antecedent, or gives a requirement.
3. An antecedent states a sufficient condition for the consequent, or gives a guarantee.
4. Try to translate the statement into a standard if-then conditional and check if the same circumstances make the sentence true.

Recall that a conditional statement is only false when the antecedent can be true while the consequent is false; in all other cases, the conditional is true. For example, if parents tell their child: “if you eat your broccoli, then you’ll get dessert,” and she eats her broccoli, but then they withhold dessert, they were lying. (Which isn’t a very nice thing to do to a little kid who wants dessert!) But if she doesn’t eat her broccoli, they’ve made no promises about whether she’ll get dessert; what the parents told her is true regardless. This kind of conditional, our focus in this chapter, is called a material conditional.

To summarize, in a conditional claim, the antecedent is a condition that guarantees some consequence; it is logically prior to the consequent. The consequent is the condition that arises from, or is guaranteed by, the antecedent. In an if/then statement, the antecedent follows “if” while the consequent follows “then.”

When Hubble calculated that distant stars were more than 10 billion years old, he knew that the universe itself is at least that old. This can be stated as a conditional: If some stars are more than 10 billion years old, then the universe must be more than 10 billion years old. In other words, a sufficient condition for the universe’s being 10 billion years old is that some stars are 10 billion years old. If the universe were younger, it couldn’t contain any objects that old. The universe being 10 billion years old is thus a requirement for any star to be that old. But again, this doesn’t work in reverse: learning that the universe is a certain age would not guarantee that any star is that old. It’s possible for the oldest stars to be younger than the universe containing them. The universe’s having a given age is a necessary condition for there to be a star of that age, but it’s not a sufficient condition.

#### Valid and sound arguments

Recall from section 6.1 that, in a valid deductive argument, the truth of all premises guarantees the truth of the conclusion. In other words, the truth of all premises is a sufficient condition for the truth of the conclusion. Deductive arguments for which this is not so are said to be invalid. An invalid deductive argument does not always have a false conclusion. This just means the truth of all premises does not guarantee the conclusion is true. Likewise, a valid deductive argument does not always have a true conclusion. Recall from earlier that Aristotle gave a valid deductive argument for the conclusion that the universe is eternal, but we now believe that conclusion to be false. A valid deductive argument with a false conclusion must have one or more false premises—because if the premises were all true, the conclusion would be as well (or else it’s not a valid argument).

So, to assess whether an argument or inference is valid, assume or stipulate that all premises are true, and then ask whether it’s possible for the conclusion to be false. If not—if the truth of the premises alone guarantees the truth of the conclusion—the inference is valid. But if this is possible, the inference is invalid. Deductive inferences cannot be made more valid, or rendered invalid, by adding more premises. Deductive inferences are thus monotonic inferences: inferences that cannot be invalidated by the addition of new information. Because deductive reasoning is monotonic, it is fully secure in the sense that, if your inferences are valid, you can be absolutely certain that true premises guarantee a true conclusion. (As we will see in Chapter 7, this is not so for inductive or abductive arguments.)

Some patterns of deductive inference are common enough to have names. One such pattern is affirming the antecedent (also known as modus ponens), a valid pattern of deductive inference in which a conditional statement and its antecedent are used as premises for concluding the consequent is true. For example,

​	(1) If the James Webb Space Telescope is at the second Lagrange point, then it will orbit the Sun at 1.5 gigameters from Earth.

​	(2) The James Webb Space Telescope is at the second Lagrange point.

​	∴ (3) It will orbit the Sun at 1.5 gigameters from Earth.  

(A Lagrange point is a location where an object is equally influenced by two orbiting bodies, in this case the Sun and Earth.) The conditional statement of the relationship between the second Lagrange point and orbital distance holds regardless of where the telescope is in fact located; the observation of the telescope’s location at this Lagrange point then makes the antecedent of the conditional true such that the consequent also must be true. The conclusion is, thus, just a statement asserting the consequent.

Another elementary pattern of deductive inference is denying the consequent (also known as modus tollens), a valid pattern of deductive inference in which a conditional statement and the denial of its consequent are used as premises for concluding the antecedent is also false. For example,

​	(1) If the universe is in a steady state, then astral bodies remain the same distance from one another.

​	(2) Astral bodies do not remain the same distance from one another.

​	∴ (3) The universe is not in a steady state.

In this argument, the conditional statement relating the universe’s state to relative distances of astral bodies enables an observation of increasing distance between astral bodies (as evident from changes in redshift) to be used to conclude something about the universe—namely, that it is not in a steady state but expanding.

Any arguments following these two patterns are deductively valid. The premises may not be true, of course. But if they were true, they would logically guarantee that the conclusion must also be true. No matter how long and deep you think, you will not be able to find an instance of either pattern that is invalid.

Keep in mind that a valid deductive argument is more than premises and a conclusion that are all true. To have a valid inference, the truth of the premises must logically force the conclusion to be true; there must be no way around having a true conclusion if the premises are true. Consider this argument:

1. Cats are mammals.
2. Tigers are mammals.
3. ∴ Tigers are cats.

Both premises are true, and so is the conclusion. But the inference is invalid. Even though all three statements are true, the truth of the conclusion isn’t guaranteed by the truth of the premises. To see this, substitute in dogs for cats in the argument; the two premises will still be true, but not the conclusion.

##### Box 6.2 Different kinds of logic

Formal logic is the study of the rules governing what can validly be inferred from a set of claims. The study of logic is deeply related to mathematics and computer science, where researchers also explore formal relations between sets of claims. Two rules of deductive logic we’ve encountered are affirming the antecedent (modus ponens) and denying the consequent (modus tollens). Both rules are valid, since the truth of the premises guarantees the truth of the conclusion.

Formal logic employs fully precise rules like these. Yet natural languages (English and all other languages used around the world) are not fully precise. Ideas expressed in natural language can sometimes be interpreted in different ways. This means there are choices to make in how to define the precise rules of formal logic. Different choices result in different systems of formal logic.

For instance, the most common logic system, called classical logic, has an assumption called the law of the excluded middle. This law stipulates that, for every claim, either the claim is true or its negation is true. For example, if it is not true that the grass is green, then it is true that the grass is not green. In many cases, the excluded-middle assumption accurately reflects how we reason in natural language. But sometimes it seems to go wrong. For example, it’s not obvious that, if it’s not true that it’s raining, then it’s definitely not raining. Perhaps it’s sprinkling out, but we wouldn’t yet call it rain. Other systems of logic make different assumptions to recognize this possibility, making it possible for a sentence to be neither true nor false or a sentence to be both true and false. These systems of nonclassical logic thus reject the law of the excluded middle.

So invalid arguments can have true premises and conclusions, while valid arguments can have false premises and conclusions. Successful deductive inferences are those that combine both validity and truth. A sound inference is a valid deductive inference with all true premises. If you know both that all premises are true and that the inference is valid, then you know that the conclusion must be true. No additional evidence or reasoning can change that. If it does, then either you didn’t actually have a valid deductive inference, or you didn’t actually know that all the premises are true. (Or something changed such that a premise that had been true became false.) If scientists know some inference is sound, they can be certain that the conclusion is true beyond a shadow of a doubt.

#### Uncovering bad arguments

Being persuaded is a psychological phenomenon. People can fall for bad arguments or may be unpersuaded by good ones. But whether a deductive inference is good—valid and sound—is simply a matter of logic and truth.

A valid deductive argument is unsound if one or more of its premises is false. An argument is invalid, as we’ve seen, if the truth of the premises does not guarantee the truth of the conclusion. You can show that an argument is invalid by giving a counterexample: a situation, real or imagined, in which the premises of an argument are true but the conclusion false. Even if the situation could never really occur, describing it shows the argument is invalid, as the premises being true alone can’t guarantee the truth of the conclusion.

To evaluate a deductive argument, one should determine whether either of these criticisms apply: is the argument invalid? Is one or more premise false? Here, psychological reasoning intersects with logical inference. If an argument is faulty on one or both of these grounds, consider whether it can be repaired by replacing any false premises with true ones or whether additional premises could be supplied that render the inference to the conclusion valid. Sometimes promising arguments are not yet successful. Other times, an argument is confused, misleading, or just wrong and simply should be rejected.

The valid inference patterns involving conditional statements discussed earlier—affirming the antecedent and denying the consequent—have related invalid inference patterns that result from confusing the roles of necessary and sufficient conditions in conditional statements. Denying the antecedent is an invalid pattern of deductive inference in which a conditional statement and the denial of its antecedent are used as premises for concluding the consequent is also false. Here is an argument that commits the error of denying the antecedent:

1. If a star is more than 15 billion years old, then so too is the universe.
2. No star is more than 15 billion years old.
3. ∴ The universe is not more than 15 billion years old.

This is an invalid argument. Even if the first two premises are true, that’s no guarantee that the conclusion must also be true. The first premise indicates that the age of the oldest star is just a minimum age for the universe. If the conditional statement is true, the antecedent guarantees the consequent but not the other way around. So, denying the antecedent, as the second premise does, provides no good reason to believe the consequent is the case, but it doesn’t demonstrate that the consequent is not the case, either.

Affirming the consequent is an invalid pattern of deductive inference in which a conditional statement and its consequent are used as premises for concluding the antecedent is true. Here is an argument that commits the error of affirming the consequent:

1. If Andromeda is 13.8 billion light-years away, then the universe is at least 13.8 billion years old.
2. The universe is 13.8 billion years old.
3. ∴ Andromeda is 13.8 billion light-years away.

This is also an invalid argument. Both premises are true, but, again, they don’t guarantee the truth of the conclusion. Some specific astral body viewed from Earth being 13.8 billion light-years away does imply that the universe is at least 13.8 billion years old, but the universe being that age doesn’t guarantee the age of any particular astral body. In fact, Andromeda is around 2.5 million light-years away.

##### Box 6.3 The Wason selection task

Suppose you see four cards on a table. You know the cards have letters on one side and numbers on the other, and the sides you see show these symbols:

- A
- K
- 4
- 7

Consider this claim: “If a card has a vowel on one side, then that card has an even number on the other side.” Which card(s) do you have to flip over to evaluate whether the claim is true? Briefly write down which of the cards you would flip.

If you are like most people, you chose the card showing the A and maybe also the card showing the 4. But, according to the rules of deductive logic, to test a conditional claim, you should look for circumstances where the antecedent is true but the consequent is false—so you should have chosen the A and the 7. Rules from logic are sometimes used as standards of rationality in psychology research. While these standards are useful to generate predictions of how idealized agents should reason, it’s a matter of debate whether deviations from these standards are a sign of irrationality. A common example comes from people’s answers to this problem, called the Wason selection task. Deviations between ideal standards of rationality and real human reasoning raise fundamental questions about what it means to be rational and whether deductive logic provides us with the right normative standards for interpreting human reasoning. Interestingly, most people get the Wason selection task right if the question relates more to everyday experience. When you ask which of the following people’s IDs should be checked to ensure no one under 21 drinks alcohol, most get the answer right—and the deductive logic is exactly the same.

The defects in reasoning seen thus far are with the form of the inference. But sometimes the problem with an inference is empirical rather than logical. Sometimes, even when an argument is valid, the world doesn’t cooperate with the statements made about it. This is one place where the detective work of science comes in. For example, consider the following argument:

1. The word atom means indivisible.
2. If the word atom means indivisible, then atoms are indivisible.
3. If atoms are indivisible, then atoms are the smallest type of matter.

∴ Atoms are the smallest type of matter.

This argument involves multiple instances of affirming the antecedent—a valid inference pattern. Given the first two premises, it follows that atoms are indivisible; and from the conjunction of that claim with the third premise, it follows that atoms are the smallest type of matter. This argument is valid. The problem, of course, is that scientists have discovered particles even smaller than atoms. Electrons were discovered in 1897, followed by the discoveries of protons, neutrons, neutrinos, positrons, muons, bosons, and hadrons, which are all smaller than atoms. These discoveries show the conclusion to be false: atoms are not the smallest type of matter. So, the argument is unsound. But because the argument is valid, learning that the conclusion is false also tells us that at least one of the three premises is also false. Can you figure out which one?

#### Bad reasons to reject inferences

Being wary of invalid inference patterns and potentially false premises can help detect bad arguments. But these logical and empirical reasons to challenge some arguments should be distinguished from the negative psychological reactions that some arguments can evoke. For instance, whether someone finds the conclusion of an argument distasteful, offensive, or disagreeable is irrelevant to whether that conclusion is true. The conclusion that global warming is caused by human activity is politically and financially inconvenient for fossil fuel industries. This inconvenience has motivated them to try to subvert the scientific research leading to this conclusion, and they’ve been incredibly successful at sowing doubt about climate change. Taking a leaf from the Big Tobacco playbook used to instill doubt about cigarettes causing cancer in the mid‐20th century, their disinformation campaigns often point to the mere occurrence of disagreement as a reason for doubting climate change, regardless of the overwhelming evidence to the contrary.

Some scientific reasoning can be counterintuitive or difficult to understand. By itself, this isn’t grounds for rejection. People with limited exposure to evolutionary theory may find it difficult to imagine the course of evolution from single‐celled organisms to humans. Similarly, without training in physics and cosmology, it can be difficult to comprehend the universe being billions of years old and expanding out from an initial Big Bang. But evolutionary theory and cosmological research provide solid grounds for accepting the truth of these bewildering claims—based on convergent evidence from many sources and sound arguments developed from that data. Just as a claim’s intuitiveness isn’t a guide to its truth, an argument’s difficulty or complexity is irrelevant to the goodness of its inferential structure. Likewise, concluding that intelligent design must be true because there is no evidence proving that there is no supernatural intelligent creator is a bad argument; this is called an appeal to ignorance.

Some people contend that the scientific estimate of the age of the universe is “just an opinion.” Similarly, skeptics of evolutionary theory love to claim that it is “just a theory” that biological species evolved from a common ancestor. These are poor objections. Natural phenomena, and natural explanations of those phenomena, are not simply a matter of opinion. And scientific theories are developed on the basis of a tremendous amount of confirming evidence and careful inference. These criticisms are not based on disagreements about evidence or the logic of arguments but instead appeal to the trivial fact that people have different ideas about some things. Ideas that are supported by evidence and sound inference should be taken seriously.

##### EXERCISES

6.7: Recall: Give an example of a conditional statement. Label the antecedent and the consequent, and state which is a necessary condition and which is a sufficient condition.

6.8: Think: The following statements concern necessary and sufficient conditions. For each statement, rephrase it as a standard if/then conditional statement and state whether it’s true or false.

1. Being a mammal is a sufficient condition for being human.
2. Being human is a sufficient condition for being an animal.
3. Being alive is a necessary condition for having a right to life.
4. Being alive is a sufficient condition for having a right to life.
5. Having a PhD is necessary to become a scientist.
6. It’s sufficient for being awarded the Nobel Prize in immunology that one cures cancer.

6.9: Recall: Write out an example of each of these argument patterns in standard form (numbered statements with the conclusion last, introduced by “∴”) and then label each as valid or invalid: affirming the consequent; denying the antecedent; denying the consequent; affirming the antecedent. For the valid patterns, give a short justification for the validity. For the invalid patterns, give a counterexample.

6.10: Apply: Review Hubble’s scientific arguments about the size, expansion, and age of the universe in section 6.1. Identify an inference that fits the pattern of affirming the antecedent and an inference that fits the pattern of denying the consequent. Write each out in standard form. (One option: consider inferences leading to the conclusions that (a) the universe is expanding and (b) Andromeda is not part of our galaxy.)

6.11 Recall: List at least two good reasons to reject inferences and at least three bad reasons to reject inferences, providing justification for each being good or bad.

6.12 Apply: The following argument is invalid, but if one premise is added, it becomes a valid argument. Add a premise that makes the argument valid, and then assess the quality of the revised argument, considering the truth of each premise and the pattern of each inference.

 	1. If a star is 13.8 billion light-years away, then the universe is at least 13.8 billion years old.
 	2. If the universe came into existence 6,000 years ago, then it is not 13.8 billion years old.
 	3. ∴ The universe did not come into existence 6,000 years ago.

​	Should this argument be preserved in its revised form with the added premise? Why or why not?

### 6.3 DEDUCTIVE REASONING IN HYPOTHESIS-TESTING

After reading this section, you should be able to:

- Define hypothetico-deductive method
- Analyze an instance of hypothesis‐testing using the H‐D method
- Describe how the Duhem‐Quine problem complicates the H‐D method

#### The hypothetico-deductive method

Hypothesis‐testing is a central component of scientific research. Chapters 3 – 5 focused on several strategies for gaining empirical evidence to test hypotheses, but in this chapter, we’ve seen that testing hypotheses also requires rational inference to see how empirical evidence bears on hypotheses. One way of thinking about the inferential relationship between evidence and hypotheses is the hypothetico‐deductive method, or H‐D method. This applies the logic of deductive inference to hypothesis testing.

In general, hypothesis‐testing involves establishing expectations from a hypothesis, and then comparing those expectations with observations. For the hypothetico-deductive method, an expectation is deductively inferred from the hypothesis, and then the expectation is compared with an observation. Violation of the expectation deductively refutes the hypothesis, while a match with the expectation nondeductively boosts support for the hypothesis.

The first use of deductive inference in the H‐D method is in the relationship between hypothesis and expectation. This involves determining what to expect if the hypothesis under investigation is true. That relationship can be expressed as a conditional statement with the hypothesis as the antecedent and the expectation as the consequent: “if H, then E.” We don’t yet know whether the hypothesis is true, but we do know that if the hypothesis is true, then the expectation will be true. This conditional statement can be thought of as an answer to the question: “if this hypothesis is true, what must the world be like?” Recall Hubble’s reasoning about the size of the universe. The then‐accepted hypothesis that the universe is in a steady state leads to the expectation that there would be no pattern in the redshift of stars: if the universe is in a steady state (H), then there’s no pattern in stars’ redshift (E).

After deductively inferring an expectation from a hypothesis, scientists make observations to compare with the expectations. For the H‐D method, deductive inference plays a role in this step as well. If what is observed doesn’t match what was expected, this enables a deductive argument for the conclusion that the hypothesis is false. That is, the observation violates the expectation, which refutes the hypothesis—proves it to be wrong. This is called refutation and can be represented this way:

##### Refutation

1. If H, then E
2. Not E
3. ∴ Not H

The applicable inference pattern is denying the consequent, which we’ve learned is a valid form of deductive inference. Scientists whose observations defy their expectations should reason that something is amiss. If a hypothesis guarantees some expectation will occur, and then the observation violates the expectation, one can deductively conclude the hypothesis is false. In other words, the mismatch between expected and actual observations refutes the hypothesis. When Hubble observed a distinctive pattern in stars’ redshift—those further away had more redshift—this enabled him to reject the hypothesis that the universe was in a steady state.

Sometimes, of course, observations do match the expectations. This is a good sign about the hypothesis. Careful, though! If the observations and expectations match, and we conclude the hypothesis must be true, this follows the inference pattern of affirming the consequent, which is an invalid form of deductive inference. So, if observations match expectations, this does not enable a valid deductive argument for the hypothesis. Think of it this way. A match between expectations and observations is consistent with the truth of the hypothesis, sure, but it does not guarantee the truth of the hypothesis. We can think of this nondeductive inference as confirmation: the observation matches the expectation based on the hypothesis, providing evidence in favor of the hypothesis.

##### Confirmation

1. If H, then E
2. E
3. ∴ Probably or possibly H

If the evidence matches expectations, the hypothesis is confirmed; if not, it’s refuted. The H‐D method identifies an important difference in the logic of confirmation versus refutation. Refutation of a hypothesis is deductively valid and thus certain, while confirmation of a hypothesis is not. This is why we included “probably or possibly” in the previous argument form for confirmation.

When Hubble observed a distinctive pattern in the redshift of stars, he hypothesized that the universe is expanding. That would lead us to expect that more distant stars have a greater redshift, as they are moving away from us more quickly than stars closer by. This expectation matches Hubble’s observation, and so confirms the hypothesis. But perhaps there’s some other reason for this observation. Scientists needed to look for additional evidence supporting the hypothesis that the universe was expanding.

A very simple example can help illustrate this point about the different logic of refutation and confirmation. Consider the hypothesis that all swans are white. If this hypothesis is true, then the swan you observe next will be white. This is a true conditional statement: the antecedent’s truth guarantees the truth of the consequent. So, you go out looking for swans, with the expectation that, if your hypothesis is true, you will see a white one. Let’s say you instead encounter a black swan. This observation violates your expectation; by denying the consequent, you’ve shown the antecedent (the hypothesis) is false. Breaking news: it’s not the case that all swans are white! However, if the next swan you see is white, then your observation matches the expectation. You haven’t proven anything, but you do have a bit more evidence in favor of the hypothesis.

The H‐D method thus posits a crucial difference between refutation and confirmation. Refutation is a valid deductive inference proving the hypothesis is false. In contrast, the logical structure of confirmation is a deductively invalid inference. Thus, we are not warranted in concluding the hypothesis is certainly true but only that it probably or possibly is. An observation matching what a hypothesis leads us to expect usually provides some evidence for the hypothesis, but this isn’t always so, and it’s surprisingly tricky to articulate how this works.

##### The case of puerperal fever

The philosopher Carl Hempel famously invoked the story of Ignaz Semmelweis to illustrate the H‐D method. Semmelweis was a doctor working in the First Maternity Division of the Vienna General Hospital in the 1840s. At that time, many birthing women contracted a serious—even fatal—illness known as puerperal or “child-bed” fever. (Puerperium refers to the postpartum period following labor and delivery.) A puzzling observation was that the mortality rate in the First Maternity Division was approximately three times higher than in the adjacent Second Maternity Division. These rates are shown in Table 6.1.

What accounted for the difference between the two wards? Semmelweis made several interesting observations. Women with extremely long dilation periods died of puerperal fever more often; patients in the first ward fell ill in a sequential manner, one after another; and neither patients’ health nor their caretakers’ skill seemed related to the incidence of puerperal fever. Finally, not only was the illness rate in the second ward lower, but women who instead gave birth at home or elsewhere outside the clinic—even unattended on the street—did not suffer from puerperal fever.

###### Table 6.1: Annual births, deaths, and mortality rates for all patients at two clinics of the vienna maternity hospital (1841–1846)

| Year       | First Clinic | First Clinic | First Clinic | Second Clinic | Second Clinic | Second Clinic |      |      |      |      |
| ---------- | ------------ | ------------ | ------------ | ------------- | ------------- | ------------- | ---- | ---- | ---- | ---- |
|            | Births       | Deaths       | Rate         | Births        | Deaths        | Rate          |      |      |      |      |
| 1841       | 3036         | 237          | 7.7          | 2442          | 86            | 3.5           |      |      |      |      |
| 1842       | 3287         | 518          | 15.8         | 2659          | 202           | 7.5           |      |      |      |      |
| 1843       | 3060         | 274          | 8.9          | 2739          | 164           | 5.9           |      |      |      |      |
| 1844       | 3157         | 260          | 8.2          | 2956          | 68            | 2.3           |      |      |      |      |
| 1845       | 3492         | 241          | 6.8          | 3241          | 66            | 2.0           |      |      |      |      |
| 1846       | 4010         | 459          | 11.4         | 3754          | 105           | 2.7           |      |      |      |      |
| Total Avg. | 20,042       | 1989         | 9.92         | 17,791        | 691           | 3.38          |      |      |      |      |

Semmelweis used these observations to rule out several possible sources of illness. If puerperal fever were a citywide epidemic, then women laboring outside the hospital would also suffer from the illness—but they didn’t. If puerperal fever were triggered by psychological concerns during childbirth, like intense modesty from being medically examined by male doctors (as had been proposed), then women delivering in the streets should also experience puerperal fever—but they didn’t. Further, all of the proposed sources of illness led to the expectation of equal rates of the illness in the first and second maternity wards, but that expectation didn’t match observations. As in the H-D method of refutation, Semmelweis rejected these hypotheses about the origin of puerperal fever.

Semmelweis also tried to develop hypotheses that were consistent with the observed difference in puerperal fever rates between the two wards. One difference between them was male doctors and medical students staffed the first ward, whereas female midwives staffed the second ward. Women in the first ward also gave birth on their backs, while women in the second ward gave birth on their sides. Semmelweis changed procedures in the first ward so that all women there also gave birth on their sides. If giving birth on one’s back increases incidence of the puerperal fever, then that changed position will decrease incidence of puerperal fever. Alas, this expectation didn’t match Semmelweis’s observation: changing birth position in the first ward made no difference. Other hypotheses were similarly tested and ruled out.

In March 1847, Semmelweis learned that his colleague Jakob Kolletschka had died. Kolletschka was a professor of forensic medicine and had been performing an autopsy when a scalpel had lacerated his finger. Kolletschka had then exhibited the same symptoms as the mothers and infants who died of puerperal fever. Although distraught, Semmelweis also recognized the significance of this information for his investigation. He hypothesized that the scalpel had contaminated Kolletschka’s blood with “cadaverous particles,” which had caused puerperal fever leading to his death.

Semmelweis’s hypothesis fit with the observed difference in illness rates between the two wards: doctors and medical students performed autopsies, whereas midwives did not. If cadaverous particles from autopsies caused puerperal fever, then only births attended by doctors and medical students who had performed autopsies would result in puerperal fever. In fact, much higher rates were observed in the ward attended by doctors and medical students, confirming this hypothesis.

Semmelweis reasoned that if the hypothesis that cadaverous particles caused puerperal fever were true, then the illness could be prevented by eliminating the particles. To test his hypothesis, he required all doctors, medical students, and midwives to wash their hands in a solution of chlorinated lime prior to examining patients. If this made no difference, then cadaverous particles weren’t to blame—the hypothesis would be refuted. Instead, the mortality rate from puerperal fever began to decrease, and the incidence of illness in the first and second wards became similar.

As described here, this case involves many instances of the H-D method, and it illustrates the logical difference between refutation and confirmation. On the H-D account, refutation is decisive because it results from a valid deductive inference, while confirmation is logically weaker. And, as it turns out, Semmelweis’s confirmed hypothesis was incorrect: puerperal fever does not originate from cadaverous material but from uterine bacterial infection. Luckily, chlorinated lime has antibacterial properties. Semmelweis thought the prescribed handwashing worked because it removed cadaverous material; instead, it worked because it removed bacteria. (The role of bacteria in illness was not yet widely accepted.)

Some other important instances of hypothesis‐testing are also well captured by the H‐D method. In Chapter 3, we discussed Arthur Eddington’s confirmation of Einstein’s theory of relativity from the 1919 solar eclipse as a crucial experiment, decisively adjudicating between two hypotheses. This is because the experiment refuted Newton’s cosmological theory while fitting with Einstein’s new theory. Measuring how much light bends around the Sun enabled Eddington to refute Newton’s theory and confirm Einstein’s.

#### Auxiliary assumptions

The hypothetico‐deductive (H‐D) method captures something important about hypothesis‐testing in science, namely, the distinctive power of refutation. Data that fit our expectations are well and good, but we can really learn something from data that go against our expectations. This accords with the importance of falsifiable hypotheses, too—hypotheses must be at risk of refutation in order to have the potential to be confirmed by evidence. The power of refutation is also what makes the idea of crucial experiments compelling, as with Eddington’s test of Einstein’s new theory of relativity against Newton’s reigning theory.

However, the H‐D method also has its limitations. One limitation is that inferences from hypotheses to expectations are never genuinely deductive. Additional claims are needed to make a deductive inference from hypothesis to expectation valid. These additional claims are auxiliary assumptions: assumptions about how the world works that often go unnoticed but that are needed for a hypothesis or theory to have the expected implications. In Chapter 3, we stressed the role of background knowledge in shaping expectations; this is the same point. Lurking in the background of Semmelweis’s inference about handwashing, for example, was the assumption that handwashing would remove cadaverous material. Behind Eddington’s refutation of Newtonian physics were numerous assumptions about the behavior of instruments, the properties of light, the location of certain astral bodies, and more.

Auxiliary assumptions often go unnoticed. Sometimes, this is because an auxiliary assumption is assumed to be true; other times, no one has even noticed the assumption is needed. But, because valid deductive inference requires the premises to guarantee the conclusion, any auxiliary assumptions are essential for the deductive inference from a hypothesis to some expectation, a key component of the H‐D method. But this also impacts the conclusions one can draw. So, the schemes identified earlier for refutation and confirmation on the H‐D account need to be adjusted:

| Refutation             | Confirmation                         |
| ---------------------- | ------------------------------------ |
| (1) If H and A, then E | (1) If H and A, then E               |
| (2) Not E              | (2) E                                |
| ∴ (3) Not (H and A)    | ∴ (3) Probably or possibly (H and A) |

In this new formulation, A stands for whatever auxiliary assumptions are required as additional premises to validly deduce E from H. These may include background knowledge about the phenomenon under investigation, information about the reliability of experimental instruments and measurement procedures, and more. But taking into account auxiliary assumptions means that all we can deductively include in refutation is that it’s not the case that both H and A are true—either the hypothesis is false or an auxiliary assumption is false (or both). Given the need for auxiliary assumptions, the H-D method cannot be used to conclusively determine that the hypothesis is false.

This problem relates to underdetermination, introduced in Chapter 3 as the idea the evidence may not be sufficient to determine which of multiple hypotheses is true. This variety of underdetermination is known as the Duhem-Quine problem, the idea that scientific hypotheses can never be tested in isolation but only against the background of auxiliary assumptions. The Duhem-Quine problem is named after the 19th-century French physicist, mathematician, and philosopher Pierre Duhem and the 20th-century American philosopher Willard van Orman Quine, who both emphasized this challenge.

One consequence of the Duhem-Quine problem is that deductive logic alone is insufficient for successful hypothesis-testing. In the face of refutation, scientists need to decide whether to give up on a hypothesis or to question their auxiliary assumptions. This seems to involve an element of choice. In the face of refutation, scientists may well want to hold on to a hypothesis they like and search for other explanations for why the observations didn’t turn out as expected. This makes the logic of refutation more similar to that of confirmation: neither is fully decisive.

That said, there are some guidelines for whether to reject a hypothesis in the face of refutation or instead blame an auxiliary assumption. Usually, scientists have independent evidence for many of their auxiliary assumptions. Instruments and measurement procedures have been tested and calibrated, and background knowledge about a phenomenon is based on evidence or commonsense. These considerations can help scientists decide how much to trust auxiliary assumptions and thus whether, and when, to reject the hypothesis under investigation. A refutation may also spur additional tests of auxiliary assumptions before a verdict about whether to reject the hypothesis.

Nonetheless, the need for auxiliary assumptions limits the power of the H-D method of hypothesis-testing. The Duhem-Quine problem makes clear that, just like confirmation, refutation is messier than simple deductive inference.

##### EXERCISES



6.13 Recall: The name of the hypothetico-deductive method refers to hypotheses and deductive inference. Briefly summarize the H-D method. How does the H-D method relate to hypotheses? What are the two applications of deductive inference in the H-D method?

6.14 Recall: Write out the H-D schemes for refutation and for confirmation. What is the key difference between them, and how does that difference relate to deductive inference?

6.15: Apply: Return to the description of Semmelweis’s investigation of puerperal fever. Identify three inferences that can be described as uses of the H-D method (either refutation or confirmation). For each, write out the inference as an argument in standard form with numbered premises and conclusion.

 6.16 Think: You might think the problem Semmelweis uncovered was that doctors weren’t washing their hands. But this isn’t so; the doctors in Vienna General Hospital already had been washing their hands. Consider what you know about bacteria. If doctors were already washing their hands, what do you think the problem could have been?

6.17 Recall: What is the Duhem-Quine problem? How does this relate to underdetermination? Why does the Duhem-Quine problem complicate the H-D method?

6.18 Apply: Consider Semmelweis’s inference that if he required all doctors, medical students, and midwives to wash their hands in a solution of chlorinated lime prior to examining patients and this made no difference to the incidence of puerperal fever, then cadaverous particles weren’t to blame. List at least three auxiliary assumptions needed for this inference to hold.

### 6.4 AXIOMATIC METHODS AND MODELING

After reading this section, you should be able to:

- Characterize the axiomatic method and indicate how it is used in science
- Articulate how deductive inference is used in mathematical modeling
- Describe how non‐Euclidean geometry and the James Webb Space Telescope exemplify roles of deductive reasoning in science

#### Axiomatic methods

Deductive inference plays special roles in some fields of science. Progress in scientific reasoning is sometimes achieved through formal axiomatization, a constructive procedure by which statements are derived from foundational principles. The foundational principles, called axioms, are accepted as self‐evident truths about some domain. A set of axioms is then used to deductively infer other truths about the domain, called theorems.

The most venerable example of axiomatization comes from the Greek mathematician Euclid, working around 300 BCE. Euclid’s Elements of Geometry begins with 23 definitions and five axioms. The five axioms are the following:

1. A straight line may be drawn between any two points.
2. Any terminated straight line may be extended indefinitely.
3. A circle may be drawn with any given point as center and any given radius.
4. All right angles are equal.
5. If two straight lines in a plane are met by another line, and if the sum of the internal angles on one side is less than two right angles, then the straight lines will meet if extended sufficiently on the side on which the sum of the angles is less than two right angles.

Together, these five axioms serve as the theoretical core of Euclidean geometry.

Figure 6.4 shows a fragment—one of the oldest on record—containing a diagram that accompanies the fifth axiom of Book II of the Euclid’s Elements.

Using this set of axioms as premises, one can validly deduce theorems about the congruency of figures, parallel lines, and other results of Euclidean geometry. In turn, these theorems can be treated as premises in new arguments aimed at validly deducing new theorems.

Euclid’s axiomatization of geometry was accepted as decisive for almost two millennia. This is a clear example of rigorous inference grounded in first principles, with the power to systematize all existing knowledge of geometry. Euclid’s axiomatization of geometry deeply influenced Ibn al‐Haytham’s work in optics and Newton’s physical theory of mechanics.

And yet, beginning in the 19th century, nonclassical geometries were developed that diverge from Euclid’s axiomatization. These arose from questioning the fifth axiom of Euclidean geometry. The fifth axiom is notably more complicated and less intuitive than the other axioms, and over centuries, many scholars tried to prove this principle as a theorem from the other axioms. None succeeded. Mathematicians working in the early 19th century then developed different geometries by introducing deviations from Euclid’s fifth axiom. Just as Euclid’s geometry was central to earlier developments in mathematics, physics and astronomy, these non‐Euclidean geometries paved the way for Einstein’s radical new theories of the relativity of space and time. Einstein’s theories of relativity imply that the geometry of physical space itself is generally not Euclidean. A principle accepted as mathematical certainty for millennia was then rejected as not in general true. (Einstein’s theories do entail that geometry here on Earth is approximately Euclidean, though.)

Another example of the axiomatic method concerns the foundations of arithmetic. Concerned with questions about the exact nature of numbers, the Italian mathematician Giuseppe Peano employed axiomatic reasoning to give a rigorous foundation for the natural numbers (that is, 0, 1, 2, 3, 4, . . .). Peano’s axiomatization of natural numbers began with three primitive concepts not defined in terms of other concepts. Peano thought these primitive concepts are self‐evident: the set of natural numbers, N; the number zero, a member of the set N; and the successor function S. This successor function can be applied to any natural number, and it will yield the next number after it. For example, S(6) = 7. Likewise, S(0) = 1. From here, Peano laid down several axioms:

1. Zero is a number.
2. If n is a number, then S(n) is a number.
3. Zero is not the successor of a number.
4. Distinct natural numbers have distinct successors.
5. If 0 is an element in a set of numbers and the successor of every number is in that set, then every number is in that set.

From these axioms, the basic properties of natural numbers could be described, and theorems about them, including arithmetic operations like addition and subtraction, could be deduced. To take a simple example, the supposition that there is a number preceding zero (S(k) = 0) would contradict axiom (3). Accordingly, the theorem that zero has no predecessor in N can be derived from axiom (3).

#### Deductive reasoning in mathematical modeling

This chapter began with a consideration of how Hubble reasoned from astronomical discoveries to conclusions about the size, expansion, and age of the universe. The newest chapter of the story of such cosmological discovery is the launch of the James Webb Space Telescope (JWST) in December 2021.

JWST is the successor to the Hubble and Spitzer Space Telescopes, and it is the most powerful deep space observatory ever built. Among its main goals is the delivery of data about mid‐infrared light with wavelengths up to 28,000 nanometers; scientists can use that data to reason about the beginning of the universe—especially the epoch of reionization, when stars began to generate light. JWST will also investigate galactic and stellar formation and evolution, and it will measure atmospheric chemistry to search various planetary systems for the conditions that make life possible.

Constructing and launching JWST was an amazing feat of human ingenuity and effort. The endeavor is an excellent example of fruitful collaboration between vocational, scientific, and philosophical disciplines. One of the many challenges to be worked out was the path JWST should take after its launch.

Theoretical resources used to answer that question come from mathematician and astronomer Leonhard Euler and his student Joseph‐Louis Lagrange, who in the 19th century explored mathematical solutions to what has come to be called “the three‐body problem.” In physics, this is the challenge of how the position, momentum, and gravitation of three celestial bodies affects the movement of each through space. There is no general solution to the three‐body problem; there’s no equation you can plug these values into and calculate the results. But a few special cases have been solved. These include when two of the bodies are motionless, and also when one of the three bodies is nearly massless relative to two massive orbiting bodies—such as a spacecraft, star, and planet.

Euler and Lagrange discovered five solutions for this special case of one nearly massless body and two massive orbiting bodies. These solutions are now known as Lagrange points. Lagrange points are regions of space where the gravitational pull of the two massive orbiting bodies is identical to the force needed for the nearly massless body to move with them. These points can be used to keep a spacecraft in position with less energy. In the Sun/Earth system, for the first three solutions (L1, L2, L3), the bodies are linearly aligned and the last two (L4 and L5) are the apices of equilateral triangles; collectively, these form what looks like a “peace” sign. Sending JWST to a Lagrange point offered a way to keep JWST “tethered” to the Sun and Earth, in a sense; that is, to use the gravitational force of those two bodies to speed JWST in its journey.

In January 2022, JWST journeyed to L2, which is approximately 1.5 million kilometers beyond the dark side of the Earth. In L2, JWST could harvest energy on its Sun‐facing side, helping to reduce fuel needs, and this also enabled reliable communication back to Earth. But if JWST overshot L2, it would have to be abandoned or returned to Earth, exposing sensitive instrumentation to solar radiation and heat in the process. And if JWST undershot L2, it would not be able to get into a stable position. So, mid‐course correction maneuvers were required to exactly reach L2. To determine the necessary course corrections, NASA scientists had to build models simulating the vectors of various thrusts in a state space. Computer simulations were used to help visualize these models, but the models themselves were essentially logical derivations from equations. These derivations enabled scientists to reason deductively about what consequences to expect from potential changes. Ultimately, scientists used these models to settle on three mid‐course correction maneuvers: one immediately after launch for redirection, another just before sunshield deployment, and the final correction to insert JWST into its L2 orbit.

At L2, the force required to keep JWST in position was minimized by the balance between Earth’s and Sun’s gravitational pull. But our solar system is not actually a three‐body system. There’s also our moon’s mass and gravitational pull to contend with, among other forces, and so the orbital stability of L2 is imperfect. Even minuscule deviations from equilibrium will tend to increase over time; think of a fishtailing trailer or skateboard that eventually crashes. If such deviations were left uncorrected, JWST would just wander out of L2. So, the question rises anew: how can scientists maintain JWST’s location over time while keeping it oriented so as to provide an unoccluded view of deep space?

NASA scientists modeled the range of possible perturbations of different orbital trajectories, examined what would result from these increasing changes without intervention, and then predicted the possible corrections to those curvatures that would allow them to maintain JWST’s position. Again, these geometric and topological models involve deductive inference from various formulae to predict the consequences of various trajectories around L2. For these reasons, JWST is not actually at L2. The halo motion the scientists settled on has it moving in a very wide, tilted, and slow elliptical orbit around L2. These mathematical models also demonstrated the need for throttle adjustments or “burns” every three weeks to correct for things like rotational torque and other small perturbations. The calculations involved in determining the timing and duration of these burns again requires scientists to reason deductively from their models.

These theoretical resources and calculations required to support the position and movement of the James Webb Space Telescope in space illustrate another way in which deductive reasoning is used in science. In any scientific research, inferential reasoning is needed to connect empirical investigation to conclusions. But the role of deductive reasoning is even more central to some scientific research. This includes the mathematical modeling used to inform the management of JWST and the axiomatic methods at the heart of the development of Euclidean and non-Euclidean geometries.

# EXERCISES

6.19: Recall: Describe the axiomatic method, including the roles of axioms and theorems. How does this method involve deductive reasoning? How has this method been used in science?

6.20: Apply: The triangle sum theorem in Euclidean geometry says that if you add all three interior angles—that is, the angles inside the triangle—they sum to 180 degrees. Look up a discussion of this theorem. Read the discussion, and then analyze the use(s) of deductive inference. Describe how the premises are used to infer the triangle sum theorem as conclusion. Include a citation of the source for the discussion you analyze.

6.21: Recall: Describe the three-body problem and how this relates to JWST.

6.22: Think: Why is it important that the reasoning involved in modeling the orbits of JWST be deductive?

6.23: Think: The examples of axiomatization and deductive reasoning in model building come from geometry, mathematics, and astrophysics. Why do you think examples like these come from those disciplines rather than, say, biology or sociology?

##### FURTHER READING

- For NASA resources on the relevance of James Webb Space Telescope for science, see https://webb.nasa.gov/content/science/index.html.
- For more on deductive and nondeductive reasoning, see Harman, G. (1986). Change in view: Principles of reasoning. MIT Press.
- For more on contradictions and logic, see Priest, G. (2014). Beyond true and false. Aeon Magazine. https://aeon.co/essays/the‐logic‐of‐buddhist‐philosophy‐goes‐beyond‐simple‐truth.
- For more on the hypothetico‐deductive method, see Sprenger, J. (2011). Hypothetico‐deductive confirmation. Philosophy Compass, 6(7), 497–508.
- For more on axiomatic methods, see Cantu, P. (2022). What is axiomatics? Annals of Mathematics and Philosophy, 1, 1–24.

